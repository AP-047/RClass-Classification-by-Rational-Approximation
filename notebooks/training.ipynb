{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"####  ðŸCheck Versions","metadata":{}},{"cell_type":"code","source":"# !python --version\n\nimport cupy as cp\ncp.__version__\n\n# !pip show jedi\n# !pip show setuptools\n# !pip show pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:41:02.232432Z","iopub.execute_input":"2024-12-16T01:41:02.232761Z","iopub.status.idle":"2024-12-16T01:41:04.077963Z","shell.execute_reply.started":"2024-12-16T01:41:02.232724Z","shell.execute_reply":"2024-12-16T01:41:04.077191Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'13.3.0'"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"#### ðŸ Set folder","metadata":{}},{"cell_type":"code","source":"import os\n\nmodels_dir = \"/kaggle/working/models/\"  # Kaggle's default working directory\n\n# Ensure the directory exists\nos.makedirs(models_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:41:04.078906Z","iopub.execute_input":"2024-12-16T01:41:04.079342Z","iopub.status.idle":"2024-12-16T01:41:04.086295Z","shell.execute_reply.started":"2024-12-16T01:41:04.079303Z","shell.execute_reply":"2024-12-16T01:41:04.085086Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Step 1: Import Data","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_openml\nimport numpy as np\n\n# Import MNIST dataset\nmnist = fetch_openml('mnist_784', version=1)\nx_full = mnist.data.values  # Full dataset\ny_full = mnist.target.values.astype(int)  # Labels (0â€“9)\n\nprint(f\"x_full shape: {x_full.shape}, y_full shape: {y_full.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:41:23.836243Z","iopub.execute_input":"2024-12-16T01:41:23.837042Z","iopub.status.idle":"2024-12-16T01:41:52.382045Z","shell.execute_reply.started":"2024-12-16T01:41:23.836988Z","shell.execute_reply":"2024-12-16T01:41:52.381091Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"x_full shape: (70000, 784), y_full shape: (70000,)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Step 2: Create Subset","metadata":{}},{"cell_type":"code","source":"# Create a subset of training data (1000 images per digit)\nsubset_size = 100\nx_subset = []\ny_subset = []\n\nfor digit in range(10):\n    digit_indices = np.where(y_full == digit)[0][:subset_size]\n    x_subset.append(x_full[digit_indices])\n    y_subset.append(y_full[digit_indices])\n\nx_subset = np.vstack(x_subset)\ny_subset = np.hstack(y_subset)\n\nprint(f\"x_subset shape: {x_subset.shape}, y_subset shape: {y_subset.shape}\")\nprint(f\"Unique labels in y_subset: {np.unique(y_subset)}\")\nprint(f\"x_subset[3].shape: {x_subset[3].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:42:01.327327Z","iopub.execute_input":"2024-12-16T01:42:01.327665Z","iopub.status.idle":"2024-12-16T01:42:01.342387Z","shell.execute_reply.started":"2024-12-16T01:42:01.327634Z","shell.execute_reply":"2024-12-16T01:42:01.341526Z"}},"outputs":[{"name":"stdout","text":"x_subset shape: (1000, 784), y_subset shape: (1000,)\nUnique labels in y_subset: [0 1 2 3 4 5 6 7 8 9]\nx_subset[3].shape: (784,)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Step 3: Apply PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport pickle\n\n# Apply PCA to reduce dimensionality\nn_components = 20\npca = PCA(n_components=n_components)\nx_pca = pca.fit_transform(x_subset)\n\n# Load PCA instance\nwith open(\"models/pca_model.pkl\", \"wb\") as file:\n    pickle.dump(pca, file)  # Save the fitted PCA model\n\nprint(f\"Original shape: {x_subset.shape}, PCA shape: {x_pca.shape}\")\nprint(f\"variance retained: {np.sum(pca.explained_variance_ratio_)*100}%\")\n\nprint(f\"shape of x_pca: \", x_pca.shape)\nprint(f\"shape of x_pca[5]: \", x_pca[5].shape)\n\nprint(f\"check any image vector: \", x_pca[5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T02:02:03.928172Z","iopub.execute_input":"2024-12-16T02:02:03.928959Z","iopub.status.idle":"2024-12-16T02:02:04.385238Z","shell.execute_reply.started":"2024-12-16T02:02:03.928921Z","shell.execute_reply":"2024-12-16T02:02:04.383911Z"}},"outputs":[{"name":"stdout","text":"Original shape: (1000, 784), PCA shape: (1000, 20)\nvariance retained: 66.00934331776499%\nshape of x_pca:  (1000, 20)\nshape of x_pca[5]:  (20,)\ncheck any image vector:  [1073.16458501 -209.31731563  791.9349834   225.96305438  821.33836512\n -624.52374331 -833.45224807 -471.0246632   -63.53703852  -53.73103906\n   94.3053625  -112.0961743   380.31245692 -425.9955943  -252.19020375\n  421.54830479  189.39211706  -73.01711337  205.48640401  330.71885856]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Step 4: Thresholding","metadata":{}},{"cell_type":"code","source":"# Thresholding: Convert to binary\nthreshold_value = 0\nx_b = (x_pca > threshold_value).astype(int)\n\nprint(f\"x_b shape: {x_b.shape}\")\nprint(f\"x_b[5] =\", x_b[5])\n\nprint(f\"x_b =\", x_b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T02:02:09.765902Z","iopub.execute_input":"2024-12-16T02:02:09.766545Z","iopub.status.idle":"2024-12-16T02:02:09.772231Z","shell.execute_reply.started":"2024-12-16T02:02:09.766504Z","shell.execute_reply":"2024-12-16T02:02:09.771343Z"}},"outputs":[{"name":"stdout","text":"x_b shape: (1000, 20)\nx_b[5] = [1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1]\nx_b = [[1 1 0 ... 1 1 1]\n [1 1 0 ... 0 1 0]\n [1 1 0 ... 0 0 0]\n ...\n [1 0 1 ... 1 1 1]\n [0 0 1 ... 1 1 1]\n [0 0 1 ... 1 1 0]]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Shuffle the dataset\nshuffle_indices = np.arange(len(y_subset))\nnp.random.shuffle(shuffle_indices)\n\nx_b = x_b[shuffle_indices]\ny_subset = y_subset[shuffle_indices]\n\nprint(f\"x_b.shape =\", x_b.shape)\nprint(f\"y_subset.shape =\", y_subset.shape)\n\nprint(f\"x_b =\", x_b)\nprint(f\"y_subset =\", y_subset)","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"x_b.shape = (1000, 20)\ny_subset.shape = (1000,)\nx_b = [[1 1 1 ... 0 0 1]\n [0 0 1 ... 0 0 0]\n [1 1 0 ... 0 1 0]\n ...\n [1 1 1 ... 0 0 0]\n [1 0 1 ... 1 0 0]\n [1 0 1 ... 0 0 1]]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"### Step 5: Train Classifiers","metadata":{}},{"cell_type":"code","source":"import pickle\nimport cupy as cp\nimport numpy as np\nfrom scipy.optimize import linprog\nimport matplotlib.pyplot as plt\n\n# Feasibility check function\ndef check_feasibility_and_compute_coefficients(z, x_b, y_binary):\n    num_data_points = x_b.shape[0]\n    num_coefficients = n_components + 1  # (+1 for the first constant terms Î±0 & Î²0)\n    delta = 1e-6  # a small positive value\n\n    # Construct G(x) and H(x) matrices for numerator and denominator\n    G = cp.zeros((num_data_points, num_coefficients))  # Numerator matrix\n    H = cp.zeros((num_data_points, num_coefficients))  # Denominator matrix\n\n    for i in range(num_data_points):\n      G[i, 0] = 1\n      H[i, 0] = 1\n      for j in range(num_coefficients-1):\n        G[i, j+1] = x_b[i, j] ** (j+1)\n        H[i, j+1] = x_b[i, j] ** (j+1)\n\n    # print(f\"G: {G}\")\n    # print(f\"G.shape =\", G.shape)\n    # print(f\"H: {H}\")\n\n    # Construct constraints for Ax <= b\n    A = []\n    b = []\n\n    for i in range(num_data_points):\n        f_plus_z = y_binary[i] + z  # Upper bound\n        f_minus_z = y_binary[i] - z  # Lower bound\n\n        # Constraint 1: (f(xi) - z) * Î²^T H(xi) - Î±^T G(xi) â‰¤ Î¸\n        # (-G(xi))Î±T + (f(xi) - z).H(xi)Î²T + (-1)Î¸ â‰¤ 0\n        constraint_1 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Î±\n        constraint_1[0:num_coefficients] = -G[i]\n        # (2) Coefficients of Î²\n        constraint_1[num_coefficients:2 * num_coefficients] = (f_minus_z) * H[i]\n        # (3) Coefficient of Î¸ (last element)\n        constraint_1[-1] = -1\n        A.append(constraint_1)\n        b.append(0)\n\n        # Constraint 2: Î±^T G(xi) + (-1).(f(xi) + z) * Î²^T H(xi) â‰¤ Î¸\n        # G(xi).Î±T + (-1)(f(xi) - z).H(xi)Î²T + (-1)Î¸ â‰¤ 0\n        constraint_2 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Î±\n        constraint_2[0:num_coefficients] = G[i]\n        # (2) Coefficients of Î²\n        constraint_2[num_coefficients:2 * num_coefficients] = -(f_plus_z) * H[i]\n        # (3) Coefficient of Î¸ (last element)\n        constraint_2[-1] = -1\n        A.append(constraint_2)\n        b.append(0)\n\n        # Constraint 3: Î²^T H(x) â‰¥ Î´\n        # (0)Î±^T + (-H(x)) Î²^T + (0)Î¸ â‰¤ -Î´\n        constraint_3 = cp.zeros(2 * num_coefficients + 1)\n        # Coefficient of Î²\n        constraint_3[num_coefficients:2 * num_coefficients] = -H[i]\n        A.append(constraint_3)\n        b.append(-delta)\n\n    # Convert CuPy arrays to NumPy arrays for SciPy\n    A = cp.asnumpy(cp.array(A))\n    b = cp.asnumpy(cp.array(b))\n\n    # print(f\"A =\", len(A))\n    # print(f\"A: {A[0]}\")\n    # print(f\"A.shape =\", A.shape)\n    # print(f\"len(A[0]): {len(A[0])}\")\n    # print(f\"len(b): {len(b)}\")\n    # print(f\"n_components =\", n_components)\n\n    # Objective function to minimize Î¸\n    c = cp.asnumpy(cp.zeros(2 * num_coefficients + 1))\n    c[-1] = 1  # Only Î¸ has a coefficient in the objective function\n\n    # Solve the linear programming problem (methods: highs, revised simplex)\n    result = linprog(c, A_ub=A, b_ub=b, method=\"highs\")\n\n    # Check feasibility and return results\n    if result.success:\n        alpha_coefficients = result.x[:num_coefficients]\n        beta_coefficients = result.x[num_coefficients:2 * num_coefficients]\n        theta = result.x[-1]\n        return True, alpha_coefficients, beta_coefficients, theta\n    else:\n        return False, None, None, None\n\n\n# Bisection loop\ndef bisection_loop(x_b, y_binary, uL, uH, precision):\n    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n    z_values = []\n\n    while uH - uL > precision:\n        z = (uL + uH) / 2\n        z_values.append(z)\n        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(z, x_b, y_binary)\n\n        if feasible:\n            uH = z\n            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n        else:\n            uL = z\n\n    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values\n\n# Train a classifier for each digit\nfor digit in range(10):\n    print(f\"Training classifier for digit {digit}...\")\n\n    y_subset = cp.array(y_subset)\n\n    # Assign labels: Positive for the current digit, negative for others\n    y_binary = (y_subset == digit).astype(int)\n\n    print(f\"y_binary =\", y_binary)\n    print(f\"y_subset =\", y_subset)\n\n    # Bisection parameters\n    uL = 0  # Initial lower bound\n    uH = 5000  # Initial upper bound\n    precision = 1e-6 # Precision threshold\n\n    # Run bisection loop\n    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(x_b, y_binary, uL, uH, precision)\n\n    # Print results\n    print(f\"Number of Iterations: {len(z_values)}\")\n    # print(f\"z Values in all Iterations: {z_values}\")\n    print(f\"Optimal z (Maximum Deviation): {optimal_z}\")\n\n    # # Plot convergence of z values\n    # plt.figure(figsize=(8, 6))\n    # plt.plot(range(len(z_values)), z_values, marker='o', linestyle='-')\n    # plt.xlabel(\"Iteration\")\n    # plt.ylabel(\"z Value\")\n    # plt.title(\"Convergence of z Values\")\n    # plt.grid(True)\n    # plt.show()\n\n    print(f\"Optimized Coefficients (Numerator Î±): {optimal_alpha}\")\n    print(f\"Optimized Coefficients (Denominator Î²): {optimal_beta}\")\n    print(f\"Optimal Î¸: {optimal_theta}\")\n    \n    # print(f\"rational_function =\", rational_function(x_b[0], optimal_alpha, optimal_beta))\n\n    # Save the model\n    model = {\n        \"alpha\": optimal_alpha,\n        \"beta\": optimal_beta,\n        \"theta\": optimal_theta,\n        \"n_components\": n_components\n    }\n\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"wb\") as file:\n        pickle.dump(model, file)\n\n    print(f\"Model for digit {digit} saved at {models_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T02:06:54.325843Z","iopub.execute_input":"2024-12-16T02:06:54.326197Z","iopub.status.idle":"2024-12-16T02:10:50.365997Z","shell.execute_reply.started":"2024-12-16T02:06:54.326165Z","shell.execute_reply":"2024-12-16T02:10:50.365131Z"}},"outputs":[{"name":"stdout","text":"Training classifier for digit 0...\ny_binary = [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1\n 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1\n 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06  0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimal Î¸: 4.999994179233908e-07\nModel for digit 0 saved at /kaggle/working/models/\nTraining classifier for digit 1...\ny_binary = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0\n 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0\n 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00  0.e+00  0.e+00\n  0.e+00 -0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00\n  0.e+00 -0.e+00 -0.e+00]\nOptimal Î¸: 4.999994179233908e-07\nModel for digit 1 saved at /kaggle/working/models/\nTraining classifier for digit 2...\ny_binary = [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0\n 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1\n 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n  0.e+00 -0.e+00 -0.e+00]\nOptimal Î¸: 4.999994179233909e-07\nModel for digit 2 saved at /kaggle/working/models/\nTraining classifier for digit 3...\ny_binary = [0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00  0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00  0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00\n  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimal Î¸: 4.999994179233908e-07\nModel for digit 3 saved at /kaggle/working/models/\nTraining classifier for digit 4...\ny_binary = [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0\n 0 0 1 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0\n 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0\n 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07  0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00  0.e+00\n -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00\n -0.e+00  0.e+00 -0.e+00]\nOptimal Î¸: 4.999994179233908e-07\nModel for digit 4 saved at /kaggle/working/models/\nTraining classifier for digit 5...\ny_binary = [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1\n 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00\n -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00]\nOptimal Î¸: 4.999994179233908e-07\nModel for digit 5 saved at /kaggle/working/models/\nTraining classifier for digit 6...\ny_binary = [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0\n 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0\n 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07 -0.e+00 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00\n -0.e+00 -0.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00\n  0.e+00  0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00\n -0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00]\nOptimal Î¸: 4.999994179233908e-07\nModel for digit 6 saved at /kaggle/working/models/\nTraining classifier for digit 7...\ny_binary = [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0\n 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00\n  0.e+00 -0.e+00 -0.e+00]\nOptimal Î¸: 4.999994179233908e-07\nModel for digit 7 saved at /kaggle/working/models/\nTraining classifier for digit 8...\ny_binary = [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0\n 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0\n 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0\n 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0\n 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 1]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06  0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00\n  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00\n -0.e+00  0.e+00 -0.e+00]\nOptimal Î¸: 4.999994179233908e-07\nModel for digit 8 saved at /kaggle/working/models/\nTraining classifier for digit 9...\ny_binary = [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n 0 0 0 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0\n 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n 0]\ny_subset = [5 3 3 2 8 8 8 7 7 9 2 0 4 0 1 3 6 5 5 2 0 4 3 8 0 4 3 9 3 8 1 1 4 9 5 1 7\n 4 2 9 1 4 5 3 7 9 5 4 3 0 1 5 1 3 8 7 8 7 6 4 6 6 6 9 6 3 5 3 5 9 1 1 4 2\n 3 6 3 0 5 0 9 0 4 3 2 7 7 0 1 3 6 9 8 1 6 4 0 6 5 3 5 3 4 3 7 2 1 3 1 5 2\n 7 7 1 4 4 9 9 6 0 4 2 0 0 4 3 0 1 2 3 3 8 0 8 7 7 4 6 3 4 6 7 2 4 5 1 6 3\n 3 1 0 1 9 3 2 5 5 1 6 2 6 9 5 9 6 7 5 7 1 6 6 2 7 0 5 0 6 5 8 8 8 4 0 5 5\n 7 4 8 3 6 0 9 1 3 9 1 5 4 4 2 9 9 2 2 9 5 1 7 0 0 3 3 1 2 6 1 3 0 5 4 5 9\n 9 4 6 4 8 0 8 4 6 5 4 7 2 6 9 9 3 2 7 0 1 9 0 6 1 5 9 0 1 7 4 7 6 5 6 1 9\n 2 0 1 4 3 7 6 2 4 7 8 6 1 3 1 8 1 7 5 1 2 8 2 0 0 9 8 2 7 0 8 5 0 2 8 3 6\n 0 9 1 4 7 9 8 4 1 7 3 9 1 8 8 8 6 1 1 9 0 8 0 8 0 6 4 1 9 6 8 1 2 6 7 6 8\n 5 1 9 5 1 7 5 4 1 5 3 4 0 7 6 0 9 8 1 8 2 8 0 4 1 3 4 2 7 6 0 4 9 6 5 6 5\n 2 5 4 7 5 4 0 5 8 3 5 4 2 4 1 2 8 8 2 4 2 0 9 3 9 6 7 4 9 1 2 7 6 5 3 4 8\n 2 4 7 4 9 7 5 1 9 9 8 4 4 7 6 1 2 5 9 9 3 3 5 5 1 2 5 2 7 7 7 4 0 9 9 7 0\n 1 8 3 5 6 7 4 0 4 7 1 7 4 8 4 6 2 7 9 0 2 4 2 2 6 0 6 1 0 5 5 7 9 7 0 4 8\n 1 7 6 9 5 2 9 9 9 2 1 6 2 7 9 3 4 7 7 5 2 5 8 8 8 9 2 3 1 4 0 6 3 8 2 2 7\n 2 3 7 7 8 5 8 7 1 3 6 7 5 3 3 7 4 7 9 5 9 4 5 3 3 3 3 9 1 2 7 6 2 9 8 2 5\n 1 6 7 5 9 5 6 4 2 1 2 9 5 6 6 3 7 3 8 0 4 7 9 6 1 3 5 2 6 9 0 6 7 9 2 3 1\n 6 3 8 4 2 5 5 2 3 1 3 8 3 1 7 9 1 3 9 5 8 8 3 2 2 8 0 7 2 3 1 6 3 6 8 7 1\n 8 6 9 0 1 1 0 0 5 6 3 9 0 4 0 6 1 0 1 8 4 1 6 4 8 3 3 4 4 5 7 9 2 9 8 8 7\n 4 4 5 8 3 2 6 9 1 5 4 7 3 8 3 9 5 8 2 9 1 0 8 3 4 6 0 5 5 2 2 8 9 0 9 6 7\n 0 9 0 9 5 1 0 1 2 7 8 0 8 6 2 9 9 4 7 9 4 5 8 1 2 1 7 4 0 2 8 4 2 3 6 6 2\n 0 1 3 5 2 5 3 8 0 2 5 9 2 7 0 5 3 5 2 4 9 4 3 8 5 0 2 8 8 8 8 4 0 5 7 0 0\n 3 3 1 1 2 8 8 1 0 9 7 5 3 8 2 3 9 9 9 2 9 2 7 5 8 0 4 8 1 3 8 8 3 0 4 1 0\n 1 7 9 2 4 5 0 6 6 3 2 2 9 3 1 4 7 8 0 8 9 3 3 4 6 0 5 9 6 6 6 6 4 2 7 1 7\n 9 8 5 5 6 0 1 1 0 0 5 8 0 4 7 7 0 7 2 4 7 3 8 1 5 6 0 8 4 6 6 9 2 8 4 4 9\n 9 6 3 4 6 5 8 0 5 3 2 6 6 0 4 3 3 2 2 1 5 7 6 6 7 8 8 7 7 6 2 0 1 0 8 5 3\n 6 0 6 9 6 5 9 2 2 4 4 4 0 7 8 1 3 3 2 7 6 0 6 0 7 7 1 4 7 2 9 9 6 4 3 1 8\n 5 6 7 5 0 8 6 8 9 5 2 9 5 5 2 1 3 6 7 8 5 4 3 0 6 7 9 2 8 7 0 1 4 1 1 0 0\n 8]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 5.e-07  0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00\n -0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00\n -0.e+00  0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00\n -0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00  0.e+00  0.e+00]\nOptimal Î¸: 4.999994179233909e-07\nModel for digit 9 saved at /kaggle/working/models/\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"### Testing","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport pickle\nimport matplotlib.pyplot as plt\n\n#------------------------------------------\n# Define the rational function\ndef rational_function(x, alpha, beta):\n    \"\"\"\n    r(x) = (Î±_0 + Î±_1*x1**1 + Î±_2*x2**2 + ...) / \n           (Î²_0 + Î²_1*x1**1 + Î²_2*x2**2 + ...).\n    \"\"\"\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n#------------------------------------------\n# Load MNIST test data (10,000 images)\nfrom keras.datasets import mnist\n(_, _), (x_test, y_test) = mnist.load_data()\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#------------------------------------------\nsubset_size = 10000\n# Subset the test dataset\nx_test_subset = x_test[:subset_size]\ny_test_subset = y_test[:subset_size]\nprint(f\"Shape of test subset: {x_test_subset.shape}\")\n\n#------------------------------------------\n# Flatten the test dataset (convert from 28x28 to 784)\nx_test_subset = x_test_subset.reshape(x_test_subset.shape[0], -1)\nprint(f\"Shape of flattened test subset: {x_test_subset.shape}\")\n\n#------------------------------------------\n# Load PCA instance\nwith open(\"models/pca_model.pkl\", \"rb\") as file:\n    pca = pickle.load(file)  # Load the PCA model trained on training data\n    \nx_test_pca = pca.transform(x_test_subset)  # Transform test data using the saved PCA\n\nprint(f\"Shape of PCA-transformed test subset: {x_test_pca.shape}\")\n\n# # Apply PCA to test data\n# n_components = 77  # Desired number of components\n# pca = PCA(n_components=n_components)\n# x_test_pca = pca.fit_transform(x_test_subset)\n\n#------------------------------------------\n# Thresholding: Convert PCA-transformed data to binary (0s and 1s)\nthreshold_value = 0\nx_test_binary = (x_test_pca > threshold_value).astype(int)\nprint(f\"Binary thresholded test subset: {x_test_binary.shape}\")\n\n#------------------------------------------\n# Load the saved models and test\nmodels_dir = \"/kaggle/working/models/\"  # Update based on your environment\naccuracies = []\n\nfor digit in range(10):\n    # Load model for each digit\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n    theta = model[\"theta\"]\n\n    # Evaluate the rational function for each test data point\n    y_predicted = [\n        rational_function(x, alpha, beta) for x in x_test_binary\n    ]\n\n    # Convert predictions to binary (1 for this digit, 0 for others)\n    y_pred_binary = np.array(y_predicted) > 0.5\n    y_true_binary = y_test_subset == digit\n\n    # Calculate accuracy for this digit\n    accuracy = np.mean(y_pred_binary == y_true_binary)\n    accuracies.append(accuracy)\n\n    print(f\"Accuracy for digit {digit}: {accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Calculate and print overall accuracy\noverall_accuracy = np.mean(accuracies)\nprint(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Plotting accuracies for each digit\nplt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\nplt.xlabel(\"Digits\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy for Each Digit\")\nplt.xticks(range(10))\nplt.ylim(0, 1)\nplt.legend()\nplt.grid(True)\nplt.show()\n\nprint(f\"y_pred_binary =\", y_pred_binary)\nprint(f\"y_true_binary =\", y_true_binary)\n\nprint(f\"y_pred_binary.shape =\", y_pred_binary.shape)\nprint(f\"y_true_binary.shape =\", y_true_binary.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T02:11:35.973582Z","iopub.execute_input":"2024-12-16T02:11:35.974279Z","iopub.status.idle":"2024-12-16T02:11:49.948984Z","shell.execute_reply.started":"2024-12-16T02:11:35.974239Z","shell.execute_reply":"2024-12-16T02:11:49.948151Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nx_test shape: (10000, 28, 28), y_test shape: (10000,)\nShape of test subset: (10000, 28, 28)\nShape of flattened test subset: (10000, 784)\nShape of PCA-transformed test subset: (10000, 20)\nBinary thresholded test subset: (10000, 20)\nAccuracy for digit 0: 90.20%\nAccuracy for digit 1: 88.65%\nAccuracy for digit 2: 89.68%\nAccuracy for digit 3: 89.90%\nAccuracy for digit 4: 90.18%\nAccuracy for digit 5: 91.08%\nAccuracy for digit 6: 90.42%\nAccuracy for digit 7: 89.72%\nAccuracy for digit 8: 90.26%\nAccuracy for digit 9: 10.09%\nOverall Accuracy: 82.02%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"y_pred_binary = [ True  True  True ...  True  True  True]\ny_true_binary = [False False False ... False False False]\ny_pred_binary.shape = (10000,)\ny_true_binary.shape = (10000,)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Debugging: Check rational function output for a specific index\nspecific_index = 333  # Change this to the desired index\nif specific_index < len(x_b):\n    rational_output = rational_function(x_b[specific_index], optimal_alpha, optimal_beta)\n    prediction = 1 if rational_output > 0.5 else 0  # Binary prediction\n    b_label = y_binary[specific_index]  # Actual label (0 or 1)\n    actual_label = y_subset[specific_index]\n    \n    print(f\"Input at Index {specific_index}: {x_b[specific_index]}\")\n    print(f\"Rational Output: {rational_output:.4f}, b_Label: {b_label}, Prediction: {prediction}, Actual Label:{actual_label}\")\nelse:\n    print(f\"Index {specific_index} is out of bounds. Max index: {len(x_b)-1}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:41:15.600659Z","iopub.status.idle":"2024-12-16T01:41:15.601112Z","shell.execute_reply.started":"2024-12-16T01:41:15.600862Z","shell.execute_reply":"2024-12-16T01:41:15.600885Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ss","metadata":{}},{"cell_type":"code","source":"with open(f\"{models_dir}classifier_8.pkl\", \"rb\") as file:\n    model = pickle.load(file)\n\nalpha = model[\"alpha\"]\nbeta = model[\"beta\"]\ntheta = model[\"theta\"]\n\nx = x_test_binary[80]\nhs = rational_function(x, alpha, beta)\n\n\nprint(f\"hs =\", hs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T01:41:15.602060Z","iopub.status.idle":"2024-12-16T01:41:15.602477Z","shell.execute_reply.started":"2024-12-16T01:41:15.602256Z","shell.execute_reply":"2024-12-16T01:41:15.602280Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"gg","metadata":{}},{"cell_type":"code","source":"def visual_cross_check_rational_function(x_test_subset, x_test_binary, y_test_subset, models_dir):\n    \"\"\"\n    Visual cross-check for rational function output.\n    Displays the selected test image, the actual label, and the rational function's output.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    # Step 1: Create subsets for each digit\n    digit_subsets = {}\n    digit_indices = {}\n    for digit in range(10):\n        indices = np.where(y_test_subset == digit)[0]\n        digit_subsets[digit] = x_test_binary[indices]\n        digit_indices[digit] = indices\n\n    # Step 2: Select digit and index\n    selected_digit = int(input(\"Enter the digit (0-9) to cross-check: \"))\n    if selected_digit not in digit_subsets:\n        print(f\"Invalid digit {selected_digit}.\")\n        return\n\n    print(f\"Number of images for digit {selected_digit}: {len(digit_subsets[selected_digit])}\")\n    selected_index = int(input(f\"Enter the index (0-{len(digit_subsets[selected_digit]) - 1}) to select an image: \"))\n    if selected_index < 0 or selected_index >= len(digit_subsets[selected_digit]):\n        print(f\"Invalid index {selected_index}.\")\n        return\n\n    selected_image_binary = digit_subsets[selected_digit][selected_index]\n    original_image_index = digit_indices[selected_digit][selected_index]\n    selected_image_original = x_test_subset[original_image_index]\n\n    # Step 3: Load the corresponding model\n    with open(f\"{models_dir}classifier_{selected_digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n\n    # Step 4: Evaluate the rational function\n    rational_output = rational_function(selected_image_binary, alpha, beta)\n    prediction = 1 if rational_output > 0.5 else 0\n\n    # Step 5: Display the image, label, and rational function output\n    plt.figure(figsize=(4, 4))\n    plt.imshow(selected_image_original.reshape(28, 28), cmap=\"gray\")  # Reshape to 28x28\n    plt.title(f\"Digit: {selected_digit} | Prediction: {prediction} | Rational Output: {rational_output:.4f}\")\n    plt.axis(\"off\")\n    plt.show()\n\n# Main execution for visual cross-check\nif __name__ == \"__main__\":\n    # Visual cross-check\n    visual_cross_check_rational_function(x_test_subset, x_test_binary, y_test_subset, models_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T02:12:02.674040Z","iopub.execute_input":"2024-12-16T02:12:02.674755Z","iopub.status.idle":"2024-12-16T02:12:14.782320Z","shell.execute_reply.started":"2024-12-16T02:12:02.674718Z","shell.execute_reply":"2024-12-16T02:12:14.781024Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter the digit (0-9) to cross-check:  6\n"},{"name":"stdout","text":"Number of images for digit 6: 958\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the index (0-957) to select an image:  666\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 400x400 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":23}]}
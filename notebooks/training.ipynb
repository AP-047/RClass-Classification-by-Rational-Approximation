{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"####  ðŸCheck Versions","metadata":{}},{"cell_type":"code","source":"# !python --version\n\nimport cupy as cp\ncp.__version__\n\n# !pip show jedi\n# !pip show setuptools\n# !pip show pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:28:09.887952Z","iopub.execute_input":"2024-12-17T18:28:09.888566Z","iopub.status.idle":"2024-12-17T18:28:11.843235Z","shell.execute_reply.started":"2024-12-17T18:28:09.888534Z","shell.execute_reply":"2024-12-17T18:28:11.842368Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'13.3.0'"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"#### ðŸ Set folder","metadata":{}},{"cell_type":"code","source":"import os\n\nmodels_dir = \"/kaggle/working/models/\"  # Kaggle's default working directory\n\n# Ensure the directory exists\nos.makedirs(models_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:28:14.869986Z","iopub.execute_input":"2024-12-17T18:28:14.870550Z","iopub.status.idle":"2024-12-17T18:28:14.874823Z","shell.execute_reply.started":"2024-12-17T18:28:14.870516Z","shell.execute_reply":"2024-12-17T18:28:14.874019Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Preprocessing","metadata":{}},{"cell_type":"code","source":"#1 Import\nfrom keras.datasets import mnist\n(x_train, y_train), (_, _) = mnist.load_data()\nprint(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n\n#2 Flatten\nx_train = x_train.reshape(x_train.shape[0], -1)\nprint(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n\n#3 Subsets\nsubset_size = 1000\nx_train_subset = x_train[:subset_size]\ny_train_subset = y_train[:subset_size]\nprint(f\"x_train_subset shape: {x_train_subset.shape}\")\n\n#4 PCA\nfrom sklearn.decomposition import PCA\nimport pickle\nn_components = 77\npca = PCA(n_components=n_components)\nx_train_pca = pca.fit_transform(x_train_subset)\nprint(f\"x_train_pca shape: \", x_train_pca.shape)\n# Load PCA instance\nwith open(\"models/pca_model.pkl\", \"wb\") as file:\n    pickle.dump(pca, file)  # Save the fitted PCA model\n\n#5 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_train_norm = scaler.fit_transform(x_train_pca)\nprint(f\"x_train_norm shape: {x_train_norm.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:28:32.210390Z","iopub.execute_input":"2024-12-17T18:28:32.210701Z","iopub.status.idle":"2024-12-17T18:28:45.141855Z","shell.execute_reply.started":"2024-12-17T18:28:32.210674Z","shell.execute_reply":"2024-12-17T18:28:45.139728Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nx_train shape: (60000, 28, 28), y_train shape: (60000,)\nx_train shape: (60000, 784), y_train shape: (60000,)\nx_train_subset shape: (1000, 784)\nx_train_pca shape:  (1000, 77)\nx_train_norm shape: (1000, 77)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Step 1: Import Data","metadata":{}},{"cell_type":"code","source":"# from sklearn.datasets import fetch_openml\n# import numpy as np\n\n# # Import MNIST dataset\n# mnist = fetch_openml('mnist_784', version=1)\n# x_full = mnist.data.values  # Full dataset\n# y_full = mnist.target.values.astype(int)  # Labels (0â€“9)\n\n# print(f\"x_full shape: {x_full.shape}, y_full shape: {y_full.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 2: Create Subset","metadata":{}},{"cell_type":"code","source":"# # Create a subset of training data (1000 images per digit)\n# subset_size = 100\n# x_subset = []\n# y_subset = []\n\n# for digit in range(10):\n#     digit_indices = np.where(y_full == digit)[0][:subset_size]\n#     x_subset.append(x_full[digit_indices])\n#     y_subset.append(y_full[digit_indices])\n\n# x_subset = np.vstack(x_subset)\n# y_subset = np.hstack(y_subset)\n\n# print(f\"x_subset shape: {x_subset.shape}, y_subset shape: {y_subset.shape}\")\n# print(f\"Unique labels in y_subset: {np.unique(y_subset)}\")\n# print(f\"x_subset[3].shape: {x_subset[3].shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 3: Apply PCA","metadata":{}},{"cell_type":"code","source":"# from sklearn.decomposition import PCA\n# import pickle\n\n# # Apply PCA to reduce dimensionality\n# n_components = 77\n# pca = PCA(n_components=n_components)\n# x_pca = pca.fit_transform(x_subset)\n\n# # Load PCA instance\n# with open(\"models/pca_model.pkl\", \"wb\") as file:\n#     pickle.dump(pca, file)  # Save the fitted PCA model\n\n# print(f\"Original shape: {x_subset.shape}, PCA shape: {x_pca.shape}\")\n# print(f\"variance retained: {np.sum(pca.explained_variance_ratio_)*100}%\")\n\n# print(f\"shape of x_pca: \", x_pca.shape)\n# print(f\"shape of x_pca[5]: \", x_pca[5].shape)\n\n# print(f\"check any image vector: \", x_pca[5])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 4: Thresholding","metadata":{}},{"cell_type":"code","source":"# # Thresholding: Convert to binary\n# threshold_value = 0\n# x_b = (x_pca > threshold_value).astype(int)\n\n# print(f\"x_b shape: {x_b.shape}\")\n# print(f\"x_b[5] =\", x_b[5])\n\n# print(f\"x_b =\", x_b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 4: Normalizing","metadata":{}},{"cell_type":"code","source":"# from sklearn.preprocessing import MinMaxScaler\n\n# # Normalize PCA-transformed data\n# scaler = MinMaxScaler(feature_range=(0, 1))\n# x_b = scaler.fit_transform(x_pca)\n\n# print(f\"x_b.shape =\", x_b.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 5: Dataset Shuffle","metadata":{}},{"cell_type":"code","source":"# # Shuffle the dataset\n# shuffle_indices = np.arange(len(y_subset))\n# np.random.shuffle(shuffle_indices)\n\n# x_b = x_b[shuffle_indices]\n# y_subset = y_subset[shuffle_indices]\n\n# print(f\"x_b.shape =\", x_b.shape)\n# print(f\"y_subset.shape =\", y_subset.shape)\n\n# print(f\"x_b =\", x_b)\n# print(f\"y_subset =\", y_subset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Step 6: Train Classifiers","metadata":{}},{"cell_type":"code","source":"import pickle\nimport cupy as cp\nimport numpy as np\nfrom scipy.optimize import linprog\nimport matplotlib.pyplot as plt\n\n# Feasibility check function\ndef check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary):\n    num_data_points = x_train_norm.shape[0]\n    num_coefficients = n_components + 1  # (+1 for the first constant terms Î±0 & Î²0)\n    delta = 1e-6  # a small positive value\n\n    # Construct G(x) and H(x) matrices for numerator and denominator\n    G = cp.zeros((num_data_points, num_coefficients))  # Numerator matrix\n    H = cp.zeros((num_data_points, num_coefficients))  # Denominator matrix\n\n    for i in range(num_data_points):\n      G[i, 0] = 1\n      H[i, 0] = 1\n      for j in range(num_coefficients-1):\n        G[i, j+1] = x_train_norm[i, j] ** (j+1)\n        H[i, j+1] = x_train_norm[i, j] ** (j+1)\n\n    # print(f\"G: {G}\")\n    # print(f\"G.shape =\", G.shape)\n    # print(f\"H: {H}\")\n\n    # Construct constraints for Ax <= b\n    A = []\n    b = []\n\n    for i in range(num_data_points):\n        f_plus_z = y_binary[i] + z  # Upper bound\n        f_minus_z = y_binary[i] - z  # Lower bound\n\n        # Constraint 1: (f(xi) - z) * Î²^T H(xi) - Î±^T G(xi) â‰¤ Î¸\n        # (-G(xi))Î±T + (f(xi) - z).H(xi)Î²T + (-1)Î¸ â‰¤ 0\n        constraint_1 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Î±\n        constraint_1[0:num_coefficients] = -G[i]\n        # (2) Coefficients of Î²\n        constraint_1[num_coefficients:2 * num_coefficients] = (f_minus_z) * H[i]\n        # (3) Coefficient of Î¸ (last element)\n        constraint_1[-1] = -1\n        A.append(constraint_1)\n        b.append(0)\n\n        # Constraint 2: Î±^T G(xi) + (-1).(f(xi) + z) * Î²^T H(xi) â‰¤ Î¸\n        # G(xi).Î±T + (-1)(f(xi) - z).H(xi)Î²T + (-1)Î¸ â‰¤ 0\n        constraint_2 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Î±\n        constraint_2[0:num_coefficients] = G[i]\n        # (2) Coefficients of Î²\n        constraint_2[num_coefficients:2 * num_coefficients] = -(f_plus_z) * H[i]\n        # (3) Coefficient of Î¸ (last element)\n        constraint_2[-1] = -1\n        A.append(constraint_2)\n        b.append(0)\n\n        # Constraint 3: Î²^T H(x) â‰¥ Î´\n        # (0)Î±^T + (-H(x)) Î²^T + (0)Î¸ â‰¤ -Î´\n        constraint_3 = cp.zeros(2 * num_coefficients + 1)\n        # Coefficient of Î²\n        constraint_3[num_coefficients:2 * num_coefficients] = -H[i]\n        A.append(constraint_3)\n        b.append(-delta)\n\n    # Convert CuPy arrays to NumPy arrays for SciPy\n    A = cp.asnumpy(cp.array(A))\n    b = cp.asnumpy(cp.array(b))\n\n    # print(f\"A =\", len(A))\n    # print(f\"A: {A[0]}\")\n    # print(f\"A.shape =\", A.shape)\n    # print(f\"len(A[0]): {len(A[0])}\")\n    # print(f\"len(b): {len(b)}\")\n    # print(f\"n_components =\", n_components)\n\n    # Objective function to minimize Î¸\n    c = cp.asnumpy(cp.zeros(2 * num_coefficients + 1))\n    c[-1] = 1  # Only Î¸ has a coefficient in the objective function\n\n    # Solve the linear programming problem (methods: highs, revised simplex)\n    result = linprog(c, A_ub=A, b_ub=b, method=\"highs\")\n\n    # Check feasibility and return results\n    if result.success:\n        alpha_coefficients = result.x[:num_coefficients]\n        beta_coefficients = result.x[num_coefficients:2 * num_coefficients]\n        theta = result.x[-1]\n        return True, alpha_coefficients, beta_coefficients, theta\n    else:\n        return False, None, None, None\n\n\n# Bisection loop\ndef bisection_loop(x_train_norm, y_binary, uL, uH, precision):\n    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n    z_values = []\n\n    while uH - uL > precision:\n        z = (uL + uH) / 2\n        z_values.append(z)\n        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary)\n\n        if feasible:\n            uH = z\n            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n        else:\n            uL = z\n\n    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values\n\n# Train a classifier for each digit\nfor digit in range(10):\n    print(f\"Training classifier for digit {digit}...\")\n\n    # Assign labels: Positive for the current digit, negative for others\n    # y_binary = (y_train_subset == digit).astype(int)\n    y_binary = (y_train_subset == digit).astype(float)\n\n    # Scale binary labels to larger values\n    # Positive class = 2, Negative class = 4\n    y_binary = np.where(y_binary == 1, 2, 4)\n\n    # print(f\"y_binary =\", y_binary)\n    # print(f\"y_train_subset =\", y_train_subset)\n\n    # Bisection parameters\n    uL = 0  # Initial lower bound\n    uH = 500  # Initial upper bound\n    precision = 1e-6 # Precision threshold\n\n    # Run bisection loop\n    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(x_train_norm, y_binary, uL, uH, precision)\n\n    # Print results\n    print(f\"Number of Iterations: {len(z_values)}\")\n    # print(f\"z Values in all Iterations: {z_values}\")\n    print(f\"Optimal z (Maximum Deviation): {optimal_z}\")\n\n    # # Plot convergence of z values\n    # plt.figure(figsize=(8, 6))\n    # plt.plot(range(len(z_values)), z_values, marker='o', linestyle='-')\n    # plt.xlabel(\"Iteration\")\n    # plt.ylabel(\"z Value\")\n    # plt.title(\"Convergence of z Values\")\n    # plt.grid(True)\n    # plt.show()\n\n    print(f\"Optimized Coefficients (Numerator Î±): {optimal_alpha}\")\n    print(f\"Optimized Coefficients (Denominator Î²): {optimal_beta}\")\n    print(f\"Optimal Î¸: {optimal_theta}\")\n    \n    # print(f\"rational_function =\", rational_function(x_train_norm[0], optimal_alpha, optimal_beta))\n\n    # Save the model\n    model = {\n        \"alpha\": optimal_alpha,\n        \"beta\": optimal_beta,\n        \"theta\": optimal_theta,\n        \"n_components\": n_components\n    }\n\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"wb\") as file:\n        pickle.dump(model, file)\n\n    print(f\"Model for digit {digit} saved at {models_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:33:51.009166Z","iopub.execute_input":"2024-12-17T18:33:51.009491Z","iopub.status.idle":"2024-12-17T18:45:37.293514Z","shell.execute_reply.started":"2024-12-17T18:33:51.009464Z","shell.execute_reply":"2024-12-17T18:45:37.292373Z"}},"outputs":[{"name":"stdout","text":"Training classifier for digit 0...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 2.99997123e-06  0.00000000e+00  2.86961614e-11  1.43943562e-11\n  1.84189951e-10  1.02687708e-10  8.87661018e-11  1.11352991e-10\n -2.05692198e-11 -2.16439161e-09  1.61271358e-10  9.29465554e-10\n  6.74584705e-09  4.70383719e-09  1.09576575e-08 -3.20804981e-09\n  1.06254823e-08 -1.25503142e-08 -2.32104980e-08 -8.22661028e-08\n -1.40174297e-08  0.00000000e+00 -8.80806916e-10  4.19446640e-09\n -3.60808480e-09  0.00000000e+00  8.44786043e-09  5.30845059e-10\n  3.36706559e-06 -5.89288076e-09  0.00000000e+00  1.17713960e-09\n  5.88848959e-07 -2.57389394e-09 -1.51300287e-10 -1.49444685e-08\n -2.05245340e-08  3.45962582e-08  0.00000000e+00  0.00000000e+00\n  2.45404912e-09 -1.46727459e-10  0.00000000e+00  1.01323259e-08\n  1.99247879e-06 -1.46501700e-09  2.26890883e-08 -4.32547615e-11\n -3.46822779e-08 -3.35404904e-10  4.48647392e-11  0.00000000e+00\n -6.53622123e-09  5.29871373e-11  2.00007549e-06  1.99988665e-06\n -1.94376337e-10  5.76970093e-02 -1.30965076e-10  2.32152092e-08\n  1.99159694e-06  9.22140174e-10  1.99991262e-06  0.00000000e+00\n -1.38301730e-11 -2.26206412e-11 -5.31611745e-12  1.99992895e-06\n  1.85766641e-11  1.99952299e-06 -4.23120064e-10  0.00000000e+00\n -9.67991993e-08  1.99979774e-06 -4.17515737e-11  1.99996433e-06\n  8.05518821e-11  0.00000000e+00]\nOptimized Coefficients (Denominator Î²): [ 9.99984453e-07  2.15722137e-11 -3.37877040e-12  0.00000000e+00\n  4.43113501e-11  6.84134352e-11  2.98861787e-11  4.66125976e-11\n  9.22820030e-11 -2.31543657e-10  3.59710048e-11  9.13569526e-11\n -5.73367976e-12  2.79937449e-10  2.70277051e-09  2.36680775e-09\n  6.47924907e-13 -4.08490314e-09 -2.40130953e-11  6.80360505e-10\n -6.86686506e-09 -1.14782265e-10  1.63506946e-12  0.00000000e+00\n -3.67178432e-12 -2.48054956e-10  2.17133610e-09 -3.33912427e-10\n  3.41760827e-07  9.16856255e-10  1.00000458e-06 -3.12061271e-11\n  1.47336254e-07 -1.76033437e-10 -3.86965599e-11 -9.46653384e-11\n  1.38928488e-10  2.17791152e-11 -9.41557411e-10  2.92360291e-10\n  6.46586841e-10 -6.92945071e-11  4.43699816e-10  3.03367718e-09\n  8.99926528e-09 -1.95769806e-10 -2.84452450e-11 -5.85894291e-11\n -2.19046639e-11  1.95038089e-10  2.38187593e-11  9.33463312e-10\n  1.28818732e-10 -1.45425297e-12  2.79773036e-11 -3.88096347e-14\n -4.28467239e-11  1.44237490e-02 -2.73410309e-11  1.22945009e-09\n -2.15178567e-09 -1.65172224e-10  4.72046988e-11 -5.40718538e-13\n -0.00000000e+00  4.44266260e-11  3.62268865e-12  0.00000000e+00\n  4.49178771e-12 -1.30405245e-09 -1.02723056e-10 -1.41977644e-08\n -4.83979015e-08  0.00000000e+00 -3.12321033e-11  0.00000000e+00\n -1.52721470e-10  2.68351269e-08]\nOptimal Î¸: 9.999974231966002e-07\nModel for digit 0 saved at /kaggle/working/models/\nTraining classifier for digit 1...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 2.99938632e-06  1.02829274e-09  0.00000000e+00 -4.82101458e-10\n  3.54392732e-11  5.83421046e-10  3.01818107e-09  2.07718245e-09\n -4.71714423e-10 -4.11112031e-09  1.57517398e-07  6.56325018e-10\n  6.60644808e-08  2.35925752e-08  4.45913617e-07 -9.23971774e-08\n -7.66023182e-09  2.58509087e-06 -7.28483975e-08  8.27903395e-08\n  1.99596358e-06  1.99541975e-06  8.81288940e-09  0.00000000e+00\n  2.55822161e-04  0.00000000e+00  1.01539429e-06  1.36394623e-08\n  3.19592419e-07  2.28599414e-04 -9.52204085e-10  2.70129267e-10\n -5.04070803e-08  5.85025032e-09  1.99207501e-06  1.84603039e-06\n  1.94392158e-06  0.00000000e+00  0.00000000e+00  7.58005589e-06\n  7.86769610e-06  1.99944203e-06  0.00000000e+00 -3.84753623e-09\n  0.00000000e+00  1.96617769e-06 -3.41053916e-09  0.00000000e+00\n  1.98820816e-06  1.49517869e-08  1.93578784e-06  0.00000000e+00\n  0.00000000e+00  1.87536122e-07  1.97316326e-06  4.27057569e-11\n  1.99987194e-06  1.99859907e-06 -7.52750469e-09  2.39872081e-06\n  1.98917998e-06 -2.19199768e-08  3.10807062e-08  1.99796064e-06\n  1.97544486e-06  0.00000000e+00  1.99932039e-06  0.00000000e+00\n -3.29535588e-08  1.99502544e-06  0.00000000e+00  0.00000000e+00\n  2.67185597e-06  2.00013349e-06  1.99905777e-06 -5.51575118e-09\n  1.49131244e-10 -8.75877529e-09]\nOptimized Coefficients (Denominator Î²): [ 9.99863343e-07  1.63765677e-10  1.61533468e-10 -1.04534709e-10\n  1.28811179e-10 -1.11885556e-10  5.05477364e-10  3.20710115e-10\n -2.41419994e-10 -5.97355247e-09 -1.06825061e-08  7.51821358e-10\n  1.28151094e-08  5.30425371e-09  1.12123729e-07 -2.16914305e-08\n  8.33630916e-11  1.47525129e-07 -9.12964385e-09  1.22836531e-08\n  0.00000000e+00 -4.75710495e-10 -2.83990979e-10  5.75851319e-09\n  6.34172666e-05  1.61446464e-08  2.53662844e-07  3.19531757e-09\n  7.97503475e-08  5.71826309e-05 -5.88264859e-11  2.59806720e-10\n -1.32524968e-08 -8.11479529e-10 -1.87563900e-09 -3.52949056e-08\n  9.73560771e-12  2.46516403e-08  2.99682390e-07  1.89483794e-06\n  1.47136292e-06  1.51294829e-11  2.42266732e-07  2.95049318e-10\n  3.85031765e-08  0.00000000e+00 -4.02454146e-10  1.12540451e-10\n -2.47474140e-08 -1.64020600e-09  1.04690683e-10  1.38321183e-07\n  1.34795261e-08  5.51971908e-08 -4.01418422e-10 -3.13945856e-11\n -4.75333900e-10 -1.74298966e-10 -1.82836740e-09  0.00000000e+00\n -6.49500756e-10 -5.40852760e-09 -5.02709952e-10 -4.97186238e-10\n -1.02580950e-09  2.56586260e-09  4.74579807e-11  5.86154666e-10\n -4.78541516e-10  0.00000000e+00  8.49554679e-08  0.00000000e+00\n  1.68003218e-07  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  7.00427399e-11 -5.16578141e-10]\nOptimal Î¸: 9.999610726841513e-07\nModel for digit 1 saved at /kaggle/working/models/\nTraining classifier for digit 2...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 3.00010685e-06 -1.60281327e-11  0.00000000e+00 -1.91904218e-09\n  5.04722947e-09  2.60304539e-09 -2.86335602e-09 -4.25107879e-08\n  1.14418923e-09  0.00000000e+00  1.24156384e-07 -1.41716726e-08\n  9.04110697e-08  0.00000000e+00 -1.01637103e-08  1.36505015e-07\n  1.84648410e-07  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -8.30747598e-08 -9.92988212e-10  0.00000000e+00  0.00000000e+00\n  0.00000000e+00 -6.34717801e-08  9.09978670e-07  0.00000000e+00\n  1.09221093e-06  7.32756945e-08  0.00000000e+00  0.00000000e+00\n  1.36651589e-07  0.00000000e+00  3.93031077e-09  1.99947212e-06\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  1.99589857e-06  0.00000000e+00  2.60309826e-06  0.00000000e+00\n  0.00000000e+00  1.97703453e-06  1.58298166e-07  5.24146817e-09\n  5.06548295e-06  0.00000000e+00 -5.50515328e-11  2.18822790e-08\n  0.00000000e+00  0.00000000e+00 -8.28004554e-09  0.00000000e+00\n  0.00000000e+00 -2.13399381e-09  0.00000000e+00  1.43743160e-06\n  0.00000000e+00 -2.90587637e-09  0.00000000e+00  1.99964355e-06\n  1.99530724e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  5.02645943e-08 -9.80997636e-09  0.00000000e+00 -1.66747378e-08\n  0.00000000e+00  0.00000000e+00  2.00035759e-06 -2.75454308e-09\n  2.00101682e-06 -2.49443128e-08]\nOptimized Coefficients (Denominator Î²): [ 9.99911090e-07  1.44786090e-10  2.49868934e-10 -1.71380079e-10\n  1.16209510e-09  3.82501042e-10 -8.78971772e-10 -1.04921515e-08\n  3.92319322e-10  6.84367405e-09  1.13305687e-08 -3.25677532e-09\n  1.41861937e-08  1.98230513e-08 -2.89153037e-09  3.30593213e-08\n  4.60464231e-08  3.22340002e-10  1.75141906e-08 -7.78741839e-10\n -5.78039106e-08  0.00000000e+00 -1.26219435e-08 -3.02946410e-08\n -4.36134057e-09  0.00000000e+00  2.25427756e-07  2.18936989e-10\n  2.73679177e-07  3.45328167e-08 -1.42447920e-10 -2.20910292e-11\n  3.64849416e-08 -1.05708826e-10  7.92263814e-10 -5.43678554e-10\n  4.20659489e-10  1.26745293e-06  0.00000000e+00 -1.98352707e-08\n  0.00000000e+00  1.00117647e-06  6.51814408e-07  1.88677193e-08\n -3.88861551e-09  0.00000000e+00  3.88967761e-08 -1.61844142e-10\n  0.00000000e+00  5.13629921e-10 -1.26001040e-10  1.56601448e-08\n  7.24585094e-09 -1.59191653e-11 -6.52512157e-10 -2.13292636e-10\n -8.17905876e-11 -6.30453121e-10  0.00000000e+00  0.00000000e+00\n  1.53986927e-09 -6.45744787e-10  0.00000000e+00 -4.70984306e-11\n  0.00000000e+00  1.57828081e-09  3.77475745e-11  0.00000000e+00\n  2.55761458e-08 -2.56267064e-09  0.00000000e+00  0.00000000e+00\n  4.47078942e-09 -5.21063708e-09  1.31906030e-10 -3.69120367e-10\n  2.03830794e-10 -6.34153127e-09]\nOptimal Î¸: 9.999786278378918e-07\nModel for digit 2 saved at /kaggle/working/models/\nTraining classifier for digit 3...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 3.00000085e-06  6.75348207e-12  0.00000000e+00  0.00000000e+00\n -7.40648614e-12 -2.38682807e-11  8.63629127e-11 -4.06817117e-11\n  6.21558991e-11 -2.03270125e-09  0.00000000e+00 -2.74051863e-10\n -3.06737174e-10 -4.22952930e-10 -3.67543331e-08 -1.12545812e-08\n  9.27882606e-10 -9.52965603e-10  5.61986302e-09  0.00000000e+00\n -3.62330673e-10 -1.78182699e-08  0.00000000e+00 -2.23944916e-09\n  0.00000000e+00  8.04536962e-08  2.04773939e-09  1.03535213e-08\n  9.02463248e-10  3.88618566e-09  1.99997566e-06  0.00000000e+00\n  1.80456409e-09  0.00000000e+00  2.09536790e-06  0.00000000e+00\n  8.49282278e-05  0.00000000e+00  9.81132083e-11  6.47703810e-07\n  0.00000000e+00  3.18955490e-08 -1.51051466e-10  1.07416406e-08\n  1.24137142e-09  0.00000000e+00  2.00530631e-06  2.00016923e-06\n -1.92125659e-11 -2.92149184e-08  2.73554260e-06  1.99999843e-06\n  2.00036509e-06 -2.69553064e-08  2.43512803e-07  1.57895893e-05\n  1.99995651e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -3.06148948e-11  0.00000000e+00  1.99945944e-06  1.90180121e-07\n  1.99997811e-06  1.99515542e-06  1.99999830e-06  1.98718226e-06\n -2.88811328e-08  0.00000000e+00  1.99999796e-06  0.00000000e+00\n -1.61918387e-08  4.57089336e-07  2.38058835e-07  1.99925569e-06\n  0.00000000e+00  1.99990363e-06]\nOptimized Coefficients (Denominator Î²): [ 9.99999194e-07  8.93960311e-14  4.26158994e-12 -7.80461343e-14\n -5.90300094e-13 -5.24364774e-12  1.07470424e-11 -3.43324539e-12\n  2.91316404e-12 -2.61790504e-10  1.42718133e-11 -1.78351661e-11\n -8.63300495e-11 -1.05271893e-10 -4.45853330e-11 -2.51572454e-09\n  2.32334504e-10  4.13791232e-10 -2.35637407e-11 -3.98197208e-10\n -9.25374782e-11  9.84125044e-12  9.17911375e-12 -1.94840812e-10\n  7.51169790e-09 -6.63770342e-09  1.00215427e-09  3.41545617e-09\n  8.50504424e-10  4.11794808e-10 -9.03839207e-13 -2.71402149e-12\n  1.84505474e-09 -3.17220853e-10  2.38418856e-08 -2.72804157e-11\n  2.07320612e-05 -8.45030850e-10  8.77168106e-09  1.61930331e-07\n -5.46661330e-09  3.85872255e-10 -1.99286780e-10  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  1.32691594e-09  4.14956072e-11\n  0.00000000e+00  0.00000000e+00  1.83834969e-07  2.33570477e-11\n  9.44922401e-11  0.00000000e+00  1.21752079e-07  3.94954009e-06\n  0.00000000e+00  1.70929217e-12  4.37700556e-11 -7.31490472e-09\n -4.48059613e-12  1.03925867e-08 -3.53803708e-12  4.75470966e-08\n  0.00000000e+00 -4.71793718e-10  0.00000000e+00 -2.42376085e-09\n  1.01353272e-09  5.66013968e-10  9.34347398e-10 -7.56823737e-09\n -1.76955454e-12  2.28549500e-07  5.96197883e-08 -2.76605139e-10\n  7.27307877e-11 -3.49917071e-11]\nOptimal Î¸: 9.999989673454646e-07\nModel for digit 3 saved at /kaggle/working/models/\nTraining classifier for digit 4...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 3.00002536e-06 -8.02413487e-11 -2.43486650e-11 -1.10889811e-10\n -4.73559936e-11  5.19650060e-11 -4.10828114e-11  6.50445521e-11\n  6.96927351e-10 -1.01783327e-09  6.19653453e-10  8.58649119e-11\n -3.72979795e-10  1.05740209e-09  7.60051405e-09 -7.33032439e-09\n  6.60807346e-10  1.13263499e-10 -2.68384907e-09  2.00002061e-06\n -7.03663915e-11  1.09165818e-09  1.24464054e-08  1.47216991e-07\n  0.00000000e+00  4.26628398e-08  3.55502284e-09 -6.43959390e-09\n  2.92348586e-08 -2.12039727e-09  2.87818490e-11  1.98880653e-10\n  1.32179879e-10  0.00000000e+00 -1.01817497e-10 -6.03470316e-11\n -2.71967753e-08  3.04956918e-09 -6.99601254e-09  0.00000000e+00\n  9.97384886e-09  2.00012730e-06  1.04223392e-09 -2.75156473e-09\n  1.99764486e-06  0.00000000e+00  0.00000000e+00  3.28639525e-10\n  5.93163954e-10  2.66374224e-08  6.02999117e-07  0.00000000e+00\n  3.13539318e-06  1.99979290e-06  0.00000000e+00 -6.52154257e-10\n  1.99997365e-06  2.00003130e-06  0.00000000e+00  1.95656717e-06\n  2.61264453e-06 -0.00000000e+00  4.55405283e-05  0.00000000e+00\n  0.00000000e+00  1.99870402e-06  3.21387429e-08  4.43163030e-04\n -9.71696493e-10 -5.09372746e-10 -1.79638830e-09  0.00000000e+00\n  1.04833294e-08  1.99505674e-06 -2.70342388e-11  0.00000000e+00\n  3.94951336e-06  0.00000000e+00]\nOptimized Coefficients (Denominator Î²): [ 1.00000525e-06 -1.92395824e-11 -7.85154674e-12 -1.32719627e-11\n  9.56871573e-13  1.22767380e-11 -1.69087537e-11  1.09489035e-11\n  2.80510274e-10  2.17827711e-12  1.68588144e-10  1.33512361e-11\n -4.15672810e-11  3.71961837e-10 -6.22471306e-11  1.50382999e-11\n  1.02946925e-11  3.96162864e-11  8.49553601e-10  1.42791460e-11\n  0.00000000e+00  2.68808587e-10  3.14892731e-09 -1.31215002e-09\n -5.52373636e-08  1.17385111e-11  1.14899360e-10 -0.00000000e+00\n  7.37779420e-09 -1.33357767e-09  1.70292715e-12  9.52172988e-11\n  1.15791228e-12  1.85648911e-10 -5.41933804e-11  2.52615418e-10\n -1.59631032e-09  1.01134750e-09 -1.04586998e-08 -1.12381485e-10\n -1.31522274e-10  0.00000000e+00 -2.17554047e-11 -1.79107798e-10\n  6.18696687e-08  3.73317734e-10 -0.00000000e+00 -0.00000000e+00\n -1.80522794e-11 -7.90503794e-12 -5.03029917e-09 -1.38464073e-11\n  2.84110640e-07  8.08090511e-10 -5.55118725e-12 -1.69518175e-10\n -1.67218082e-11 -0.00000000e+00  1.30440747e-11  0.00000000e+00\n  1.53929429e-07 -3.73098360e-10  1.08882212e-05 -4.22720951e-12\n -5.17814657e-12 -2.39005452e-11  1.60709054e-08  1.10791179e-04\n  6.10677822e-10  1.17559165e-11  0.00000000e+00 -6.95535119e-09\n  4.55934667e-09 -1.23004349e-09 -0.00000000e+00  1.19212159e-10\n  4.87372926e-07  0.00000000e+00]\nOptimal Î¸: 9.999984273047731e-07\nModel for digit 4 saved at /kaggle/working/models/\nTraining classifier for digit 5...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 0.0009546056389808655\nOptimized Coefficients (Numerator Î±): [ 3.00001274e-06  2.08223075e-11  0.00000000e+00  0.00000000e+00\n -8.58234958e-11  2.02211242e-10 -1.82642889e-10 -2.16157613e-10\n -3.21903074e-10  5.82154144e-09  0.00000000e+00 -3.88426234e-09\n -1.33492551e-08  5.88820784e-10 -1.78306698e-08  1.41816298e-09\n  4.41729163e-09  0.00000000e+00 -8.60755462e-09  7.78944806e-08\n -2.26042928e-08  7.48098230e-11 -4.72061726e-10  3.62944522e-09\n -1.36857458e-09  1.81127194e-09 -4.90627487e-10  0.00000000e+00\n -1.19077845e-09  9.17786203e-08  8.98642916e-07 -1.02948090e-09\n  5.77152300e-09  2.57547891e-09  0.00000000e+00  2.00064617e-06\n  1.23355379e-10  3.83222768e-08  0.00000000e+00 -5.09913813e-10\n -5.15849007e-08 -9.47047671e-11  1.46321871e-09  1.84872911e-08\n  1.74525892e-06  3.10251218e-09 -2.74499989e-11  1.17740847e-10\n -3.83131968e-08  2.01025888e-06  2.00030013e-06  0.00000000e+00\n  1.36748769e-08  3.92575750e-08  2.00000882e-06 -1.85823834e-09\n  0.00000000e+00  3.90560963e-12  1.99995259e-06  2.01437837e-06\n  0.00000000e+00  1.96775166e-06 -5.30341005e-09  1.01457664e-07\n  1.55075006e-09 -7.71020668e-10  2.00000491e-06  0.00000000e+00\n -3.47514570e-10 -1.04108110e-09  0.00000000e+00  0.00000000e+00\n  1.71313872e-09  1.99982091e-06 -1.12336910e-09 -6.40915376e-08\n  0.00000000e+00  1.99997053e-06]\nOptimized Coefficients (Denominator Î²): [ 1.00000396e-06  0.00000000e+00  6.87599036e-12 -5.74359449e-12\n -8.25672020e-12 -3.59826603e-11 -3.37370855e-11 -2.80986730e-11\n -9.91534738e-11  1.64255280e-09  4.79456564e-11 -9.21001632e-10\n -2.65816173e-09  7.00250906e-11 -7.13882234e-11  5.98053294e-10\n  2.21439799e-09 -4.48826541e-09 -4.22965703e-09 -4.29889858e-10\n -1.01774592e-08  1.86994727e-11 -1.16590465e-10  0.00000000e+00\n  4.03005896e-12  4.86089474e-10 -1.58102615e-11 -1.92553831e-11\n  1.81023589e-10  2.31929601e-08  2.24751724e-07 -1.84816057e-11\n  1.55236163e-09  6.79591927e-10 -2.42829220e-12  1.88486952e-10\n  2.16853163e-11  0.00000000e+00 -1.03966208e-08 -5.58829945e-11\n -1.26076706e-08  0.00000000e+00  3.09878021e-09  5.16334205e-09\n  4.14255140e-09  4.66888034e-10 -3.38446024e-12  2.51445633e-11\n -2.12669396e-12  2.58092615e-09  4.79069797e-11  1.00060430e-06\n  2.86057730e-09 -7.09260356e-09  2.74406648e-11 -2.97924866e-12\n  3.35624893e-08 -0.00000000e+00  2.31166129e-11  1.44444986e-08\n  1.29796002e-10  2.68970713e-11  0.00000000e+00  2.53718095e-08\n  8.07013729e-10 -1.75069153e-10  1.08164659e-12  0.00000000e+00\n -4.36478329e-11 -2.54933065e-10  0.00000000e+00 -2.90358881e-09\n  4.28366352e-10  0.00000000e+00  1.73316082e-11  5.20567679e-12\n  1.30784645e-11  1.43495778e-12]\nOptimal Î¸: 9.99044975765092e-07\nModel for digit 5 saved at /kaggle/working/models/\nTraining classifier for digit 6...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 2.99998858e-06  3.73508069e-12  1.89875295e-11  9.03590066e-12\n  0.00000000e+00 -3.90299244e-11  6.39678418e-11 -1.60641031e-10\n -6.46276904e-11 -1.36151591e-09  2.72850857e-10 -4.63021367e-11\n -8.78312754e-10 -2.24124459e-09  3.02437284e-09 -6.21750325e-09\n  1.24197763e-09  5.44614301e-08 -5.66623960e-10 -2.88235507e-08\n -2.27659666e-10 -5.29514600e-08  2.60363983e-09  0.00000000e+00\n -5.73649762e-10 -3.36939968e-08 -1.87197641e-08  1.62654964e-08\n  2.45248454e-07  5.40186585e-08 -3.82918961e-11 -4.87542933e-09\n  0.00000000e+00  6.93778969e-07  7.01772847e-09  1.76260080e-09\n  3.03648522e-07  1.92157075e-06  0.00000000e+00  8.44283205e-10\n  1.98004861e-06 -4.75329523e-08  2.10963529e-10 -1.66469645e-09\n  0.00000000e+00 -2.72773899e-08  6.94914530e-10  1.85962475e-06\n  6.85853849e-08 -1.02900889e-08  3.68453562e-07  2.00007131e-06\n -2.11322885e-09  1.99998065e-06  1.89193311e-06  1.99999961e-06\n  0.00000000e+00 -3.85426243e-11  2.74260569e-06  1.44491132e-06\n  1.27742667e-08  1.99099890e-06 -1.23942124e-08  2.00272793e-06\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  3.48555228e-07  3.06953246e-06  1.65804579e-06  2.27995625e-09\n  1.77823442e-03  0.00000000e+00  1.99160068e-06  1.36582385e-03\n  2.13678365e-06 -5.39102370e-09]\nOptimized Coefficients (Denominator Î²): [ 9.99999557e-07  9.45208738e-13  2.58273553e-12  2.24697054e-12\n -6.47700060e-12 -7.60417649e-12  1.36676801e-12 -3.23784441e-11\n -4.02364512e-12 -3.82516816e-10 -1.98714564e-10 -5.33386674e-11\n -1.74651135e-10 -2.15383817e-10 -3.03135902e-12 -1.52956884e-09\n  3.29993715e-10  1.39982396e-08 -2.31033351e-11  2.39663145e-09\n  1.26402602e-11 -1.65636224e-08  6.82236313e-10 -2.66942655e-11\n  1.90202355e-10  1.63586901e-10 -3.83625584e-09  3.99944885e-09\n  2.67618144e-08  1.34555407e-08 -1.65678943e-12 -4.63638109e-10\n  7.79571515e-11  1.73442565e-07  1.75223683e-09  0.00000000e+00\n  1.92830521e-10  0.00000000e+00 -1.32817854e-08 -1.54692904e-10\n -4.97676819e-09  6.16260277e-10  0.00000000e+00 -5.13144207e-10\n  9.57333467e-09 -5.89303631e-09  1.64618496e-11 -3.50940820e-08\n -2.44725678e-09 -2.52467910e-09  0.00000000e+00 -2.67368553e-12\n  1.77606380e-10 -5.31456232e-12 -2.69990576e-08 -5.97962322e-13\n -2.09919917e-11  4.03218420e-12  6.86522389e-07  1.19784939e-08\n  3.84082571e-09  0.00000000e+00  0.00000000e+00  6.80142163e-10\n  1.12524423e-11  1.27426638e-10 -1.30429862e-12  8.85494630e-13\n -2.11644138e-10  2.67373549e-07  0.00000000e+00 -9.39600611e-09\n  4.44058504e-04  1.97261804e-09 -1.82884339e-09  3.40972026e-04\n  3.41954164e-08 -4.78761747e-11]\nOptimal Î¸: 9.999989154189426e-07\nModel for digit 6 saved at /kaggle/working/models/\nTraining classifier for digit 7...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 2.99999712e-06 -8.99963746e-11 -3.69759828e-10 -1.26359650e-10\n  9.97882302e-10 -9.05841223e-10  1.97827481e-09 -8.85537593e-10\n -4.98740363e-10  0.00000000e+00  4.02339545e-09 -8.73699328e-09\n  1.73410360e-08 -2.85348438e-08  0.00000000e+00  3.88128656e-08\n  9.69036626e-07  7.42433302e-07 -2.70618634e-08 -6.64521146e-11\n  3.30468204e-08  8.13459508e-08  2.22429307e-08 -7.11102541e-09\n  0.00000000e+00 -6.51724810e-08  1.79172603e-07 -7.81849415e-09\n  2.39900413e-08  0.00000000e+00  2.00016406e-06  3.44377462e-06\n  0.00000000e+00  5.03104179e-07  1.99999222e-06  0.00000000e+00\n -2.32416803e-10  8.83198777e-10  3.20386974e-09  2.76855070e-08\n  1.99986984e-06 -7.66633886e-09  2.00319576e-06  1.98146034e-06\n  2.01036823e-06 -1.53672498e-08  2.00187521e-06  1.99728089e-06\n -1.08802858e-09  0.00000000e+00  1.99535971e-06  1.99094300e-06\n -1.79777048e-08  1.99988982e-06  0.00000000e+00  0.00000000e+00\n -4.38564495e-09  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -3.28984126e-09  1.98638679e-06 -4.30389493e-09  0.00000000e+00\n  0.00000000e+00 -2.29614280e-08  0.00000000e+00  2.00073342e-06\n  2.00048561e-06  1.99548314e-06  0.00000000e+00  0.00000000e+00\n -1.22808082e-10  0.00000000e+00  1.99276790e-06  1.93562374e-06\n -7.39862191e-11 -1.90469675e-10]\nOptimized Coefficients (Denominator Î²): [ 9.99991951e-07 -5.85285579e-11  5.12061881e-11 -1.11580475e-11\n  4.52560800e-11 -8.55250094e-12  3.08575247e-10  2.79623727e-10\n -1.79092215e-10 -4.40232010e-10 -8.30096902e-11 -4.34142086e-09\n  5.64137765e-09 -5.63870885e-10  1.18597052e-07  1.01863934e-08\n  2.42250659e-07  1.87596149e-07 -6.76018223e-09  3.75076124e-11\n -1.92764465e-11  2.05278242e-08 -2.99567014e-10 -2.56741133e-09\n  8.39655682e-09  5.08023342e-11 -2.00688052e-10 -1.66498184e-09\n -3.28365758e-08  4.70338094e-08  0.00000000e+00  3.61517528e-07\n -1.52741803e-10 -8.68511858e-10 -1.18720859e-11  1.67134443e-08\n -9.74106589e-12  2.42992284e-10  0.00000000e+00  4.22411983e-10\n  0.00000000e+00 -4.26579743e-11  0.00000000e+00 -1.56947790e-11\n  0.00000000e+00 -4.78524291e-09  0.00000000e+00 -6.69997687e-10\n -1.98467291e-10  4.58916336e-09 -4.64206651e-10 -1.23209368e-11\n -5.72769736e-09 -1.30042242e-10  7.48680313e-11  2.13218615e-09\n  0.00000000e+00 -3.47641767e-11  6.65381770e-12  1.37856676e-07\n -2.05609098e-11 -1.07827927e-09  4.27513592e-11  2.00723380e-11\n  3.86436317e-11 -6.09352647e-09 -3.94150514e-11 -2.29949062e-10\n  0.00000000e+00 -4.07999410e-11  8.54714927e-08 -6.32862317e-09\n -1.49896208e-11  0.00000000e+00 -1.39510565e-10  0.00000000e+00\n  2.48390281e-11 -5.07667314e-11]\nOptimal Î¸: 9.999927532532813e-07\nModel for digit 7 saved at /kaggle/working/models/\nTraining classifier for digit 8...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 3.00000199e-06 -1.56271326e-11  0.00000000e+00  1.59872268e-11\n -9.43137368e-12  3.49943544e-11  2.58988082e-11 -4.67765378e-10\n  3.41501409e-10 -1.41990818e-09  1.78633611e-10  1.50736295e-10\n -1.14952070e-09 -7.09357144e-10  0.00000000e+00 -6.61402577e-10\n -8.41383250e-10 -1.67763318e-09  5.11358490e-10  2.27283455e-08\n -6.84593179e-09 -3.55388877e-09 -2.34443016e-09  1.91934868e-09\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.24825335e-09\n -3.62288808e-09 -1.98085837e-09  0.00000000e+00 -3.15568592e-08\n -2.43522372e-09  0.00000000e+00  1.99829488e-06  0.00000000e+00\n -7.09138579e-11  0.00000000e+00  1.39827761e-05  0.00000000e+00\n  1.10838008e-09 -8.42822016e-11  3.53266848e-08  1.04415638e-10\n  0.00000000e+00  2.00940555e-06 -1.85145117e-09  8.03531855e-08\n  2.09791515e-06 -6.97955376e-10  9.80077752e-11  1.99619172e-06\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -3.02150035e-11  0.00000000e+00\n -7.50164703e-10  2.00152327e-06  1.99941805e-06  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  2.00002816e-06  0.00000000e+00\n  2.00279558e-06  0.00000000e+00  1.64870407e-10  8.55295490e-03\n  1.99992052e-06  0.00000000e+00 -1.43606568e-09 -2.83568424e-08\n  2.00226212e-06  0.00000000e+00]\nOptimized Coefficients (Denominator Î²): [ 1.00000017e-06 -3.24420379e-12 -6.95086518e-13  3.03450044e-12\n  2.43926073e-12  1.31096673e-11 -1.25314084e-11 -1.17861904e-10\n  7.81273300e-11 -4.10427376e-10  4.93326900e-11  7.80904881e-11\n -2.11469353e-10 -1.95348822e-10  5.18207115e-12  1.32158915e-10\n -3.82365847e-10 -4.87449876e-10  3.55216097e-11 -7.34048167e-10\n -1.49568958e-09  5.96234375e-12  2.50588683e-09  4.02765566e-10\n  6.19466666e-10  1.29804547e-08 -5.47543520e-11 -1.47911854e-11\n  0.00000000e+00 -3.24454254e-10 -2.85831659e-10 -4.94444346e-09\n -8.36106168e-12 -1.34267324e-08 -3.51987032e-10  1.94716810e-10\n  2.87697446e-11  2.44041218e-08 -5.31488440e-07  2.16730433e-11\n  5.22492339e-10 -2.37389190e-11  1.04866495e-08  2.50155381e-11\n  2.13774083e-03  2.28298719e-09  4.40692965e-10  2.01126881e-08\n  7.54266053e-11  4.71907480e-11 -0.00000000e+00 -1.18578256e-09\n -1.29790444e-10 -3.48916938e-10 -2.53104588e-11  0.00000000e+00\n  2.54164178e-10 -1.58721096e-08 -6.17292015e-11  3.52823602e-06\n -1.42840524e-10  3.77624638e-10  2.66557064e-11 -1.12440403e-12\n -4.29860702e-12 -8.83537400e-12  6.29072579e-12  0.00000000e+00\n  5.75412313e-10  2.28844427e-12  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  3.92855926e-11  0.00000000e+00\n -0.00000000e+00 -5.79336124e-12]\nOptimal Î¸: 9.999984226473375e-07\nModel for digit 8 saved at /kaggle/working/models/\nTraining classifier for digit 9...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Î±): [ 2.99995155e-06 -1.50939955e-11  8.20439476e-11  7.90747529e-12\n -4.83549229e-10  1.66016429e-10  4.11619183e-10 -7.59029256e-10\n  1.78246045e-09  4.14288399e-08  5.73581780e-09 -9.46246044e-10\n -8.26615364e-10 -1.74630995e-09 -1.37658937e-08 -3.03138819e-08\n  3.49068275e-08  7.25450960e-08 -6.50786502e-09  3.91216846e-07\n -2.43969191e-10  5.40141722e-08  1.09041449e-08  1.10786086e-08\n  9.60345565e-07  0.00000000e+00  0.00000000e+00  1.23221565e-08\n  6.29437705e-07  0.00000000e+00  0.00000000e+00  3.59577894e-08\n  1.69158930e-07 -4.98161901e-10  5.44040400e-11 -1.26238444e-10\n  4.74076391e-06 -1.94442401e-08  1.83373601e-06  1.24790499e-09\n  2.90648251e-11 -1.74719526e-10  6.87391553e-08  4.20264499e-08\n  0.00000000e+00  0.00000000e+00 -1.35158017e-09  0.00000000e+00\n  2.01961428e-06 -4.20516759e-09  0.00000000e+00  1.99983294e-06\n  1.25277151e-03  4.32900866e-06  1.99828642e-06  1.87992980e-08\n  1.99965508e-06 -3.78067788e-10 -1.59886195e-10  2.47191187e-07\n  7.82818520e-06  1.95057759e-06  0.00000000e+00  0.00000000e+00\n -5.79821973e-10  1.99482856e-06  2.00010016e-06 -1.41629167e-09\n -1.34963846e-09  1.99966564e-06  2.00001199e-06  1.88464363e-06\n  2.24440204e-07  1.99972929e-06  1.99870240e-06  0.00000000e+00\n  1.08542608e-10  1.99926503e-06]\nOptimized Coefficients (Denominator Î²): [ 1.00000128e-06 -1.67691370e-11  2.26060120e-12  1.22585059e-11\n  1.90405293e-11 -6.55648551e-11 -2.93009647e-11 -1.57574280e-10\n  6.58876754e-11  4.29126697e-09  2.77990469e-10 -3.32651391e-10\n -3.92909270e-10 -8.02609676e-11 -9.35099005e-10 -5.53441893e-10\n -4.93069885e-11 -1.53891506e-09  6.69600276e-10 -8.33673683e-09\n  2.06729332e-12  1.32669277e-08  3.16140438e-09 -1.95732548e-09\n  2.10885664e-07 -1.78327070e-11  2.94195726e-10  2.60067922e-09\n  1.56439489e-07  1.79631717e-09  1.09844560e-10 -8.06098605e-10\n  2.93546919e-08  1.91945774e-11  4.84870649e-11  2.38224680e-13\n  1.18434017e-06  0.00000000e+00  2.28576804e-08  0.00000000e+00\n  6.31351266e-11  1.39452313e-12  2.67743857e-08  1.04609724e-08\n  0.00000000e+00  4.07803935e-10  1.96696779e-11 -1.01988514e-10\n  1.06480115e-10 -1.66282127e-09  2.53571671e-12 -8.54633065e-12\n  3.13193153e-04  1.08268516e-06 -8.44257695e-11  2.17629139e-09\n -4.32495262e-11 -5.47029154e-11  1.79006108e-11  0.00000000e+00\n  1.45680431e-06 -4.23704607e-09  6.68757342e-09 -3.03706124e-12\n -6.05009660e-12 -4.44262215e-10  6.51085813e-12 -3.32365665e-10\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  7.78104814e-12 -6.18798263e-11  2.27287316e-11  0.00000000e+00\n  1.30235683e-11  0.00000000e+00]\nOptimal Î¸: 9.999969909017537e-07\nModel for digit 9 saved at /kaggle/working/models/\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### [Testing]","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport pickle\nimport matplotlib.pyplot as plt\n\n#------------------------------------------\n# Define the rational function\ndef rational_function(x, alpha, beta):\n    \"\"\"\n    r(x) = (Î±_0 + Î±_1*x1**1 + Î±_2*x2**2 + ...) / \n           (Î²_0 + Î²_1*x1**1 + Î²_2*x2**2 + ...).\n    \"\"\"\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n# #------------------------------------------\n# #1 Load MNIST test data (10,000 images)\n# from keras.datasets import mnist\n# (_, _), (x_test, y_test) = mnist.load_data()\n# print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n# #------------------------------------------\n# #2 Subset the test dataset\n# subset_size = 10000\n# x_test_subset = x_test[:subset_size]\n# y_test_subset = y_test[:subset_size]\n# print(f\"Shape of test subset: {x_test_subset.shape}\")\n\n# #------------------------------------------\n# # Flatten the test dataset (convert from 28x28 to 784)\n# x_test_subset = x_test_subset.reshape(x_test_subset.shape[0], -1)\n# print(f\"Shape of flattened test subset: {x_test_subset.shape}\")\n\n# #------------------------------------------\n# #3 Load PCA instance\n# with open(\"models/pca_model.pkl\", \"rb\") as file:\n#     pca = pickle.load(file)  # Load the PCA model trained on training data\n    \n# x_test_pca = pca.transform(x_test_subset)  # Transform test data using the saved PCA\n\n# print(f\"Shape of PCA-transformed test subset: {x_test_pca.shape}\")\n\n# #------------------------------------------\n# # #4 Thresholding: Convert PCA-transformed data to binary (0s and 1s)\n# # threshold_value = 0\n# # x_test_binary = (x_test_pca > threshold_value).astype(int)\n# # print(f\"Binary thresholded test subset: {x_test_binary.shape}\")\n\n# #------------------------------------------\n# #4 Normalize PCA-transformed data\n# from sklearn.preprocessing import MinMaxScaler\n\n# scaler = MinMaxScaler(feature_range=(0, 1))\n# x_test_norm = scaler.fit_transform(x_test_pca)\n\n# #------------------------------------------\n# #5 Shuffle the dataset\n# shuffle_indices = np.arange(len(y_test_subset))\n# np.random.shuffle(shuffle_indices)\n\n# x_test_shuf = x_test_norm[shuffle_indices]\n# y_test_subset = y_test_subset[shuffle_indices]\n\n#------x-x-x--------\n#------x-x-x--------\n# Import\nfrom keras.datasets import mnist\n(_, _), (x_test, y_test) = mnist.load_data()\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#1 Flatten\nx_test = x_test.reshape(x_test.shape[0], -1)\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#2 Subsets\nsubset_size = 10000\nx_test_subset = x_test[:subset_size]\ny_test_subset = y_test[:subset_size]\nprint(f\"x_test_subset shape: {x_test_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\nimport pickle\nn_components = 77\npca = PCA(n_components=n_components)\nx_test_pca = pca.fit_transform(x_test_subset)\nprint(f\"x_test_pca shape: \", x_test_pca.shape)\n\n# # with training settings\n# with open(\"models/pca_model.pkl\", \"rb\") as file:\n#     pca = pickle.load(file)  # Load the PCA model trained on training data\n    \n# # Transform test data using the saved PCA\n# x_test_pca = pca.transform(x_test_subset)\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_test_norm = scaler.fit_transform(x_test_pca)\nprint(f\"x_test_norm shape: {x_test_norm.shape}\")\n\n#------------------------------------------\n# Load the saved models and test\nmodels_dir = \"/kaggle/working/models/\"  # Update based on your environment\naccuracies = []\n\n#------------------------------------------\nfor digit in range(10):\n    # Load model for each digit\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n    theta = model[\"theta\"]\n\n    # Evaluate the rational function for each test data point\n    y_predicted = [\n        rational_function(x, alpha, beta) for x in x_test_norm\n    ]\n\n    # Convert predictions to binary (1 for this digit, 0 for others)\n    y_pred_binary = np.array(y_predicted) < 3\n    y_true_binary = y_test_subset == digit\n\n    # Calculate accuracy for this digit\n    accuracy = np.mean(y_pred_binary == y_true_binary)\n    accuracies.append(accuracy)\n\n    print(f\"Accuracy for digit {digit}: {accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Calculate and print overall accuracy\noverall_accuracy = np.mean(accuracies)\nprint(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Plotting accuracies for each digit\nplt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\nplt.xlabel(\"Digits\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy for Each Digit\")\nplt.xticks(range(10))\nplt.ylim(0, 1)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# print(f\"y_pred_binary =\", y_pred_binary)\n# print(f\"y_true_binary =\", y_true_binary)\n\n# print(f\"y_pred_binary.shape =\", y_pred_binary.shape)\n# print(f\"y_true_binary.shape =\", y_true_binary.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:58:49.849992Z","iopub.execute_input":"2024-12-17T18:58:49.850520Z","iopub.status.idle":"2024-12-17T18:58:59.526459Z","shell.execute_reply.started":"2024-12-17T18:58:49.850475Z","shell.execute_reply":"2024-12-17T18:58:59.525771Z"}},"outputs":[{"name":"stdout","text":"x_test shape: (10000, 28, 28), y_test shape: (10000,)\nx_test shape: (10000, 784), y_test shape: (10000,)\nx_test_subset shape: (10000, 784)\nx_test_pca shape:  (10000, 77)\nx_test_norm shape: (10000, 77)\nAccuracy for digit 0: 66.60%\nAccuracy for digit 1: 87.41%\nAccuracy for digit 2: 60.00%\nAccuracy for digit 3: 39.41%\nAccuracy for digit 4: 58.39%\nAccuracy for digit 5: 51.05%\nAccuracy for digit 6: 40.56%\nAccuracy for digit 7: 48.02%\nAccuracy for digit 8: 50.97%\nAccuracy for digit 9: 61.94%\nOverall Accuracy: 56.44%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Define the rational function\ndef rational_function(x, alpha, beta):\n    \"\"\"\n    r(x) = (Î±_0 + Î±_1*x1**1 + Î±_2*x2**2 + ...) / \n           (Î²_0 + Î²_1*x1**1 + Î²_2*x2**2 + ...).\n    \"\"\"\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n# Function to cross-check a single test image\ndef cross_check_single_image(x_test_subset, y_test_subset, index, models_dir, pca_model_path):\n    \"\"\"\n    Cross-check a single image from the test dataset.\n    \n    Steps:\n    - Displays the actual test image at the given index.\n    - Shows the actual label.\n    - Calculates rational function outputs for all digit models.\n    - Predicts the digit with the highest confidence.\n    \"\"\"\n    # Load the PCA model\n    with open(pca_model_path, \"rb\") as file:\n        pca = pickle.load(file)\n    \n    # Preprocess the test image\n    selected_image = x_test_subset[index]  # Select the test image\n    selected_label = y_test_subset[index]  # Select the actual label\n    \n    # Flatten and apply PCA transformation\n    selected_image_flat = selected_image.reshape(1, -1)  # Flatten (1, 784)\n    selected_image_pca = pca.transform(selected_image_flat)  # Apply PCA\n    \n    # Normalize using MinMaxScaler\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    selected_image_normalized = scaler.fit_transform(selected_image_pca)[0]  # Normalized PCA data\n    \n    # Display the actual image\n    plt.imshow(selected_image, cmap=\"gray\")\n    plt.title(f\"Actual Label: {selected_label}\")\n    plt.axis(\"off\")\n    plt.show()\n    \n    # Load all digit models and calculate rational function outputs\n    rational_outputs = {}\n    for digit in range(10):\n        # Load the respective model\n        with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n            model = pickle.load(file)\n        \n        alpha = model[\"alpha\"]\n        beta = model[\"beta\"]\n        \n        # Calculate the rational function output\n        output = rational_function(selected_image_normalized, alpha, beta)\n        rational_outputs[digit] = output\n    \n    # Print rational function outputs\n    print(\"Rational Function Outputs for Each Digit:\")\n    for digit, output in rational_outputs.items():\n        print(f\"Digit {digit}: {output:.4f}\")\n    \n    # Predict the digit based on the closest output to the positive class (e.g., 2)\n    predictions = {digit: abs(output - 2) for digit, output in rational_outputs.items()}\n    predicted_digit = min(predictions, key=predictions.get)\n    \n    print(f\"\\nPredicted Digit: {predicted_digit}\")\n    print(f\"Actual Label: {selected_label}\")\n    \n    # Final Cross-Check\n    if predicted_digit == selected_label:\n        print(\"Prediction: Correct âœ…\")\n    else:\n        print(\"Prediction: Incorrect âŒ\")\n\n# Main execution\nif __name__ == \"__main__\":\n    # Load the MNIST test dataset\n    from keras.datasets import mnist\n    (_, _), (x_test, y_test) = mnist.load_data()\n    print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n    \n    # Set up test dataset\n    subset_size = 10000  # Use all test images\n    x_test_subset = x_test[:subset_size]\n    y_test_subset = y_test[:subset_size]\n    \n    # Path to saved models and PCA\n    models_dir = \"/kaggle/working/models/\"  # Update the directory path\n    pca_model_path = \"models/pca_model.pkl\"\n    \n    # Select an index (change this to test different images)\n    test_index = 47 # Set the index of the image you want to test\n    \n    # Cross-check the selected image\n    cross_check_single_image(x_test_subset, y_test_subset, test_index, models_dir, pca_model_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T19:00:25.313875Z","iopub.execute_input":"2024-12-17T19:00:25.314230Z","iopub.status.idle":"2024-12-17T19:00:25.720431Z","shell.execute_reply.started":"2024-12-17T19:00:25.314200Z","shell.execute_reply":"2024-12-17T19:00:25.718383Z"}},"outputs":[{"name":"stdout","text":"x_test shape: (10000, 28, 28), y_test shape: (10000,)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Rational Function Outputs for Each Digit:\nDigit 0: 3.0000\nDigit 1: 2.9998\nDigit 2: 3.0004\nDigit 3: 3.0000\nDigit 4: 3.0000\nDigit 5: 3.0000\nDigit 6: 3.0000\nDigit 7: 3.0000\nDigit 8: 3.0000\nDigit 9: 2.9999\n\nPredicted Digit: 1\nActual Label: 2\nPrediction: Incorrect âŒ\n","output_type":"stream"}],"execution_count":23}]}
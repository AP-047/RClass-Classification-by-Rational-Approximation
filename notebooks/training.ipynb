{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"####  üçÅCheck Versions","metadata":{}},{"cell_type":"code","source":"# !python --version\n\nimport cupy as cp\ncp.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:28:09.887952Z","iopub.execute_input":"2024-12-17T18:28:09.888566Z","iopub.status.idle":"2024-12-17T18:28:11.843235Z","shell.execute_reply.started":"2024-12-17T18:28:09.888534Z","shell.execute_reply":"2024-12-17T18:28:11.842368Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'13.3.0'"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"#### üçÅ Create Directory","metadata":{}},{"cell_type":"code","source":"import os\n\nmodels_dir = \"/kaggle/working/models/\"\n\n# Ensure the directory exists\nos.makedirs(models_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T18:28:14.869986Z","iopub.execute_input":"2024-12-17T18:28:14.870550Z","iopub.status.idle":"2024-12-17T18:28:14.874823Z","shell.execute_reply.started":"2024-12-17T18:28:14.870516Z","shell.execute_reply":"2024-12-17T18:28:14.874019Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### üçÅ Preprocessing","metadata":{}},{"cell_type":"code","source":"# Import\nfrom keras.datasets import mnist\n(x_train, y_train), (_, _) = mnist.load_data()\nprint(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n\n#1 Flatten\nx_train_flat = x_train.reshape(x_train.shape[0], -1)\nprint(f\"x_train_flat shape: {x_train_flat.shape}, y_train shape: {y_train.shape}\")\n\n#2 Subsets\nsubset_size = 10000\nx_train_subset = x_train_flat[:subset_size]\ny_train_subset = y_train[:subset_size]\nprint(f\"x_train_subset shape: {x_train_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\nimport pickle\nn_components = 77\npca = PCA(n_components=n_components)\nx_train_pca = pca.fit_transform(x_train_subset)\nprint(f\"x_train_pca shape: \", x_train_pca.shape)\n# Load PCA instance\nwith open(\"models/pca_model.pkl\", \"wb\") as file:\n    pickle.dump(pca, file)  # Save the fitted PCA model\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_train_norm = scaler.fit_transform(x_train_pca)\nprint(f\"x_train_norm shape: {x_train_norm.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T19:05:56.287882Z","iopub.execute_input":"2024-12-17T19:05:56.288227Z","iopub.status.idle":"2024-12-17T19:05:58.676046Z","shell.execute_reply.started":"2024-12-17T19:05:56.288198Z","shell.execute_reply":"2024-12-17T19:05:58.674278Z"}},"outputs":[{"name":"stdout","text":"x_train shape: (60000, 28, 28), y_train shape: (60000,)\nx_train_flat shape: (60000, 784), y_train shape: (60000,)\nx_train_subset shape: (10000, 784)\nx_train_pca shape:  (10000, 77)\nx_train_norm shape: (10000, 77)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"### Step 6: Train Classifiers","metadata":{}},{"cell_type":"code","source":"import pickle\nimport cupy as cp\nimport numpy as np\nfrom scipy.optimize import linprog\nimport matplotlib.pyplot as plt\n\n# Feasibility check function\ndef check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary):\n    num_data_points = x_train_norm.shape[0]\n    num_coefficients = n_components + 1  # (+1 for the first constant terms Œ±0 & Œ≤0)\n    delta = 1e-6  # a small positive value\n\n    # Construct G(x) and H(x) matrices for numerator and denominator\n    G = cp.zeros((num_data_points, num_coefficients))  # Numerator matrix\n    H = cp.zeros((num_data_points, num_coefficients))  # Denominator matrix\n\n    for i in range(num_data_points):\n      G[i, 0] = 1\n      H[i, 0] = 1\n      for j in range(num_coefficients-1):\n        G[i, j+1] = x_train_norm[i, j] ** (j+1)\n        H[i, j+1] = x_train_norm[i, j] ** (j+1)\n\n    # print(f\"G: {G}\")\n    # print(f\"G.shape =\", G.shape)\n    # print(f\"H: {H}\")\n\n    # Construct constraints for Ax <= b\n    A = []\n    b = []\n\n    for i in range(num_data_points):\n        f_plus_z = y_binary[i] + z  # Upper bound\n        f_minus_z = y_binary[i] - z  # Lower bound\n\n        # Constraint 1: (f(xi) - z) * Œ≤^T H(xi) - Œ±^T G(xi) ‚â§ Œ∏\n        # (-G(xi))Œ±T + (f(xi) - z).H(xi)Œ≤T + (-1)Œ∏ ‚â§ 0\n        constraint_1 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Œ±\n        constraint_1[0:num_coefficients] = -G[i]\n        # (2) Coefficients of Œ≤\n        constraint_1[num_coefficients:2 * num_coefficients] = (f_minus_z) * H[i]\n        # (3) Coefficient of Œ∏ (last element)\n        constraint_1[-1] = -1\n        A.append(constraint_1)\n        b.append(0)\n\n        # Constraint 2: Œ±^T G(xi) + (-1).(f(xi) + z) * Œ≤^T H(xi) ‚â§ Œ∏\n        # G(xi).Œ±T + (-1)(f(xi) - z).H(xi)Œ≤T + (-1)Œ∏ ‚â§ 0\n        constraint_2 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Œ±\n        constraint_2[0:num_coefficients] = G[i]\n        # (2) Coefficients of Œ≤\n        constraint_2[num_coefficients:2 * num_coefficients] = -(f_plus_z) * H[i]\n        # (3) Coefficient of Œ∏ (last element)\n        constraint_2[-1] = -1\n        A.append(constraint_2)\n        b.append(0)\n\n        # Constraint 3: Œ≤^T H(x) ‚â• Œ¥\n        # (0)Œ±^T + (-H(x)) Œ≤^T + (0)Œ∏ ‚â§ -Œ¥\n        constraint_3 = cp.zeros(2 * num_coefficients + 1)\n        # Coefficient of Œ≤\n        constraint_3[num_coefficients:2 * num_coefficients] = -H[i]\n        A.append(constraint_3)\n        b.append(-delta)\n\n    # Convert CuPy arrays to NumPy arrays for SciPy\n    A = cp.asnumpy(cp.array(A))\n    b = cp.asnumpy(cp.array(b))\n\n    # print(f\"A =\", len(A))\n    # print(f\"A: {A[0]}\")\n    # print(f\"A.shape =\", A.shape)\n    # print(f\"len(A[0]): {len(A[0])}\")\n    # print(f\"len(b): {len(b)}\")\n    # print(f\"n_components =\", n_components)\n\n    # Objective function to minimize Œ∏\n    c = cp.asnumpy(cp.zeros(2 * num_coefficients + 1))\n    c[-1] = 1  # Only Œ∏ has a coefficient in the objective function\n\n    # Solve the linear programming problem (methods: highs, revised simplex)\n    result = linprog(c, A_ub=A, b_ub=b, method=\"highs\")\n\n    # Check feasibility and return results\n    if result.success:\n        alpha_coefficients = result.x[:num_coefficients]\n        beta_coefficients = result.x[num_coefficients:2 * num_coefficients]\n        theta = result.x[-1]\n        return True, alpha_coefficients, beta_coefficients, theta\n    else:\n        return False, None, None, None\n\n\n# Bisection loop\ndef bisection_loop(x_train_norm, y_binary, uL, uH, precision):\n    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n    z_values = []\n\n    while uH - uL > precision:\n        z = (uL + uH) / 2\n        z_values.append(z)\n        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary)\n\n        if feasible:\n            uH = z\n            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n        else:\n            uL = z\n\n    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values\n\n# Train a classifier for each digit\nfor digit in range(10):\n    print(f\"Training classifier for digit {digit}...\")\n\n    # Assign labels: Positive for the current digit, negative for others\n    # y_binary = (y_train_subset == digit).astype(int)\n    y_binary = (y_train_subset == digit).astype(float)\n\n    # Scale binary labels to larger values\n    # Positive class = 2, Negative class = 4\n    y_binary = np.where(y_binary == 1, 2, 4)\n\n    # print(f\"y_binary =\", y_binary)\n    # print(f\"y_train_subset =\", y_train_subset)\n\n    # Bisection parameters\n    uL = 0  # Initial lower bound\n    uH = 500  # Initial upper bound\n    precision = 1e-6 # Precision threshold\n\n    # Run bisection loop\n    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(x_train_norm, y_binary, uL, uH, precision)\n\n    # Print results\n    print(f\"Number of Iterations: {len(z_values)}\")\n    # print(f\"z Values in all Iterations: {z_values}\")\n    print(f\"Optimal z (Maximum Deviation): {optimal_z}\")\n\n    # # Plot convergence of z values\n    # plt.figure(figsize=(8, 6))\n    # plt.plot(range(len(z_values)), z_values, marker='o', linestyle='-')\n    # plt.xlabel(\"Iteration\")\n    # plt.ylabel(\"z Value\")\n    # plt.title(\"Convergence of z Values\")\n    # plt.grid(True)\n    # plt.show()\n\n    print(f\"Optimized Coefficients (Numerator Œ±): {optimal_alpha}\")\n    print(f\"Optimized Coefficients (Denominator Œ≤): {optimal_beta}\")\n    print(f\"Optimal Œ∏: {optimal_theta}\")\n    \n    # print(f\"rational_function =\", rational_function(x_train_norm[0], optimal_alpha, optimal_beta))\n\n    # Save the model\n    model = {\n        \"alpha\": optimal_alpha,\n        \"beta\": optimal_beta,\n        \"theta\": optimal_theta,\n        \"n_components\": n_components\n    }\n\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"wb\") as file:\n        pickle.dump(model, file)\n\n    print(f\"Model for digit {digit} saved at {models_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T19:06:08.010004Z","iopub.execute_input":"2024-12-17T19:06:08.010313Z","iopub.status.idle":"2024-12-17T21:02:29.007742Z","shell.execute_reply.started":"2024-12-17T19:06:08.010287Z","shell.execute_reply":"2024-12-17T21:02:29.006763Z"}},"outputs":[{"name":"stdout","text":"Training classifier for digit 0...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 0.4883278161287308\nOptimized Coefficients (Numerator Œ±): [ 3.00000081e-06  0.00000000e+00 -1.29887846e-12  4.67832311e-12\n -1.01635194e-11  3.25765145e-13 -1.24647930e-11  2.53156288e-11\n -1.36335644e-11  3.61486898e-12 -1.07603013e-11 -2.31123031e-10\n -2.16333532e-11 -1.62140729e-11 -1.18609958e-10 -3.28028408e-09\n  3.86386635e-10 -1.27668812e-12 -1.17755362e-10  2.12961323e-10\n  7.34454889e-11  1.61099324e-09  4.74671986e-11  2.56158429e-11\n  3.22266301e-10 -2.79701479e-09 -1.90241191e-10  5.15146083e-12\n -1.74543869e-12  3.45808557e-11  1.17782549e-10 -1.24486472e-08\n -7.70177428e-12  0.00000000e+00  9.14503969e-12  2.72648517e-10\n  2.00000006e-06 -1.14618307e-10 -8.63023384e-13  4.99566535e-10\n -1.89392134e-12  3.90721590e-11  8.46104029e-13 -7.45309674e-10\n  1.30546972e-11 -2.80683990e-12 -7.86637647e-14 -1.18166462e-11\n  7.98012466e-10  2.00000788e-06 -1.14485655e-11 -5.95537119e-11\n  1.38109343e-10  2.24975303e-13  2.01308791e-06  1.10118745e-10\n  1.44208997e-13  2.00000086e-06  0.00000000e+00  0.00000000e+00\n  0.00000000e+00 -5.93706261e-11  5.95288236e-11  2.64526526e-11\n  0.00000000e+00  0.00000000e+00  3.30649431e-10  6.91017879e-11\n -4.20968863e-10  0.00000000e+00  1.99999943e-06  1.99950245e-06\n -2.35743594e-13  4.94261811e-12  4.60448996e-04  2.00002643e-06\n  2.60998729e-11 -6.11864074e-12]\nOptimized Coefficients (Denominator Œ≤): [ 9.99999945e-07  4.32443088e-13 -2.91586008e-13  1.53978943e-12\n -2.73547234e-12  1.83060695e-13 -3.12813854e-12  7.41824328e-12\n -1.34509845e-12  1.35539570e-12 -4.98604814e-12 -6.63423062e-11\n  4.39434792e-12 -9.62865893e-12 -4.47230351e-11 -9.34367413e-10\n  1.80500639e-10 -5.64916090e-13  2.47536394e-10  2.58246180e-11\n  3.23306724e-12  4.62467907e-10  2.75947348e-12 -1.47071237e-12\n  9.12210683e-11 -7.63022867e-10  1.55091482e-12  2.17504150e-12\n  1.02086015e-12  7.80190350e-12  3.26265577e-13  1.86768513e-10\n -1.12706803e-13  4.80051279e-13  3.00671686e-12  9.59966696e-11\n -4.56944182e-12  1.48501150e-11 -1.81753184e-13 -6.61959336e-11\n  0.00000000e+00  3.11214283e-11  3.89041276e-13  1.66873429e-12\n -3.38540548e-13 -4.08136813e-13 -0.00000000e+00 -4.72648067e-12\n -0.00000000e+00  2.27181154e-13 -1.01945406e-13  0.00000000e+00\n  3.90806325e-11  0.00000000e+00  3.11929469e-14  8.90267718e-13\n  0.00000000e+00  4.18424063e-13 -6.26389663e-11  2.26226161e-13\n -2.04436492e-10 -2.96608317e-12  0.00000000e+00 -5.10980129e-13\n -1.62879308e-13  0.00000000e+00  1.04796818e-10  2.23684786e-11\n -1.20049404e-10  1.37321572e-11 -2.05759562e-14  6.69491882e-11\n  1.29861060e-13  9.04211718e-13  1.31119577e-04  6.06813874e-12\n  0.00000000e+00 -1.77630281e-12]\nOptimal Œ∏: 5.116721888552797e-07\nModel for digit 0 saved at /kaggle/working/models/\nTraining classifier for digit 1...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 0.0019082799553871155\nOptimized Coefficients (Numerator Œ±): [ 2.99987044e-06 -5.24740778e-11  6.71010501e-10  4.33949922e-11\n  8.50579209e-10 -4.75672631e-10 -1.36555939e-08  6.93265125e-09\n -3.21959742e-09  1.54897713e-09 -3.45059203e-09 -2.88344406e-09\n  0.00000000e+00 -3.22793928e-09 -1.72370635e-08 -1.18664628e-08\n -1.54804232e-08  2.98281103e-07  3.03895164e-06  1.58955785e-05\n -2.61413691e-09  1.99955087e-06 -5.25341244e-09  1.95694220e-06\n -2.11170766e-09  2.00090070e-06  2.28330969e-06  1.67397828e-10\n -2.81314555e-08  1.10753515e-07  1.03812061e-06 -4.02052806e-09\n -6.93175973e-08  1.99918639e-06  3.48497653e-05  2.10346043e-06\n  1.94709128e-06 -2.46372699e-09  1.99843567e-06  1.99390874e-06\n  2.41973612e-10 -1.56246306e-08  1.83718033e-06  1.44304090e-10\n -3.14443627e-10  4.27167807e-09  1.99964305e-06  1.99225987e-06\n  2.04011749e-06  2.08974734e-06  0.00000000e+00  2.05534686e-06\n  1.93388627e-06  2.01138274e-06  2.36172609e-09 -1.19811589e-09\n  2.00156404e-06  1.99969773e-06  1.99102991e-06 -4.91428644e-08\n  1.98436046e-06  1.00862991e-09  1.97717957e-06  2.00006256e-06\n  1.99921525e-06  1.99726587e-06 -9.71462484e-08  7.67182747e-10\n  1.95272399e-06  1.99938402e-06 -8.84654091e-09  1.67033095e-09\n -1.52809839e-08  4.72099662e-10  7.77060290e-10  2.00803095e-06\n  0.00000000e+00  2.00862899e-06]\nOptimized Coefficients (Denominator Œ≤): [ 9.99950579e-07  7.89311732e-11  2.03043146e-10 -3.40666530e-11\n  2.51045900e-10 -3.49439357e-11 -5.66505790e-09  3.60933728e-09\n -1.23316063e-09  1.50466678e-09  1.22107881e-11 -8.86680427e-10\n -2.95410431e-09 -1.53054813e-09  6.71627965e-12 -3.35231648e-09\n -1.49801104e-09  5.82451130e-09  2.59601885e-07  3.47224578e-06\n -4.02592134e-10 -1.40334372e-10  5.47527479e-11 -1.08496968e-08\n -1.44211986e-10  2.44025977e-10  7.10149819e-08  1.95396123e-10\n  9.40378009e-10  9.94578959e-09  2.60030150e-07 -5.55317824e-10\n -7.54942166e-09 -3.44467823e-10  8.21122372e-06  9.39951550e-08\n -4.20768691e-09 -5.63986296e-10 -8.37592266e-11 -1.07544400e-09\n -8.88387225e-11 -4.53147560e-10  6.88234746e-10  1.27905610e-10\n -2.84993378e-11  1.00573026e-09 -0.00000000e+00 -1.57946001e-09\n  1.06028752e-08  1.25889193e-08  1.70223403e-08  2.00124340e-10\n -9.24175001e-09  2.94158322e-09  4.92400776e-10 -2.99174015e-10\n  6.45546010e-10  4.10976130e-11 -3.52431436e-10 -1.33087711e-10\n -3.71900091e-09  4.05102090e-10 -5.73531973e-09  3.92907063e-11\n -2.90528601e-10 -1.29023608e-10 -3.42623682e-10 -5.78440504e-11\n -3.07362778e-10  0.00000000e+00 -5.71824674e-10 -0.00000000e+00\n -1.40914594e-09  2.95294139e-11  2.40495159e-11  2.24083927e-09\n  5.72535401e-08  2.54561156e-09]\nOptimal Œ∏: 9.980817913804103e-07\nModel for digit 1 saved at /kaggle/working/models/\nTraining classifier for digit 2...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.00000027e-06  3.61604144e-13  6.66715185e-12 -3.97019412e-12\n -3.47942586e-11 -1.97116023e-11 -2.06761111e-12  4.64903723e-10\n  2.53523411e-10  4.47962743e-11  2.07757465e-10  2.18657797e-10\n -7.13832192e-10 -1.17008497e-09 -6.24579727e-09  2.99068334e-09\n  3.19544465e-11  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  4.21173285e-09  1.13916739e-09 -3.30250299e-09  4.19299283e-08\n -1.23988166e-09  0.00000000e+00  1.27434879e-10  0.00000000e+00\n  6.29271717e-09  5.42319077e-08  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  3.36013796e-09  6.17756087e-09  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.36081553e-09\n  0.00000000e+00  0.00000000e+00  1.99587620e-06  0.00000000e+00\n -4.07060391e-08  0.00000000e+00  1.69644728e-11  0.00000000e+00\n  0.00000000e+00 -1.58697492e-08  0.00000000e+00  0.00000000e+00\n  7.51943483e-09  0.00000000e+00  1.31479000e-07  0.00000000e+00\n  0.00000000e+00 -3.46096410e-08  0.00000000e+00  1.86702590e-07\n  2.00001179e-06 -1.10394496e-11  0.00000000e+00 -8.19440765e-08\n  0.00000000e+00  7.39635292e-09  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -1.52815460e-08 -4.92129554e-10  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  5.05706991e-12]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000034e-06  0.00000000e+00 -4.59795586e-13 -8.83138173e-13\n -4.75396571e-12 -4.75619295e-12 -3.28105750e-12  1.52814019e-10\n  7.07544119e-11  0.00000000e+00  5.09092373e-11  5.52672581e-11\n -1.05384625e-10 -5.50127580e-10 -1.49561499e-09  1.02265660e-09\n  0.00000000e+00  9.97958973e-10 -1.99392414e-10 -1.78824680e-09\n  1.00399959e-09  3.32543852e-10 -6.44717100e-10  0.00000000e+00\n -5.07770301e-10  1.00212955e-09  0.00000000e+00  2.44039226e-10\n  1.62040716e-09  1.24469830e-09  3.77848414e-09 -3.67020934e-09\n  6.89739957e-09  1.07442440e-09  2.88241738e-10  0.00000000e+00\n  8.67761397e-09  2.54525084e-09  4.42185048e-10  8.75842428e-10\n -1.01560419e-09  0.00000000e+00 -1.75135846e-10 -1.03500034e-09\n  0.00000000e+00  2.03234536e-08  0.00000000e+00  0.00000000e+00\n  0.00000000e+00 -7.93528796e-09  2.59160975e-10  1.80107275e-10\n  0.00000000e+00  0.00000000e+00  3.83022956e-08  1.19401824e-11\n  5.11316349e-14  0.00000000e+00 -1.13886103e-09  4.66719785e-08\n  0.00000000e+00  0.00000000e+00  4.56717027e-09 -2.04861196e-08\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  3.09836231e-10\n  8.34130729e-09 -0.00000000e+00  0.00000000e+00  7.89961084e-10\n  0.00000000e+00 -1.90704360e-10  0.00000000e+00 -1.28993626e-11\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.999991839281226e-07\nModel for digit 2 saved at /kaggle/working/models/\nTraining classifier for digit 3...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99999991e-06  1.32001789e-13 -6.92212585e-14  5.56350010e-13\n  1.60947032e-12 -8.36018026e-13  0.00000000e+00  3.92308727e-12\n  1.31174112e-12  0.00000000e+00 -1.79694294e-11  0.00000000e+00\n -0.00000000e+00 -1.28696770e-11  0.00000000e+00 -1.07876916e-10\n  0.00000000e+00 -3.76609930e-10  1.45073630e-10  8.16092562e-13\n  8.76678767e-11 -8.67320777e-12  2.14911188e-10 -1.03424039e-08\n  1.18618830e-10  0.00000000e+00  1.43055124e-09  1.62349024e-09\n  0.00000000e+00  2.20512820e-10  5.58244474e-10  0.00000000e+00\n  1.47104794e-14 -8.82022279e-11 -4.40402958e-11 -3.20803563e-09\n -1.32094217e-08 -1.83501987e-10  5.28400522e-09  0.00000000e+00\n  4.76096614e-07  1.07546813e-08  2.14654348e-11  3.11432842e-10\n -9.45118806e-12 -4.83039952e-13  1.06899362e-06  1.99940820e-06\n  0.00000000e+00  0.00000000e+00  1.99396520e-06  1.49098878e-08\n -2.81140790e-11 -2.51891993e-09  1.86770113e-08  5.17139414e-06\n  4.12818673e-09  2.87103213e-07 -8.01438321e-09  0.00000000e+00\n  0.00000000e+00  7.00201365e-11  4.25916221e-11 -4.63629492e-09\n  1.99992138e-06  0.00000000e+00  1.99999581e-06  3.45241947e-09\n  1.72279266e-08  0.00000000e+00  2.00000020e-06  1.99289717e-06\n -8.34443644e-10  5.79271038e-10  0.00000000e+00 -9.78717643e-10\n  0.00000000e+00  2.00000024e-06]\nOptimized Coefficients (Denominator Œ≤): [ 9.99999968e-07  5.23700887e-14 -2.56440303e-14  1.68776636e-13\n  5.01189434e-13  0.00000000e+00  2.02915243e-12  2.18197356e-12\n  0.00000000e+00 -8.75320611e-13 -5.38240766e-12  6.03902401e-13\n  2.40271204e-14 -4.73640934e-12 -1.46484030e-13 -4.53533660e-11\n -5.58712936e-14 -7.75692166e-11  6.16529891e-11 -9.20403391e-14\n  3.23247985e-11  0.00000000e+00 -4.95150829e-11 -3.48798290e-13\n  3.20592210e-11 -2.93757556e-11  2.72444745e-10 -2.23807575e-11\n -2.56518949e-12  5.83595975e-11  8.26869694e-11 -1.42482727e-11\n  6.39414881e-11 -2.41649319e-11 -1.78719147e-11 -2.76463855e-09\n -4.92028910e-09 -4.58319102e-11  1.06539141e-09 -1.78040555e-11\n  1.19020624e-07  0.00000000e+00  8.76247647e-12  0.00000000e+00\n -1.15714129e-13 -1.54216601e-13  2.67256221e-07 -1.48061101e-10\n -2.16215391e-11 -6.39678812e-11 -1.50679516e-09  3.74329427e-09\n  0.00000000e+00 -1.32750458e-09  4.69062796e-09  7.92836647e-07\n  0.00000000e+00 -2.87162881e-09 -1.01539704e-12  0.00000000e+00\n  4.10026786e-11  1.75397086e-11 -1.53556339e-12 -2.31802612e-09\n -2.16406443e-11 -3.46507729e-11  0.00000000e+00  2.19332021e-09\n  4.30055282e-09 -5.70327849e-09  0.00000000e+00 -1.07125705e-09\n -2.08614310e-10 -1.10431261e-09  0.00000000e+00 -2.47317246e-12\n -3.37293468e-11  0.00000000e+00]\nOptimal Œ∏: 9.99999080386441e-07\nModel for digit 3 saved at /kaggle/working/models/\nTraining classifier for digit 4...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99994592e-06  3.06085279e-10  6.82659371e-11 -3.84802011e-12\n -1.31795735e-09 -1.03232549e-09  0.00000000e+00  6.74225070e-10\n  1.54512261e-09  0.00000000e+00  0.00000000e+00  1.10015010e-09\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  8.55224666e-08  0.00000000e+00 -1.40549227e-10  0.00000000e+00\n  3.76460826e-08  0.00000000e+00  5.59406690e-08  0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -5.47939964e-09  4.50261430e-08\n -8.58924732e-10  2.00029161e-06  8.11312477e-09  1.96821321e-06\n  2.04978593e-06  0.00000000e+00 -8.23879113e-10  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  2.00005667e-06 -1.78737105e-10\n  0.00000000e+00  2.00032137e-06 -9.61636631e-10  0.00000000e+00\n  1.99968970e-06  2.00024939e-06  1.99895616e-06  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.99128800e-06\n  0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.51700716e-11\n  2.00016962e-06  2.00002896e-06  1.55609657e-09  0.00000000e+00\n  0.00000000e+00  1.99976282e-06  1.95497982e-06  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.99996525e-06\n  1.99960512e-06 -4.01456507e-11  0.00000000e+00  0.00000000e+00\n -1.65749382e-08  1.29719747e-08  0.00000000e+00  1.99988136e-06\n -1.85153894e-09  1.99859916e-06]\nOptimized Coefficients (Denominator Œ≤): [ 9.99979338e-07 -2.81730619e-11  1.48877113e-10  1.80280004e-10\n -3.91258270e-10 -5.64142715e-10 -8.35775230e-10  3.82140502e-10\n  9.46448008e-11 -7.54425953e-10  1.66833586e-09  0.00000000e+00\n  1.25467960e-11  5.20692792e-09  7.85061748e-11  5.98569059e-10\n  2.40784451e-10  2.05687209e-10  0.00000000e+00 -1.36237990e-09\n  0.00000000e+00 -4.58835023e-11  3.42342600e-11  5.60759205e-10\n  1.38214570e-10  2.42902018e-11  1.80616659e-10 -7.32425193e-10\n  0.00000000e+00  1.02543265e-10  2.06381495e-09  1.31039342e-10\n  0.00000000e+00  8.35977296e-11 -1.11748111e-10  6.10165974e-11\n  7.43215789e-11 -9.16284379e-11  0.00000000e+00  0.00000000e+00\n  2.04628433e-08  0.00000000e+00 -2.49125063e-10 -3.80512543e-10\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  4.90843083e-11\n  1.45330000e-08  1.25223893e-08 -3.12446818e-10 -5.57066321e-11\n  0.00000000e+00 -1.19604471e-10 -8.45481142e-11  0.00000000e+00\n  1.02972667e-10 -7.84805852e-13  6.28032127e-10  3.75559506e-09\n  4.02693232e-11  0.00000000e+00  0.00000000e+00 -1.98346764e-11\n  1.41892466e-10  2.47034900e-10 -6.36011667e-10  0.00000000e+00\n -8.88987534e-13  3.19105956e-11 -5.07511796e-12  0.00000000e+00\n  7.09541236e-11  6.27455372e-10  2.18817630e-09  1.09769220e-11\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.999780729503352e-07\nModel for digit 4 saved at /kaggle/working/models/\nTraining classifier for digit 5...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99999952e-06  0.00000000e+00  1.26876698e-12  2.28331455e-12\n -1.62170472e-12 -3.30253131e-12  0.00000000e+00  5.51087949e-11\n  1.50638694e-11 -6.60635503e-11  4.16162272e-11  3.97408387e-10\n  7.22162272e-11 -1.69334295e-10 -3.12746731e-11 -7.66514931e-10\n -4.77625696e-11 -5.04960268e-09  0.00000000e+00  1.59288507e-10\n  7.83206379e-11  0.00000000e+00  5.66646173e-10 -9.28291630e-09\n -1.67234410e-09  0.00000000e+00 -1.08522742e-09  6.07215595e-09\n  1.86174446e-08 -4.57457794e-10 -2.02765778e-10 -3.08365911e-08\n -4.14284371e-10  3.23555297e-08  2.34701820e-10  4.04335920e-08\n  2.00013966e-06  0.00000000e+00  2.12590629e-09  1.64811486e-06\n -1.00231116e-09 -4.67966446e-09  0.00000000e+00 -2.82395045e-08\n  0.00000000e+00 -8.77146868e-08  2.17872487e-07  0.00000000e+00\n  2.46712244e-08 -0.00000000e+00  0.00000000e+00  7.39862187e-07\n  0.00000000e+00  1.33523855e-06  3.28148085e-08  1.98320557e-06\n -1.13633053e-09 -5.37595901e-11 -1.89739280e-08 -4.45695053e-13\n  1.85342195e-06 -3.16719231e-09  6.41659657e-09  0.00000000e+00\n -3.07716278e-08 -6.82191885e-08  2.69027058e-10  0.00000000e+00\n -5.19825777e-12 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n  0.00000000e+00 -0.00000000e+00  1.99999667e-06 -5.74926559e-08\n  0.00000000e+00  2.00011621e-06]\nOptimized Coefficients (Denominator Œ≤): [ 9.99999969e-07 -1.65512521e-13  3.28454292e-13  4.91817171e-13\n  1.57281673e-14  0.00000000e+00 -2.60230536e-12  1.61144964e-11\n -2.84659369e-13 -2.66245414e-11  1.30582787e-11  9.84671077e-11\n  2.75686558e-11 -4.64330048e-11 -1.61493680e-11 -1.44549596e-10\n -2.27193014e-11  5.36745842e-11  3.06791032e-10  3.56979754e-11\n  2.39905395e-11 -1.93438180e-12  1.40442075e-10 -4.53263317e-09\n -4.83974462e-10 -2.05955768e-10 -2.91519361e-10  4.07873322e-10\n  4.65513317e-09 -2.89072362e-10 -2.11661009e-11 -6.41919269e-09\n -1.87992850e-10  9.84199486e-09  0.00000000e+00  1.13581070e-08\n  9.81723170e-11 -5.82024861e-09 -1.73309464e-12  4.12979969e-07\n -7.89975768e-10 -1.15239079e-09 -4.60794600e-10 -7.02098788e-09\n -0.00000000e+00  0.00000000e+00  6.38814949e-08 -3.99098964e-09\n  0.00000000e+00  8.44519114e-11 -0.00000000e+00  1.85263596e-07\n  0.00000000e+00  0.00000000e+00  7.54196175e-09  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -2.26032133e-08 -1.22211686e-09  2.66246605e-09  3.33579752e-11\n -5.49181213e-08 -3.40546163e-08  6.09801893e-08 -5.51075003e-11\n  0.00000000e+00 -8.42307763e-10 -1.49529517e-10 -7.81488674e-08\n -3.78034148e-09 -1.16435242e-08  0.00000000e+00 -1.70172701e-08\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.999991223578985e-07\nModel for digit 5 saved at /kaggle/working/models/\nTraining classifier for digit 6...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 0.0076303258538246155\nOptimized Coefficients (Numerator Œ±): [ 2.99999975e-06 -7.50349491e-14  6.75300982e-13  8.49141128e-13\n  7.52818175e-13  1.70973904e-12  0.00000000e+00 -5.47099330e-12\n -8.48407769e-12 -4.52349779e-12  4.34604311e-12  3.09814175e-12\n -6.40744036e-12 -8.69915897e-12 -1.10616873e-10  9.22772389e-11\n  4.39251170e-12 -9.46612512e-11  3.84787062e-10 -1.40030049e-10\n  0.00000000e+00  5.42131513e-12 -1.48286424e-11 -1.98668260e-11\n  6.18803672e-12 -2.52294395e-10 -1.60861609e-10  9.81235748e-10\n -1.64696647e-10  2.27944742e-09  2.19116338e-10 -4.30028466e-12\n  4.73764762e-10  1.38963649e-10 -7.71559656e-11 -5.29865195e-09\n  1.91562978e-09  4.68453840e-10 -2.75794952e-10 -5.54923479e-10\n -1.35590992e-08 -5.68975813e-11  1.03490237e-09 -4.76845305e-10\n  2.00056016e-06 -8.48293802e-09  1.45632385e-10 -6.29103262e-08\n -6.65197406e-11 -5.34503087e-09  1.75187560e-10 -2.78168471e-09\n  1.98633646e-09 -5.83399198e-11  1.99110435e-06  2.60582353e-10\n -0.00000000e+00  0.00000000e+00  0.00000000e+00  1.99999485e-06\n -0.00000000e+00 -6.18228835e-09 -1.32360265e-10 -3.00214430e-08\n -2.62111289e-11 -2.83155818e-09 -2.14095271e-08 -2.69041321e-10\n  3.92701000e-12  2.94129882e-09  1.99999998e-06 -3.41682967e-12\n  4.34649696e-05  0.00000000e+00  0.00000000e+00  3.20807146e-08\n  0.00000000e+00  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 9.99999933e-07 -1.86536051e-14  9.72949730e-14  2.51961332e-13\n  2.77307462e-13  2.82001078e-13 -1.14374471e-13 -2.58673328e-12\n -1.24003355e-12 -1.65023763e-12  1.64517367e-12  3.90018689e-12\n -2.54329066e-12  1.04533315e-12 -3.04500747e-11 -7.24212476e-12\n  1.51765652e-11 -3.29214629e-11  1.81279620e-10 -3.30486578e-11\n  1.56681527e-12  0.00000000e+00 -3.70743762e-12  4.58901093e-12\n  3.22431407e-12 -1.54047789e-10 -1.51316938e-11 -0.00000000e+00\n -9.01470268e-12  2.18967972e-10  5.15434650e-11  0.00000000e+00\n  1.20132624e-10  6.24744689e-11 -3.81966804e-11 -2.03286434e-09\n -0.00000000e+00  1.22397801e-10  0.00000000e+00 -1.59299580e-10\n -3.38830628e-09 -1.44830927e-11  5.14670767e-10 -1.19688466e-10\n  1.39797935e-10 -1.70790042e-09 -4.49633142e-12 -0.00000000e+00\n -7.26333984e-12 -1.31103291e-09  4.31370905e-11 -0.00000000e+00\n -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n  0.00000000e+00  4.94680433e-14 -0.00000000e+00  0.00000000e+00\n  0.00000000e+00 -3.07517104e-09 -3.26130776e-11  0.00000000e+00\n  0.00000000e+00 -7.09634648e-10 -1.44837915e-10  0.00000000e+00\n  1.95577969e-12 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n  1.08870099e-05 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n  0.00000000e+00 -0.00000000e+00]\nOptimal Œ∏: 9.923696668253755e-07\nModel for digit 6 saved at /kaggle/working/models/\nTraining classifier for digit 7...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 2.99998565e-06 -6.12362149e-11  6.50495445e-11 -1.40451295e-10\n  6.26832770e-10  1.43542502e-10  3.20168513e-09 -2.65024323e-09\n -4.12802369e-10  1.54390065e-09  3.13824246e-10 -6.97502604e-09\n  4.36933109e-09 -5.06291938e-09  1.01625918e-08  5.26895942e-09\n  0.00000000e+00  4.45849777e-09 -4.07800961e-08  6.64400346e-09\n -6.67256924e-08  1.18856855e-08 -3.44992276e-08  0.00000000e+00\n  2.61397748e-08 -3.14146427e-09 -3.62155812e-08 -6.69586071e-08\n  1.99941470e-06  0.00000000e+00 -6.70531598e-09  5.07767778e-10\n  0.00000000e+00  1.99658740e-06  1.24884137e-09 -9.36710539e-10\n -6.42588091e-11  2.34748033e-07  1.97385535e-06  1.99713900e-06\n -1.05553066e-08  3.26998340e-10  0.00000000e+00 -6.50551673e-09\n  1.36463371e-07 -2.23546253e-11  1.35368609e-09  0.00000000e+00\n  2.00006937e-06  6.77111987e-08 -3.95837716e-10  2.05500051e-06\n  8.80312565e-09  2.00025931e-06  7.76327359e-10  1.99944715e-06\n  5.33034405e-06  2.00002265e-06  7.70062498e-10  1.99968524e-06\n -5.60449560e-10 -5.00628300e-10  1.99976188e-06  1.04840706e-08\n  7.36842258e-09 -0.00000000e+00  0.00000000e+00 -1.20755626e-09\n -4.44877094e-08 -8.92614058e-12 -1.48042453e-09  0.00000000e+00\n -1.96441173e-10  1.99979493e-06  0.00000000e+00  1.99978581e-06\n  2.00014230e-06 -9.16906830e-08]\nOptimized Coefficients (Denominator Œ≤): [ 9.99987243e-07 -2.57415770e-13  6.83083033e-12  1.52342605e-11\n  2.55472110e-10 -9.48447936e-11  1.06830828e-09 -6.29741609e-10\n -3.82559138e-10  6.12483751e-10  2.82803173e-10 -3.13666897e-09\n  1.81909113e-09 -3.45876490e-10  1.94744556e-09 -4.86415144e-11\n -2.77386052e-11  0.00000000e+00 -6.73688731e-09 -5.32002620e-11\n -7.47447539e-09  9.32681809e-10 -8.69557231e-09 -1.07492192e-08\n  6.53269448e-09 -7.89086144e-10 -1.16216212e-10 -1.72042516e-08\n -1.83195219e-10 -2.22062056e-11 -6.06674238e-09  6.06081383e-10\n  0.00000000e+00  6.05116915e-11  4.21536807e-11  7.39433507e-11\n  0.00000000e+00  0.00000000e+00 -6.54156446e-09 -0.00000000e+00\n -2.63328987e-09  8.71932641e-11  8.43212339e-10 -1.92040904e-09\n  3.40973213e-08 -0.00000000e+00  3.74711479e-10 -0.00000000e+00\n -0.00000000e+00 -1.10776976e-11 -9.50949210e-11 -2.83716180e-11\n  4.16735146e-09 -0.00000000e+00  1.71641750e-10  0.00000000e+00\n  8.32519609e-07 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n -0.00000000e+00 -1.59773826e-10  0.00000000e+00 -4.07034116e-09\n  0.00000000e+00  2.03697024e-10  0.00000000e+00 -6.73176446e-11\n  0.00000000e+00 -3.36428141e-12 -3.69276723e-10 -1.03835751e-10\n  0.00000000e+00 -1.51147165e-10  1.08154039e-11  0.00000000e+00\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.999960128493467e-07\nModel for digit 7 saved at /kaggle/working/models/\nTraining classifier for digit 8...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.00000002e-06 -7.71416551e-14 -3.13902804e-15  1.94285145e-14\n -3.86542498e-14 -2.83449767e-13  3.08184276e-12 -1.29709099e-12\n  3.78847482e-13 -8.54934838e-13  7.77247737e-13  1.14343790e-12\n  9.44623863e-13  2.66001449e-12 -1.56861172e-12 -1.86963618e-12\n -3.29535794e-12 -4.60714759e-13 -2.62599866e-13  7.75694683e-12\n -1.39314839e-12 -7.16272540e-12 -3.87138401e-11 -1.73752457e-10\n  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.84143885e-11\n -5.12358495e-12 -2.35039919e-12 -8.95059938e-11  0.00000000e+00\n  0.00000000e+00 -6.49029990e-12 -1.35139901e-11  2.27624390e-10\n  0.00000000e+00 -2.81834810e-10  0.00000000e+00  8.78339789e-11\n  1.93603341e-12 -8.44780516e-12 -9.02632117e-10  0.00000000e+00\n -0.00000000e+00  0.00000000e+00  2.04775354e-10 -1.03487112e-10\n -6.27687560e-10  1.41423778e-09  0.00000000e+00  0.00000000e+00\n -0.00000000e+00 -5.33837914e-12  0.00000000e+00 -1.49746228e-10\n -7.11055152e-10 -4.40896990e-10 -6.24542665e-10 -0.00000000e+00\n  5.49829716e-14  0.00000000e+00 -2.53147551e-09 -4.60198409e-10\n -0.00000000e+00  2.15346102e-06  1.12087541e-07 -1.35857947e-12\n -3.09936128e-10 -0.00000000e+00  1.43027786e-10  2.14657799e-10\n -9.91973938e-10  6.53888900e-10  1.98312356e-06  0.00000000e+00\n  2.00000030e-06 -0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000001e-06 -2.55286477e-14 -0.00000000e+00  3.26375318e-15\n -6.37612924e-15 -1.76476783e-13  7.69090136e-13 -3.35684726e-13\n  1.59988197e-13 -2.64147393e-13  2.02905327e-13  3.94805647e-13\n  5.46236917e-13  7.00138273e-13 -1.05425825e-12 -2.68701603e-13\n -4.29393635e-13 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n -1.33079913e-12 -1.82908803e-12 -1.32735886e-11 -2.71106571e-11\n -6.92610507e-13 -0.00000000e+00 -0.00000000e+00 -9.82371745e-12\n -7.93884405e-13 -8.67326474e-13 -2.33167172e-11  8.31709695e-13\n  1.10546511e-13 -4.43752824e-12 -0.00000000e+00  4.69292172e-11\n  8.44914913e-11  0.00000000e+00  1.28920127e-12  4.41227554e-11\n  1.26149564e-12 -0.00000000e+00 -2.25692110e-10 -5.85244644e-12\n  3.79796374e-12 -3.58366960e-12  1.94668079e-10 -0.00000000e+00\n -1.40060088e-12  0.00000000e+00  7.57725718e-11  1.35370148e-12\n -0.00000000e+00 -6.37082306e-13 -0.00000000e+00  5.97160747e-12\n  2.27691416e-10 -7.99947519e-11  9.92035181e-12  4.26134713e-13\n  1.37151574e-10 -0.00000000e+00 -1.31442433e-09 -1.14541427e-10\n -5.75200077e-10  2.73189934e-09  2.78256822e-08 -0.00000000e+00\n -6.45075721e-11 -0.00000000e+00 -8.01677147e-13 -0.00000000e+00\n -2.40133570e-10  2.41221219e-10 -4.17505940e-09 -1.33561241e-13\n -8.40301802e-14 -0.00000000e+00]\nOptimal Œ∏: 9.999990683370863e-07\nModel for digit 8 saved at /kaggle/working/models/\nTraining classifier for digit 9...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 3.073364496231079e-05\nOptimized Coefficients (Numerator Œ±): [ 2.99999994e-06 -1.01681691e-13  4.38074866e-13 -1.24558669e-12\n -8.47272226e-13  1.84107561e-12  7.79587643e-13  1.07656439e-11\n  9.53083420e-12  0.00000000e+00  4.12386601e-12  1.15381061e-11\n  4.20011129e-12 -6.88026833e-12  5.13444611e-13  9.65315595e-12\n -7.95277461e-12 -1.49324947e-10  6.76987431e-10 -4.19924350e-10\n  1.10012618e-09 -3.07191941e-09 -1.19556138e-10  2.57462754e-09\n -3.96551276e-10 -4.69809253e-11  1.00637347e-11  0.00000000e+00\n  2.64503973e-10 -6.89428177e-09 -2.04549534e-09  0.00000000e+00\n  2.53876001e-12  8.19478193e-10 -1.26378924e-10  2.82589899e-09\n  0.00000000e+00 -1.81927554e-09  0.00000000e+00 -1.21020976e-10\n  1.02704091e-08  0.00000000e+00 -2.46422317e-08  1.68506297e-09\n  1.99999912e-06 -1.89859441e-08 -6.94954541e-12  1.97870074e-06\n  0.00000000e+00 -6.54232286e-10  2.01554370e-06  2.00017977e-06\n  1.99997595e-06  7.28366624e-09  0.00000000e+00 -0.00000000e+00\n -9.67436829e-09 -0.00000000e+00  0.00000000e+00 -1.65724117e-09\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.99999959e-06\n  1.99997618e-06 -3.15608947e-12  1.99998822e-06  2.00042216e-06\n  2.47129840e-11 -0.00000000e+00  2.00001544e-06  2.00012108e-06\n  6.02734208e-12 -0.00000000e+00  0.00000000e+00 -1.82437070e-04\n  0.00000000e+00 -1.88739516e-09]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000010e-06  1.96345521e-13 -1.71513351e-13 -2.71057365e-13\n -3.26898224e-13 -9.29861219e-13 -9.17700211e-13  1.36483641e-12\n  4.28604428e-12 -3.77315261e-12  0.00000000e+00  2.05422487e-12\n  2.62433809e-13  4.66206876e-12  2.56078419e-12 -1.34054134e-12\n -4.87112188e-13  1.16211443e-11  1.95191990e-10 -8.29171227e-11\n  2.43672712e-10 -7.86696643e-10  2.46614049e-12  1.28522897e-11\n  0.00000000e+00  0.00000000e+00 -3.86425730e-13 -1.12203413e-10\n  4.11330619e-11  8.35078011e-10 -5.10423991e-10 -1.91415677e-10\n  1.60994437e-13  2.04933279e-10 -0.00000000e+00 -1.00944367e-10\n  8.12261575e-11 -5.90687849e-10  5.78735765e-12 -0.00000000e+00\n  4.24298558e-09 -0.00000000e+00  0.00000000e+00 -1.27666671e-11\n -0.00000000e+00  3.68576488e-09  0.00000000e+00 -5.32485005e-09\n -7.17794553e-11 -1.63043291e-10  3.88640535e-09  4.44373709e-11\n -0.00000000e+00  1.86404842e-09 -0.00000000e+00  2.33717486e-13\n -2.41865691e-09 -8.88897654e-14 -1.16046392e-10  0.00000000e+00\n -1.66419404e-13 -1.31131643e-12 -2.84291877e-10 -0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.06446190e-10\n -0.00000000e+00  8.41410284e-14  3.74289503e-12 -0.00000000e+00\n  3.15805137e-12  2.07510430e-13  0.00000000e+00 -4.61089133e-05\n  0.00000000e+00  9.09178382e-11]\nOptimal Œ∏: 9.999692441502463e-07\nModel for digit 9 saved at /kaggle/working/models/\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"### [Testing]","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport pickle\nimport matplotlib.pyplot as plt\n\n#------------------------------------------\n# Define the rational function\ndef rational_function(x, alpha, beta):\n    \"\"\"\n    r(x) = (Œ±_0 + Œ±_1*x1**1 + Œ±_2*x2**2 + ...) / \n           (Œ≤_0 + Œ≤_1*x1**1 + Œ≤_2*x2**2 + ...).\n    \"\"\"\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n# #------------------------------------------\n# #1 Load MNIST test data (10,000 images)\n# from keras.datasets import mnist\n# (_, _), (x_test, y_test) = mnist.load_data()\n# print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n# #------------------------------------------\n# #2 Subset the test dataset\n# subset_size = 10000\n# x_test_subset = x_test[:subset_size]\n# y_test_subset = y_test[:subset_size]\n# print(f\"Shape of test subset: {x_test_subset.shape}\")\n\n# #------------------------------------------\n# # Flatten the test dataset (convert from 28x28 to 784)\n# x_test_subset = x_test_subset.reshape(x_test_subset.shape[0], -1)\n# print(f\"Shape of flattened test subset: {x_test_subset.shape}\")\n\n# #------------------------------------------\n# #3 Load PCA instance\n# with open(\"models/pca_model.pkl\", \"rb\") as file:\n#     pca = pickle.load(file)  # Load the PCA model trained on training data\n    \n# x_test_pca = pca.transform(x_test_subset)  # Transform test data using the saved PCA\n\n# print(f\"Shape of PCA-transformed test subset: {x_test_pca.shape}\")\n\n# #------------------------------------------\n# # #4 Thresholding: Convert PCA-transformed data to binary (0s and 1s)\n# # threshold_value = 0\n# # x_test_binary = (x_test_pca > threshold_value).astype(int)\n# # print(f\"Binary thresholded test subset: {x_test_binary.shape}\")\n\n# #------------------------------------------\n# #4 Normalize PCA-transformed data\n# from sklearn.preprocessing import MinMaxScaler\n\n# scaler = MinMaxScaler(feature_range=(0, 1))\n# x_test_norm = scaler.fit_transform(x_test_pca)\n\n# #------------------------------------------\n# #5 Shuffle the dataset\n# shuffle_indices = np.arange(len(y_test_subset))\n# np.random.shuffle(shuffle_indices)\n\n# x_test_shuf = x_test_norm[shuffle_indices]\n# y_test_subset = y_test_subset[shuffle_indices]\n\n#------x-x-x--------\n#------x-x-x--------\n# Import\nfrom keras.datasets import mnist\n(_, _), (x_test, y_test) = mnist.load_data()\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#1 Flatten\nx_test = x_test.reshape(x_test.shape[0], -1)\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#2 Subsets\nsubset_size = 10000\nx_test_subset = x_test[:subset_size]\ny_test_subset = y_test[:subset_size]\nprint(f\"x_test_subset shape: {x_test_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\nimport pickle\nn_components = 77\npca = PCA(n_components=n_components)\nx_test_pca = pca.fit_transform(x_test_subset)\nprint(f\"x_test_pca shape: \", x_test_pca.shape)\n\n# # with training settings\n# with open(\"models/pca_model.pkl\", \"rb\") as file:\n#     pca = pickle.load(file)  # Load the PCA model trained on training data\n    \n# # Transform test data using the saved PCA\n# x_test_pca = pca.transform(x_test_subset)\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_test_norm = scaler.fit_transform(x_test_pca)\nprint(f\"x_test_norm shape: {x_test_norm.shape}\")\n\n#------------------------------------------\n# Load the saved models and test\nmodels_dir = \"/kaggle/working/models/\"  # Update based on your environment\naccuracies = []\n\n#------------------------------------------\nfor digit in range(10):\n    # Load model for each digit\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n    theta = model[\"theta\"]\n\n    # Evaluate the rational function for each test data point\n    y_predicted = [\n        rational_function(x, alpha, beta) for x in x_test_norm\n    ]\n\n    # Convert predictions to binary (1 for this digit, 0 for others)\n    y_pred_binary = np.array(y_predicted) < 3\n    y_true_binary = y_test_subset == digit\n\n    # Calculate accuracy for this digit\n    accuracy = np.mean(y_pred_binary == y_true_binary)\n    accuracies.append(accuracy)\n\n    print(f\"Accuracy for digit {digit}: {accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Calculate and print overall accuracy\noverall_accuracy = np.mean(accuracies)\nprint(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Plotting accuracies for each digit\nplt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\nplt.xlabel(\"Digits\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy for Each Digit\")\nplt.xticks(range(10))\nplt.ylim(0, 1)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# print(f\"y_pred_binary =\", y_pred_binary)\n# print(f\"y_true_binary =\", y_true_binary)\n\n# print(f\"y_pred_binary.shape =\", y_pred_binary.shape)\n# print(f\"y_true_binary.shape =\", y_true_binary.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T21:10:46.111381Z","iopub.execute_input":"2024-12-17T21:10:46.111743Z","iopub.status.idle":"2024-12-17T21:10:54.899720Z","shell.execute_reply.started":"2024-12-17T21:10:46.111712Z","shell.execute_reply":"2024-12-17T21:10:54.898891Z"}},"outputs":[{"name":"stdout","text":"x_test shape: (10000, 28, 28), y_test shape: (10000,)\nx_test shape: (10000, 784), y_test shape: (10000,)\nx_test_subset shape: (10000, 784)\nx_test_pca shape:  (10000, 77)\nx_test_norm shape: (10000, 77)\nAccuracy for digit 0: 54.22%\nAccuracy for digit 1: 71.02%\nAccuracy for digit 2: 62.03%\nAccuracy for digit 3: 34.34%\nAccuracy for digit 4: 56.39%\nAccuracy for digit 5: 55.39%\nAccuracy for digit 6: 58.30%\nAccuracy for digit 7: 58.96%\nAccuracy for digit 8: 70.56%\nAccuracy for digit 9: 58.77%\nOverall Accuracy: 58.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Define the rational function\ndef rational_function(x, alpha, beta):\n    \"\"\"\n    r(x) = (Œ±_0 + Œ±_1*x1**1 + Œ±_2*x2**2 + ...) / \n           (Œ≤_0 + Œ≤_1*x1**1 + Œ≤_2*x2**2 + ...).\n    \"\"\"\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n# Function to cross-check a single test image\ndef cross_check_single_image(x_test_subset, y_test_subset, index, models_dir, pca_model_path):\n    \"\"\"\n    Cross-check a single image from the test dataset.\n    \n    Steps:\n    - Displays the actual test image at the given index.\n    - Shows the actual label.\n    - Calculates rational function outputs for all digit models.\n    - Predicts the digit with the highest confidence.\n    \"\"\"\n    # Load the PCA model\n    with open(pca_model_path, \"rb\") as file:\n        pca = pickle.load(file)\n    \n    # Preprocess the test image\n    selected_image = x_test_subset[index]  # Select the test image\n    selected_label = y_test_subset[index]  # Select the actual label\n    \n    # Flatten and apply PCA transformation\n    selected_image_flat = selected_image.reshape(1, -1)  # Flatten (1, 784)\n    selected_image_pca = pca.transform(selected_image_flat)  # Apply PCA\n    \n    # Normalize using MinMaxScaler\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    selected_image_normalized = scaler.fit_transform(selected_image_pca)[0]  # Normalized PCA data\n    \n    # Display the actual image\n    plt.imshow(selected_image, cmap=\"gray\")\n    plt.title(f\"Actual Label: {selected_label}\")\n    plt.axis(\"off\")\n    plt.show()\n    \n    # Load all digit models and calculate rational function outputs\n    rational_outputs = {}\n    for digit in range(10):\n        # Load the respective model\n        with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n            model = pickle.load(file)\n        \n        alpha = model[\"alpha\"]\n        beta = model[\"beta\"]\n        \n        # Calculate the rational function output\n        output = rational_function(selected_image_normalized, alpha, beta)\n        rational_outputs[digit] = output\n    \n    # Print rational function outputs\n    print(\"Rational Function Outputs for Each Digit:\")\n    for digit, output in rational_outputs.items():\n        print(f\"Digit {digit}: {output:.4f}\")\n    \n    # Predict the digit based on the closest output to the positive class (e.g., 2)\n    predictions = {digit: abs(output - 2) for digit, output in rational_outputs.items()}\n    predicted_digit = min(predictions, key=predictions.get)\n    \n    print(f\"\\nPredicted Digit: {predicted_digit}\")\n    print(f\"Actual Label: {selected_label}\")\n    \n    # Final Cross-Check\n    if predicted_digit == selected_label:\n        print(\"Prediction: Correct ‚úÖ\")\n    else:\n        print(\"Prediction: Incorrect ‚ùå\")\n\n# Main execution\nif __name__ == \"__main__\":\n    # Load the MNIST test dataset\n    from keras.datasets import mnist\n    (_, _), (x_test, y_test) = mnist.load_data()\n    print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n    \n    # Set up test dataset\n    subset_size = 10000  # Use all test images\n    x_test_subset = x_test[:subset_size]\n    y_test_subset = y_test[:subset_size]\n    \n    # Path to saved models and PCA\n    models_dir = \"/kaggle/working/models/\"  # Update the directory path\n    pca_model_path = \"models/pca_model.pkl\"\n    \n    # Select an index (change this to test different images)\n    test_index = 90 # Set the index of the image you want to test\n    \n    # Cross-check the selected image\n    cross_check_single_image(x_test_subset, y_test_subset, test_index, models_dir, pca_model_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T21:11:22.627137Z","iopub.execute_input":"2024-12-17T21:11:22.628068Z","iopub.status.idle":"2024-12-17T21:11:23.031385Z","shell.execute_reply.started":"2024-12-17T21:11:22.628029Z","shell.execute_reply":"2024-12-17T21:11:23.030407Z"}},"outputs":[{"name":"stdout","text":"x_test shape: (10000, 28, 28), y_test shape: (10000,)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Rational Function Outputs for Each Digit:\nDigit 0: 3.0000\nDigit 1: 3.0000\nDigit 2: 3.0000\nDigit 3: 3.0000\nDigit 4: 3.0000\nDigit 5: 3.0000\nDigit 6: 3.0000\nDigit 7: 3.0000\nDigit 8: 3.0000\nDigit 9: 3.0000\n\nPredicted Digit: 2\nActual Label: 3\nPrediction: Incorrect ‚ùå\n","output_type":"stream"}],"execution_count":28}]}
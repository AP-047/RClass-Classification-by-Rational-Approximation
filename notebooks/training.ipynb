{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"####  ðŸCheck Versions","metadata":{}},{"cell_type":"code","source":"# !python --version\n\nimport cupy as cp\ncp.__version__\n\n# !pip show jedi\n# !pip show setuptools\n# !pip show pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:31:31.300144Z","iopub.execute_input":"2024-12-16T10:31:31.300867Z","iopub.status.idle":"2024-12-16T10:31:33.582678Z","shell.execute_reply.started":"2024-12-16T10:31:31.300823Z","shell.execute_reply":"2024-12-16T10:31:33.581673Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'13.3.0'"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"#### ðŸ Set folder","metadata":{}},{"cell_type":"code","source":"import os\n\nmodels_dir = \"/kaggle/working/models/\"  # Kaggle's default working directory\n\n# Ensure the directory exists\nos.makedirs(models_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:31:39.723849Z","iopub.execute_input":"2024-12-16T10:31:39.724439Z","iopub.status.idle":"2024-12-16T10:31:39.728386Z","shell.execute_reply.started":"2024-12-16T10:31:39.724407Z","shell.execute_reply":"2024-12-16T10:31:39.727470Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Step 1: Import Data","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import fetch_openml\nimport numpy as np\n\n# Import MNIST dataset\nmnist = fetch_openml('mnist_784', version=1)\nx_full = mnist.data.values  # Full dataset\ny_full = mnist.target.values.astype(int)  # Labels (0â€“9)\n\nprint(f\"x_full shape: {x_full.shape}, y_full shape: {y_full.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:31:52.032405Z","iopub.execute_input":"2024-12-16T10:31:52.032786Z","iopub.status.idle":"2024-12-16T10:32:28.648023Z","shell.execute_reply.started":"2024-12-16T10:31:52.032752Z","shell.execute_reply":"2024-12-16T10:32:28.646914Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n  warn(\n","output_type":"stream"},{"name":"stdout","text":"x_full shape: (70000, 784), y_full shape: (70000,)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Step 2: Create Subset","metadata":{}},{"cell_type":"code","source":"# Create a subset of training data (1000 images per digit)\nsubset_size = 100\nx_subset = []\ny_subset = []\n\nfor digit in range(10):\n    digit_indices = np.where(y_full == digit)[0][:subset_size]\n    x_subset.append(x_full[digit_indices])\n    y_subset.append(y_full[digit_indices])\n\nx_subset = np.vstack(x_subset)\ny_subset = np.hstack(y_subset)\n\nprint(f\"x_subset shape: {x_subset.shape}, y_subset shape: {y_subset.shape}\")\nprint(f\"Unique labels in y_subset: {np.unique(y_subset)}\")\nprint(f\"x_subset[3].shape: {x_subset[3].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:32:34.218761Z","iopub.execute_input":"2024-12-16T10:32:34.219205Z","iopub.status.idle":"2024-12-16T10:32:34.233981Z","shell.execute_reply.started":"2024-12-16T10:32:34.219172Z","shell.execute_reply":"2024-12-16T10:32:34.232954Z"}},"outputs":[{"name":"stdout","text":"x_subset shape: (1000, 784), y_subset shape: (1000,)\nUnique labels in y_subset: [0 1 2 3 4 5 6 7 8 9]\nx_subset[3].shape: (784,)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### Step 3: Apply PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport pickle\n\n# Apply PCA to reduce dimensionality\nn_components = 20\npca = PCA(n_components=n_components)\nx_pca = pca.fit_transform(x_subset)\n\n# Load PCA instance\nwith open(\"models/pca_model.pkl\", \"wb\") as file:\n    pickle.dump(pca, file)  # Save the fitted PCA model\n\nprint(f\"Original shape: {x_subset.shape}, PCA shape: {x_pca.shape}\")\nprint(f\"variance retained: {np.sum(pca.explained_variance_ratio_)*100}%\")\n\nprint(f\"shape of x_pca: \", x_pca.shape)\nprint(f\"shape of x_pca[5]: \", x_pca[5].shape)\n\nprint(f\"check any image vector: \", x_pca[5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:32:38.755404Z","iopub.execute_input":"2024-12-16T10:32:38.755759Z","iopub.status.idle":"2024-12-16T10:32:39.403578Z","shell.execute_reply.started":"2024-12-16T10:32:38.755728Z","shell.execute_reply":"2024-12-16T10:32:39.402217Z"}},"outputs":[{"name":"stdout","text":"Original shape: (1000, 784), PCA shape: (1000, 20)\nvariance retained: 66.00926974066891%\nshape of x_pca:  (1000, 20)\nshape of x_pca[5]:  (20,)\ncheck any image vector:  [1073.1645858  -209.31732147  791.93498744  225.96292297  821.33847628\n -624.52373914 -833.45530456 -471.02006125  -63.52746291  -53.84144932\n   94.18809341 -111.87394384  380.46655376 -426.23356958 -252.02480942\n  420.80287478  186.53930285  -71.85932383  203.197543    332.64686556]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"### Step 4: Thresholding","metadata":{}},{"cell_type":"code","source":"# Thresholding: Convert to binary\nthreshold_value = 0\nx_b = (x_pca > threshold_value).astype(int)\n\nprint(f\"x_b shape: {x_b.shape}\")\nprint(f\"x_b[5] =\", x_b[5])\n\nprint(f\"x_b =\", x_b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:32:41.977839Z","iopub.execute_input":"2024-12-16T10:32:41.978180Z","iopub.status.idle":"2024-12-16T10:32:41.984868Z","shell.execute_reply.started":"2024-12-16T10:32:41.978150Z","shell.execute_reply":"2024-12-16T10:32:41.983877Z"}},"outputs":[{"name":"stdout","text":"x_b shape: (1000, 20)\nx_b[5] = [1 0 1 1 1 0 0 0 0 0 1 0 1 0 0 1 1 0 1 1]\nx_b = [[1 1 0 ... 1 1 1]\n [1 1 0 ... 0 1 0]\n [1 1 0 ... 0 0 0]\n ...\n [1 0 1 ... 1 1 1]\n [0 0 1 ... 1 1 1]\n [0 0 1 ... 1 1 0]]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Shuffle the dataset\nshuffle_indices = np.arange(len(y_subset))\nnp.random.shuffle(shuffle_indices)\n\nx_b = x_b[shuffle_indices]\ny_subset = y_subset[shuffle_indices]\n\nprint(f\"x_b.shape =\", x_b.shape)\nprint(f\"y_subset.shape =\", y_subset.shape)\n\nprint(f\"x_b =\", x_b)\nprint(f\"y_subset =\", y_subset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:32:44.279557Z","iopub.execute_input":"2024-12-16T10:32:44.279909Z","iopub.status.idle":"2024-12-16T10:32:44.287905Z","shell.execute_reply.started":"2024-12-16T10:32:44.279877Z","shell.execute_reply":"2024-12-16T10:32:44.286822Z"}},"outputs":[{"name":"stdout","text":"x_b.shape = (1000, 20)\ny_subset.shape = (1000,)\nx_b = [[0 0 0 ... 1 1 0]\n [1 0 0 ... 1 0 1]\n [0 0 0 ... 0 0 0]\n ...\n [1 1 0 ... 0 1 0]\n [1 0 1 ... 0 0 1]\n [1 1 0 ... 1 1 1]]\ny_subset = [4 6 5 8 0 4 5 5 1 4 3 7 7 6 4 9 1 9 7 6 3 3 8 1 7 6 3 8 6 7 6 4 1 4 2 3 5\n 0 3 1 9 6 8 2 7 2 7 7 7 5 2 0 2 8 4 8 5 9 4 1 2 6 2 5 9 0 2 8 3 1 7 2 3 3\n 3 2 4 2 2 3 5 4 4 6 7 6 0 9 3 5 1 2 9 3 5 3 7 1 6 9 2 9 5 8 8 2 1 5 9 3 0\n 5 8 1 7 9 0 6 0 2 9 2 3 2 4 1 3 4 4 2 2 1 8 2 1 3 0 0 1 5 1 5 1 7 7 7 7 7\n 4 0 2 8 5 5 3 7 5 6 2 0 9 9 1 3 5 8 8 5 0 5 6 6 4 7 4 4 7 7 9 8 9 8 3 8 8\n 3 7 4 7 2 9 3 9 4 9 4 9 7 1 4 3 8 6 9 5 8 7 9 1 1 5 4 8 1 0 2 2 4 9 4 7 0\n 2 7 5 7 0 0 1 2 4 8 3 4 2 2 1 8 3 7 5 6 4 4 7 6 2 5 8 9 3 7 9 0 6 3 6 3 0\n 2 5 1 4 2 1 9 8 1 9 5 3 2 3 0 2 4 0 3 0 4 0 9 6 5 9 3 1 6 5 6 6 3 7 9 6 3\n 9 5 9 1 6 2 1 8 8 1 4 0 0 6 7 4 6 7 4 4 4 9 7 2 0 5 9 7 3 6 5 6 8 8 4 9 3\n 8 5 7 0 3 7 9 6 6 3 5 8 3 3 2 3 0 3 0 2 1 1 5 1 4 9 1 1 6 9 1 0 3 2 4 8 6\n 5 3 9 5 5 2 6 3 7 3 1 6 9 8 8 1 1 4 2 1 7 6 4 9 5 6 9 0 4 8 3 0 1 2 5 8 8\n 5 3 5 4 4 0 0 9 7 9 9 0 3 9 7 7 2 3 5 2 3 3 9 2 9 0 8 7 3 2 5 0 9 7 7 8 5\n 4 5 6 2 3 1 5 7 3 7 5 6 3 1 0 9 0 9 2 7 8 4 8 0 8 0 1 1 0 2 5 8 7 3 2 9 6\n 7 8 4 7 6 5 3 6 0 0 4 7 5 7 4 9 9 7 5 8 4 6 6 6 5 2 8 1 6 3 6 5 5 9 2 5 8\n 5 7 3 9 8 0 9 6 4 5 7 8 5 8 6 0 5 4 5 8 3 7 6 7 1 5 8 6 7 1 8 6 7 4 7 3 2\n 5 0 0 0 1 9 8 8 2 3 9 1 4 1 3 5 1 1 2 0 9 2 5 6 2 2 1 0 1 7 4 1 9 5 7 0 8\n 0 0 2 5 6 4 8 7 3 4 0 0 8 8 3 8 8 2 2 0 1 2 6 5 0 9 6 0 0 4 8 3 9 6 6 1 2\n 4 3 6 8 6 4 2 3 9 1 2 2 6 1 8 0 1 7 9 7 8 9 2 3 1 6 9 5 3 1 0 8 8 9 3 8 4\n 1 9 8 8 0 4 6 9 0 0 8 5 3 8 6 0 6 4 3 8 0 7 2 8 0 4 3 2 7 3 2 5 5 3 1 7 2\n 7 8 1 4 2 1 1 8 1 2 6 7 9 4 1 7 6 1 2 1 4 5 7 8 7 7 2 6 1 3 1 2 5 3 3 4 9\n 4 3 4 5 1 2 0 0 9 5 9 1 1 8 9 7 5 8 8 3 8 0 4 7 8 3 4 5 8 0 9 8 9 5 8 2 3\n 3 0 2 1 7 6 9 9 2 9 2 5 0 8 9 9 8 0 4 2 5 2 0 0 4 2 4 1 5 4 6 0 3 6 1 4 0\n 8 2 2 5 6 9 6 4 6 7 7 6 3 3 1 7 5 7 5 8 7 6 6 2 8 6 3 5 3 0 6 2 6 1 0 6 5\n 4 4 6 4 7 3 0 2 1 7 2 5 1 7 1 6 8 1 4 4 7 1 0 2 9 2 2 4 7 0 6 0 5 3 6 8 5\n 6 2 2 4 9 9 9 3 6 1 9 0 2 4 9 0 7 3 0 8 6 1 1 0 6 7 8 9 4 5 3 0 6 9 4 5 7\n 0 1 5 0 8 4 1 4 6 0 6 9 3 4 9 8 4 9 5 1 0 9 3 0 9 9 9 0 6 0 6 0 6 7 2 9 5\n 7 7 1 6 4 8 8 5 2 1 7 1 5 4 4 1 0 3 5 1 6 3 7 4 7 5 6 9 6 4 1 7 8 8 4 0 4\n 2]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### Step 5: Train Classifiers","metadata":{}},{"cell_type":"code","source":"import pickle\nimport cupy as cp\nimport numpy as np\nfrom scipy.optimize import linprog\nimport matplotlib.pyplot as plt\n\n# Feasibility check function\ndef check_feasibility_and_compute_coefficients(z, x_b, y_binary):\n    num_data_points = x_b.shape[0]\n    num_coefficients = n_components + 1  # (+1 for the first constant terms Î±0 & Î²0)\n    delta = 1e-6  # a small positive value\n\n    # Construct G(x) and H(x) matrices for numerator and denominator\n    G = cp.zeros((num_data_points, num_coefficients))  # Numerator matrix\n    H = cp.zeros((num_data_points, num_coefficients))  # Denominator matrix\n\n    for i in range(num_data_points):\n      G[i, 0] = 1\n      H[i, 0] = 1\n      for j in range(num_coefficients-1):\n        G[i, j+1] = x_b[i, j] ** (j+1)\n        H[i, j+1] = x_b[i, j] ** (j+1)\n\n    # print(f\"G: {G}\")\n    # print(f\"G.shape =\", G.shape)\n    # print(f\"H: {H}\")\n\n    # Construct constraints for Ax <= b\n    A = []\n    b = []\n\n    for i in range(num_data_points):\n        f_plus_z = y_binary[i] + z  # Upper bound\n        f_minus_z = y_binary[i] - z  # Lower bound\n\n        # Constraint 1: (f(xi) - z) * Î²^T H(xi) - Î±^T G(xi) â‰¤ Î¸\n        # (-G(xi))Î±T + (f(xi) - z).H(xi)Î²T + (-1)Î¸ â‰¤ 0\n        constraint_1 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Î±\n        constraint_1[0:num_coefficients] = -G[i]\n        # (2) Coefficients of Î²\n        constraint_1[num_coefficients:2 * num_coefficients] = (f_minus_z) * H[i]\n        # (3) Coefficient of Î¸ (last element)\n        constraint_1[-1] = -1\n        A.append(constraint_1)\n        b.append(0)\n\n        # Constraint 2: Î±^T G(xi) + (-1).(f(xi) + z) * Î²^T H(xi) â‰¤ Î¸\n        # G(xi).Î±T + (-1)(f(xi) - z).H(xi)Î²T + (-1)Î¸ â‰¤ 0\n        constraint_2 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Î±\n        constraint_2[0:num_coefficients] = G[i]\n        # (2) Coefficients of Î²\n        constraint_2[num_coefficients:2 * num_coefficients] = -(f_plus_z) * H[i]\n        # (3) Coefficient of Î¸ (last element)\n        constraint_2[-1] = -1\n        A.append(constraint_2)\n        b.append(0)\n\n        # Constraint 3: Î²^T H(x) â‰¥ Î´\n        # (0)Î±^T + (-H(x)) Î²^T + (0)Î¸ â‰¤ -Î´\n        constraint_3 = cp.zeros(2 * num_coefficients + 1)\n        # Coefficient of Î²\n        constraint_3[num_coefficients:2 * num_coefficients] = -H[i]\n        A.append(constraint_3)\n        b.append(-delta)\n\n    # Convert CuPy arrays to NumPy arrays for SciPy\n    A = cp.asnumpy(cp.array(A))\n    b = cp.asnumpy(cp.array(b))\n\n    # print(f\"A =\", len(A))\n    # print(f\"A: {A[0]}\")\n    # print(f\"A.shape =\", A.shape)\n    # print(f\"len(A[0]): {len(A[0])}\")\n    # print(f\"len(b): {len(b)}\")\n    # print(f\"n_components =\", n_components)\n\n    # Objective function to minimize Î¸\n    c = cp.asnumpy(cp.zeros(2 * num_coefficients + 1))\n    c[-1] = 1  # Only Î¸ has a coefficient in the objective function\n\n    # Solve the linear programming problem (methods: highs, revised simplex)\n    result = linprog(c, A_ub=A, b_ub=b, method=\"highs\")\n\n    # Check feasibility and return results\n    if result.success:\n        alpha_coefficients = result.x[:num_coefficients]\n        beta_coefficients = result.x[num_coefficients:2 * num_coefficients]\n        theta = result.x[-1]\n        return True, alpha_coefficients, beta_coefficients, theta\n    else:\n        return False, None, None, None\n\n\n# Bisection loop\ndef bisection_loop(x_b, y_binary, uL, uH, precision):\n    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n    z_values = []\n\n    while uH - uL > precision:\n        z = (uL + uH) / 2\n        z_values.append(z)\n        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(z, x_b, y_binary)\n\n        if feasible:\n            uH = z\n            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n        else:\n            uL = z\n\n    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values\n\n# Train a classifier for each digit\nfor digit in range(10):\n    print(f\"Training classifier for digit {digit}...\")\n\n    y_subset = cp.array(y_subset)\n\n    # Assign labels: Positive for the current digit, negative for others\n    y_binary = (y_subset == digit).astype(int)\n\n    # Scale binary labels to larger values\n    # Positive class = 5, Negative class = 10\n    y_binary = np.where(y_binary == 1, 5, 10)\n\n    print(f\"y_binary =\", y_binary)\n    print(f\"y_subset =\", y_subset)\n\n    # Bisection parameters\n    uL = 0  # Initial lower bound\n    uH = 5000  # Initial upper bound\n    precision = 1e-6 # Precision threshold\n\n    # Run bisection loop\n    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(x_b, y_binary, uL, uH, precision)\n\n    # Print results\n    print(f\"Number of Iterations: {len(z_values)}\")\n    # print(f\"z Values in all Iterations: {z_values}\")\n    print(f\"Optimal z (Maximum Deviation): {optimal_z}\")\n\n    # # Plot convergence of z values\n    # plt.figure(figsize=(8, 6))\n    # plt.plot(range(len(z_values)), z_values, marker='o', linestyle='-')\n    # plt.xlabel(\"Iteration\")\n    # plt.ylabel(\"z Value\")\n    # plt.title(\"Convergence of z Values\")\n    # plt.grid(True)\n    # plt.show()\n\n    print(f\"Optimized Coefficients (Numerator Î±): {optimal_alpha}\")\n    print(f\"Optimized Coefficients (Denominator Î²): {optimal_beta}\")\n    print(f\"Optimal Î¸: {optimal_theta}\")\n    \n    # print(f\"rational_function =\", rational_function(x_b[0], optimal_alpha, optimal_beta))\n\n    # Save the model\n    model = {\n        \"alpha\": optimal_alpha,\n        \"beta\": optimal_beta,\n        \"theta\": optimal_theta,\n        \"n_components\": n_components\n    }\n\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"wb\") as file:\n        pickle.dump(model, file)\n\n    print(f\"Model for digit {digit} saved at {models_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T10:32:48.796332Z","iopub.execute_input":"2024-12-16T10:32:48.796668Z"}},"outputs":[{"name":"stdout","text":"Training classifier for digit 0...\ny_binary = [10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10\n 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10  5 10  5 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5  5 10 10 10 10 10 10\n 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10\n  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10\n 10 10 10 10 10  5 10 10 10 10  5  5 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10  5 10 10  5 10  5 10  5 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5  5 10 10 10\n 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n  5 10 10 10 10 10 10 10 10 10 10 10 10  5 10  5 10 10 10 10 10 10 10 10\n 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10  5 10 10 10 10 10 10\n 10 10 10 10  5  5 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10\n  5 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10  5 10  5 10 10 10 10 10 10  5 10  5 10 10  5 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10  5  5 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10\n 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10  5  5  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10\n 10 10 10 10 10 10  5 10 10 10 10 10 10 10  5 10  5  5 10 10 10 10 10 10\n 10 10  5  5 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10  5  5 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10  5 10\n 10 10  5  5 10 10 10 10 10  5 10 10 10 10  5 10 10 10  5 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10  5  5 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10\n 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10  5 10 10\n 10 10  5 10 10 10 10  5  5 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10  5 10 10 10 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10  5 10  5 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10  5 10 10  5 10 10 10 10  5\n 10 10 10 10 10 10 10  5 10 10 10 10 10  5 10 10  5 10 10 10 10 10  5 10\n 10 10 10 10 10 10 10 10 10  5 10 10  5 10 10 10  5 10  5 10  5 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10]\ny_subset = [4 6 5 8 0 4 5 5 1 4 3 7 7 6 4 9 1 9 7 6 3 3 8 1 7 6 3 8 6 7 6 4 1 4 2 3 5\n 0 3 1 9 6 8 2 7 2 7 7 7 5 2 0 2 8 4 8 5 9 4 1 2 6 2 5 9 0 2 8 3 1 7 2 3 3\n 3 2 4 2 2 3 5 4 4 6 7 6 0 9 3 5 1 2 9 3 5 3 7 1 6 9 2 9 5 8 8 2 1 5 9 3 0\n 5 8 1 7 9 0 6 0 2 9 2 3 2 4 1 3 4 4 2 2 1 8 2 1 3 0 0 1 5 1 5 1 7 7 7 7 7\n 4 0 2 8 5 5 3 7 5 6 2 0 9 9 1 3 5 8 8 5 0 5 6 6 4 7 4 4 7 7 9 8 9 8 3 8 8\n 3 7 4 7 2 9 3 9 4 9 4 9 7 1 4 3 8 6 9 5 8 7 9 1 1 5 4 8 1 0 2 2 4 9 4 7 0\n 2 7 5 7 0 0 1 2 4 8 3 4 2 2 1 8 3 7 5 6 4 4 7 6 2 5 8 9 3 7 9 0 6 3 6 3 0\n 2 5 1 4 2 1 9 8 1 9 5 3 2 3 0 2 4 0 3 0 4 0 9 6 5 9 3 1 6 5 6 6 3 7 9 6 3\n 9 5 9 1 6 2 1 8 8 1 4 0 0 6 7 4 6 7 4 4 4 9 7 2 0 5 9 7 3 6 5 6 8 8 4 9 3\n 8 5 7 0 3 7 9 6 6 3 5 8 3 3 2 3 0 3 0 2 1 1 5 1 4 9 1 1 6 9 1 0 3 2 4 8 6\n 5 3 9 5 5 2 6 3 7 3 1 6 9 8 8 1 1 4 2 1 7 6 4 9 5 6 9 0 4 8 3 0 1 2 5 8 8\n 5 3 5 4 4 0 0 9 7 9 9 0 3 9 7 7 2 3 5 2 3 3 9 2 9 0 8 7 3 2 5 0 9 7 7 8 5\n 4 5 6 2 3 1 5 7 3 7 5 6 3 1 0 9 0 9 2 7 8 4 8 0 8 0 1 1 0 2 5 8 7 3 2 9 6\n 7 8 4 7 6 5 3 6 0 0 4 7 5 7 4 9 9 7 5 8 4 6 6 6 5 2 8 1 6 3 6 5 5 9 2 5 8\n 5 7 3 9 8 0 9 6 4 5 7 8 5 8 6 0 5 4 5 8 3 7 6 7 1 5 8 6 7 1 8 6 7 4 7 3 2\n 5 0 0 0 1 9 8 8 2 3 9 1 4 1 3 5 1 1 2 0 9 2 5 6 2 2 1 0 1 7 4 1 9 5 7 0 8\n 0 0 2 5 6 4 8 7 3 4 0 0 8 8 3 8 8 2 2 0 1 2 6 5 0 9 6 0 0 4 8 3 9 6 6 1 2\n 4 3 6 8 6 4 2 3 9 1 2 2 6 1 8 0 1 7 9 7 8 9 2 3 1 6 9 5 3 1 0 8 8 9 3 8 4\n 1 9 8 8 0 4 6 9 0 0 8 5 3 8 6 0 6 4 3 8 0 7 2 8 0 4 3 2 7 3 2 5 5 3 1 7 2\n 7 8 1 4 2 1 1 8 1 2 6 7 9 4 1 7 6 1 2 1 4 5 7 8 7 7 2 6 1 3 1 2 5 3 3 4 9\n 4 3 4 5 1 2 0 0 9 5 9 1 1 8 9 7 5 8 8 3 8 0 4 7 8 3 4 5 8 0 9 8 9 5 8 2 3\n 3 0 2 1 7 6 9 9 2 9 2 5 0 8 9 9 8 0 4 2 5 2 0 0 4 2 4 1 5 4 6 0 3 6 1 4 0\n 8 2 2 5 6 9 6 4 6 7 7 6 3 3 1 7 5 7 5 8 7 6 6 2 8 6 3 5 3 0 6 2 6 1 0 6 5\n 4 4 6 4 7 3 0 2 1 7 2 5 1 7 1 6 8 1 4 4 7 1 0 2 9 2 2 4 7 0 6 0 5 3 6 8 5\n 6 2 2 4 9 9 9 3 6 1 9 0 2 4 9 0 7 3 0 8 6 1 1 0 6 7 8 9 4 5 3 0 6 9 4 5 7\n 0 1 5 0 8 4 1 4 6 0 6 9 3 4 9 8 4 9 5 1 0 9 3 0 9 9 9 0 6 0 6 0 6 7 2 9 5\n 7 7 1 6 4 8 8 5 2 1 7 1 5 4 4 1 0 3 5 1 6 3 7 4 7 5 6 9 6 4 1 7 8 8 4 0 4\n 2]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 7.5e-06  0.0e+00  0.0e+00 -0.0e+00  0.0e+00  0.0e+00 -0.0e+00 -0.0e+00\n -0.0e+00 -0.0e+00  0.0e+00 -0.0e+00 -0.0e+00  0.0e+00  0.0e+00  0.0e+00\n  0.0e+00 -0.0e+00  0.0e+00 -0.0e+00  0.0e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimal Î¸: 2.499999417923368e-06\nModel for digit 0 saved at /kaggle/working/models/\nTraining classifier for digit 1...\ny_binary = [10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10  5 10 10 10 10 10 10  5\n 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10  5 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10\n 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10  5 10 10 10 10 10 10\n 10 10 10 10 10  5 10 10 10 10 10  5 10 10  5 10 10 10  5 10  5 10  5 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10  5  5 10 10 10  5 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10  5 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10\n  5 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10\n 10 10 10 10 10 10 10 10 10 10 10  5 10 10  5 10 10  5 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5  5 10  5 10 10  5\n  5 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10\n 10  5  5 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10\n 10  5 10 10 10 10 10 10 10 10 10 10 10 10  5  5 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10 10 10\n 10 10 10 10 10 10 10  5 10 10 10 10 10 10  5 10  5 10 10  5  5 10 10 10\n 10 10 10 10 10  5 10  5 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10  5 10 10 10 10 10 10 10 10 10 10  5 10 10 10  5 10 10  5 10 10\n 10 10 10 10 10  5 10 10 10 10  5 10 10 10 10 10 10 10  5 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10  5 10 10 10 10  5 10 10  5  5 10  5 10 10 10 10 10  5 10 10\n  5 10  5 10 10 10 10 10 10 10 10  5 10  5 10 10 10 10 10 10 10 10 10 10\n  5 10 10 10 10 10 10  5  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10  5 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10  5\n 10  5 10 10  5 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10  5  5 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10 10 10\n 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10  5 10 10 10 10 10 10  5 10  5 10 10 10  5 10 10 10  5 10 10\n 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10]\ny_subset = [4 6 5 8 0 4 5 5 1 4 3 7 7 6 4 9 1 9 7 6 3 3 8 1 7 6 3 8 6 7 6 4 1 4 2 3 5\n 0 3 1 9 6 8 2 7 2 7 7 7 5 2 0 2 8 4 8 5 9 4 1 2 6 2 5 9 0 2 8 3 1 7 2 3 3\n 3 2 4 2 2 3 5 4 4 6 7 6 0 9 3 5 1 2 9 3 5 3 7 1 6 9 2 9 5 8 8 2 1 5 9 3 0\n 5 8 1 7 9 0 6 0 2 9 2 3 2 4 1 3 4 4 2 2 1 8 2 1 3 0 0 1 5 1 5 1 7 7 7 7 7\n 4 0 2 8 5 5 3 7 5 6 2 0 9 9 1 3 5 8 8 5 0 5 6 6 4 7 4 4 7 7 9 8 9 8 3 8 8\n 3 7 4 7 2 9 3 9 4 9 4 9 7 1 4 3 8 6 9 5 8 7 9 1 1 5 4 8 1 0 2 2 4 9 4 7 0\n 2 7 5 7 0 0 1 2 4 8 3 4 2 2 1 8 3 7 5 6 4 4 7 6 2 5 8 9 3 7 9 0 6 3 6 3 0\n 2 5 1 4 2 1 9 8 1 9 5 3 2 3 0 2 4 0 3 0 4 0 9 6 5 9 3 1 6 5 6 6 3 7 9 6 3\n 9 5 9 1 6 2 1 8 8 1 4 0 0 6 7 4 6 7 4 4 4 9 7 2 0 5 9 7 3 6 5 6 8 8 4 9 3\n 8 5 7 0 3 7 9 6 6 3 5 8 3 3 2 3 0 3 0 2 1 1 5 1 4 9 1 1 6 9 1 0 3 2 4 8 6\n 5 3 9 5 5 2 6 3 7 3 1 6 9 8 8 1 1 4 2 1 7 6 4 9 5 6 9 0 4 8 3 0 1 2 5 8 8\n 5 3 5 4 4 0 0 9 7 9 9 0 3 9 7 7 2 3 5 2 3 3 9 2 9 0 8 7 3 2 5 0 9 7 7 8 5\n 4 5 6 2 3 1 5 7 3 7 5 6 3 1 0 9 0 9 2 7 8 4 8 0 8 0 1 1 0 2 5 8 7 3 2 9 6\n 7 8 4 7 6 5 3 6 0 0 4 7 5 7 4 9 9 7 5 8 4 6 6 6 5 2 8 1 6 3 6 5 5 9 2 5 8\n 5 7 3 9 8 0 9 6 4 5 7 8 5 8 6 0 5 4 5 8 3 7 6 7 1 5 8 6 7 1 8 6 7 4 7 3 2\n 5 0 0 0 1 9 8 8 2 3 9 1 4 1 3 5 1 1 2 0 9 2 5 6 2 2 1 0 1 7 4 1 9 5 7 0 8\n 0 0 2 5 6 4 8 7 3 4 0 0 8 8 3 8 8 2 2 0 1 2 6 5 0 9 6 0 0 4 8 3 9 6 6 1 2\n 4 3 6 8 6 4 2 3 9 1 2 2 6 1 8 0 1 7 9 7 8 9 2 3 1 6 9 5 3 1 0 8 8 9 3 8 4\n 1 9 8 8 0 4 6 9 0 0 8 5 3 8 6 0 6 4 3 8 0 7 2 8 0 4 3 2 7 3 2 5 5 3 1 7 2\n 7 8 1 4 2 1 1 8 1 2 6 7 9 4 1 7 6 1 2 1 4 5 7 8 7 7 2 6 1 3 1 2 5 3 3 4 9\n 4 3 4 5 1 2 0 0 9 5 9 1 1 8 9 7 5 8 8 3 8 0 4 7 8 3 4 5 8 0 9 8 9 5 8 2 3\n 3 0 2 1 7 6 9 9 2 9 2 5 0 8 9 9 8 0 4 2 5 2 0 0 4 2 4 1 5 4 6 0 3 6 1 4 0\n 8 2 2 5 6 9 6 4 6 7 7 6 3 3 1 7 5 7 5 8 7 6 6 2 8 6 3 5 3 0 6 2 6 1 0 6 5\n 4 4 6 4 7 3 0 2 1 7 2 5 1 7 1 6 8 1 4 4 7 1 0 2 9 2 2 4 7 0 6 0 5 3 6 8 5\n 6 2 2 4 9 9 9 3 6 1 9 0 2 4 9 0 7 3 0 8 6 1 1 0 6 7 8 9 4 5 3 0 6 9 4 5 7\n 0 1 5 0 8 4 1 4 6 0 6 9 3 4 9 8 4 9 5 1 0 9 3 0 9 9 9 0 6 0 6 0 6 7 2 9 5\n 7 7 1 6 4 8 8 5 2 1 7 1 5 4 4 1 0 3 5 1 6 3 7 4 7 5 6 9 6 4 1 7 8 8 4 0 4\n 2]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 7.5e-06 -0.0e+00  0.0e+00 -0.0e+00 -0.0e+00 -0.0e+00 -0.0e+00 -0.0e+00\n -0.0e+00 -0.0e+00 -0.0e+00 -0.0e+00  0.0e+00 -0.0e+00  0.0e+00  0.0e+00\n -0.0e+00 -0.0e+00 -0.0e+00  0.0e+00  0.0e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00 -0.e+00  0.e+00  0.e+00  0.e+00  0.e+00 -0.e+00  0.e+00\n -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimal Î¸: 2.499999417923391e-06\nModel for digit 1 saved at /kaggle/working/models/\nTraining classifier for digit 2...\ny_binary = [10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10  5 10  5 10 10\n 10 10  5 10  5 10 10 10 10 10 10 10  5 10  5 10 10 10  5 10 10 10 10  5\n 10 10 10  5 10  5  5 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10\n 10 10 10 10  5 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10  5\n 10  5 10  5 10 10 10 10 10  5  5 10 10  5 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10  5 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5\n  5 10 10 10 10 10  5 10 10 10 10 10 10  5 10 10 10 10  5  5 10 10 10 10\n 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10  5\n 10 10 10 10 10 10 10  5 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10 10 10 10 10 10\n 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10\n 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10  5 10 10 10  5 10\n 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10  5 10 10\n  5 10 10  5  5 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10  5  5 10 10  5 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10  5 10 10 10 10 10 10  5 10 10 10  5  5 10 10 10 10 10 10 10\n 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10\n  5 10 10 10 10 10  5 10 10 10 10  5 10 10 10 10  5 10 10 10 10 10 10 10\n 10  5 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10 10 10 10 10 10 10 10\n 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10  5 10 10 10  5 10 10 10 10 10  5 10  5 10 10 10 10\n 10 10 10 10  5 10  5 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10  5\n  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10\n 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10  5 10 10\n 10 10 10 10 10 10 10 10 10 10  5 10  5  5 10 10 10 10 10 10 10 10 10 10\n 10  5  5 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5\n 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5]\ny_subset = [4 6 5 8 0 4 5 5 1 4 3 7 7 6 4 9 1 9 7 6 3 3 8 1 7 6 3 8 6 7 6 4 1 4 2 3 5\n 0 3 1 9 6 8 2 7 2 7 7 7 5 2 0 2 8 4 8 5 9 4 1 2 6 2 5 9 0 2 8 3 1 7 2 3 3\n 3 2 4 2 2 3 5 4 4 6 7 6 0 9 3 5 1 2 9 3 5 3 7 1 6 9 2 9 5 8 8 2 1 5 9 3 0\n 5 8 1 7 9 0 6 0 2 9 2 3 2 4 1 3 4 4 2 2 1 8 2 1 3 0 0 1 5 1 5 1 7 7 7 7 7\n 4 0 2 8 5 5 3 7 5 6 2 0 9 9 1 3 5 8 8 5 0 5 6 6 4 7 4 4 7 7 9 8 9 8 3 8 8\n 3 7 4 7 2 9 3 9 4 9 4 9 7 1 4 3 8 6 9 5 8 7 9 1 1 5 4 8 1 0 2 2 4 9 4 7 0\n 2 7 5 7 0 0 1 2 4 8 3 4 2 2 1 8 3 7 5 6 4 4 7 6 2 5 8 9 3 7 9 0 6 3 6 3 0\n 2 5 1 4 2 1 9 8 1 9 5 3 2 3 0 2 4 0 3 0 4 0 9 6 5 9 3 1 6 5 6 6 3 7 9 6 3\n 9 5 9 1 6 2 1 8 8 1 4 0 0 6 7 4 6 7 4 4 4 9 7 2 0 5 9 7 3 6 5 6 8 8 4 9 3\n 8 5 7 0 3 7 9 6 6 3 5 8 3 3 2 3 0 3 0 2 1 1 5 1 4 9 1 1 6 9 1 0 3 2 4 8 6\n 5 3 9 5 5 2 6 3 7 3 1 6 9 8 8 1 1 4 2 1 7 6 4 9 5 6 9 0 4 8 3 0 1 2 5 8 8\n 5 3 5 4 4 0 0 9 7 9 9 0 3 9 7 7 2 3 5 2 3 3 9 2 9 0 8 7 3 2 5 0 9 7 7 8 5\n 4 5 6 2 3 1 5 7 3 7 5 6 3 1 0 9 0 9 2 7 8 4 8 0 8 0 1 1 0 2 5 8 7 3 2 9 6\n 7 8 4 7 6 5 3 6 0 0 4 7 5 7 4 9 9 7 5 8 4 6 6 6 5 2 8 1 6 3 6 5 5 9 2 5 8\n 5 7 3 9 8 0 9 6 4 5 7 8 5 8 6 0 5 4 5 8 3 7 6 7 1 5 8 6 7 1 8 6 7 4 7 3 2\n 5 0 0 0 1 9 8 8 2 3 9 1 4 1 3 5 1 1 2 0 9 2 5 6 2 2 1 0 1 7 4 1 9 5 7 0 8\n 0 0 2 5 6 4 8 7 3 4 0 0 8 8 3 8 8 2 2 0 1 2 6 5 0 9 6 0 0 4 8 3 9 6 6 1 2\n 4 3 6 8 6 4 2 3 9 1 2 2 6 1 8 0 1 7 9 7 8 9 2 3 1 6 9 5 3 1 0 8 8 9 3 8 4\n 1 9 8 8 0 4 6 9 0 0 8 5 3 8 6 0 6 4 3 8 0 7 2 8 0 4 3 2 7 3 2 5 5 3 1 7 2\n 7 8 1 4 2 1 1 8 1 2 6 7 9 4 1 7 6 1 2 1 4 5 7 8 7 7 2 6 1 3 1 2 5 3 3 4 9\n 4 3 4 5 1 2 0 0 9 5 9 1 1 8 9 7 5 8 8 3 8 0 4 7 8 3 4 5 8 0 9 8 9 5 8 2 3\n 3 0 2 1 7 6 9 9 2 9 2 5 0 8 9 9 8 0 4 2 5 2 0 0 4 2 4 1 5 4 6 0 3 6 1 4 0\n 8 2 2 5 6 9 6 4 6 7 7 6 3 3 1 7 5 7 5 8 7 6 6 2 8 6 3 5 3 0 6 2 6 1 0 6 5\n 4 4 6 4 7 3 0 2 1 7 2 5 1 7 1 6 8 1 4 4 7 1 0 2 9 2 2 4 7 0 6 0 5 3 6 8 5\n 6 2 2 4 9 9 9 3 6 1 9 0 2 4 9 0 7 3 0 8 6 1 1 0 6 7 8 9 4 5 3 0 6 9 4 5 7\n 0 1 5 0 8 4 1 4 6 0 6 9 3 4 9 8 4 9 5 1 0 9 3 0 9 9 9 0 6 0 6 0 6 7 2 9 5\n 7 7 1 6 4 8 8 5 2 1 7 1 5 4 4 1 0 3 5 1 6 3 7 4 7 5 6 9 6 4 1 7 8 8 4 0 4\n 2]\nNumber of Iterations: 33\nOptimal z (Maximum Deviation): 5.820766091346741e-07\nOptimized Coefficients (Numerator Î±): [ 7.5e-06  0.0e+00 -0.0e+00  0.0e+00 -0.0e+00  0.0e+00 -0.0e+00 -0.0e+00\n  0.0e+00  0.0e+00 -0.0e+00 -0.0e+00 -0.0e+00  0.0e+00 -0.0e+00  0.0e+00\n  0.0e+00 -0.0e+00  0.0e+00  0.0e+00 -0.0e+00]\nOptimized Coefficients (Denominator Î²): [ 1.e-06 -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00]\nOptimal Î¸: 2.4999994179233914e-06\nModel for digit 2 saved at /kaggle/working/models/\nTraining classifier for digit 3...\ny_binary = [10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10  5  5 10 10\n 10 10  5 10 10 10 10 10 10 10 10  5 10 10  5 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10\n  5  5  5 10 10 10 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10  5\n 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10\n 10 10  5 10 10 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10  5 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10  5 10 10 10 10 10  5\n 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10  5 10\n 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10  5 10 10 10 10 10 10\n 10 10 10 10 10 10  5 10  5 10 10 10 10  5 10 10 10 10 10 10 10  5 10 10\n 10 10 10  5 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10  5 10 10 10\n 10  5 10 10 10 10  5 10 10  5  5 10  5 10  5 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10  5 10 10 10 10 10  5 10 10 10 10 10  5 10  5 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10\n  5 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10  5  5 10 10 10\n 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10  5 10 10 10\n  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10\n 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10  5 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10  5 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n  5 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5\n 10 10 10 10 10 10  5 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10  5 10 10 10 10  5 10 10 10 10 10  5 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10  5 10 10 10 10 10  5 10 10 10 10 10 10 10  5 10 10  5\n 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10  5  5 10 10 10  5 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10  5 10 10\n 10 10 10 10 10 10 10 10  5  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10  5  5 10 10 10 10 10 10 10 10 10 10 10 10\n  5 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10\n 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10\n 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n 10  5 10 10 10 10 10 10 10 10 10  5 10 10 10 10 10 10 10 10 10 10 10 10\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10  5 10 10 10  5\n 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\ny_subset = [4 6 5 8 0 4 5 5 1 4 3 7 7 6 4 9 1 9 7 6 3 3 8 1 7 6 3 8 6 7 6 4 1 4 2 3 5\n 0 3 1 9 6 8 2 7 2 7 7 7 5 2 0 2 8 4 8 5 9 4 1 2 6 2 5 9 0 2 8 3 1 7 2 3 3\n 3 2 4 2 2 3 5 4 4 6 7 6 0 9 3 5 1 2 9 3 5 3 7 1 6 9 2 9 5 8 8 2 1 5 9 3 0\n 5 8 1 7 9 0 6 0 2 9 2 3 2 4 1 3 4 4 2 2 1 8 2 1 3 0 0 1 5 1 5 1 7 7 7 7 7\n 4 0 2 8 5 5 3 7 5 6 2 0 9 9 1 3 5 8 8 5 0 5 6 6 4 7 4 4 7 7 9 8 9 8 3 8 8\n 3 7 4 7 2 9 3 9 4 9 4 9 7 1 4 3 8 6 9 5 8 7 9 1 1 5 4 8 1 0 2 2 4 9 4 7 0\n 2 7 5 7 0 0 1 2 4 8 3 4 2 2 1 8 3 7 5 6 4 4 7 6 2 5 8 9 3 7 9 0 6 3 6 3 0\n 2 5 1 4 2 1 9 8 1 9 5 3 2 3 0 2 4 0 3 0 4 0 9 6 5 9 3 1 6 5 6 6 3 7 9 6 3\n 9 5 9 1 6 2 1 8 8 1 4 0 0 6 7 4 6 7 4 4 4 9 7 2 0 5 9 7 3 6 5 6 8 8 4 9 3\n 8 5 7 0 3 7 9 6 6 3 5 8 3 3 2 3 0 3 0 2 1 1 5 1 4 9 1 1 6 9 1 0 3 2 4 8 6\n 5 3 9 5 5 2 6 3 7 3 1 6 9 8 8 1 1 4 2 1 7 6 4 9 5 6 9 0 4 8 3 0 1 2 5 8 8\n 5 3 5 4 4 0 0 9 7 9 9 0 3 9 7 7 2 3 5 2 3 3 9 2 9 0 8 7 3 2 5 0 9 7 7 8 5\n 4 5 6 2 3 1 5 7 3 7 5 6 3 1 0 9 0 9 2 7 8 4 8 0 8 0 1 1 0 2 5 8 7 3 2 9 6\n 7 8 4 7 6 5 3 6 0 0 4 7 5 7 4 9 9 7 5 8 4 6 6 6 5 2 8 1 6 3 6 5 5 9 2 5 8\n 5 7 3 9 8 0 9 6 4 5 7 8 5 8 6 0 5 4 5 8 3 7 6 7 1 5 8 6 7 1 8 6 7 4 7 3 2\n 5 0 0 0 1 9 8 8 2 3 9 1 4 1 3 5 1 1 2 0 9 2 5 6 2 2 1 0 1 7 4 1 9 5 7 0 8\n 0 0 2 5 6 4 8 7 3 4 0 0 8 8 3 8 8 2 2 0 1 2 6 5 0 9 6 0 0 4 8 3 9 6 6 1 2\n 4 3 6 8 6 4 2 3 9 1 2 2 6 1 8 0 1 7 9 7 8 9 2 3 1 6 9 5 3 1 0 8 8 9 3 8 4\n 1 9 8 8 0 4 6 9 0 0 8 5 3 8 6 0 6 4 3 8 0 7 2 8 0 4 3 2 7 3 2 5 5 3 1 7 2\n 7 8 1 4 2 1 1 8 1 2 6 7 9 4 1 7 6 1 2 1 4 5 7 8 7 7 2 6 1 3 1 2 5 3 3 4 9\n 4 3 4 5 1 2 0 0 9 5 9 1 1 8 9 7 5 8 8 3 8 0 4 7 8 3 4 5 8 0 9 8 9 5 8 2 3\n 3 0 2 1 7 6 9 9 2 9 2 5 0 8 9 9 8 0 4 2 5 2 0 0 4 2 4 1 5 4 6 0 3 6 1 4 0\n 8 2 2 5 6 9 6 4 6 7 7 6 3 3 1 7 5 7 5 8 7 6 6 2 8 6 3 5 3 0 6 2 6 1 0 6 5\n 4 4 6 4 7 3 0 2 1 7 2 5 1 7 1 6 8 1 4 4 7 1 0 2 9 2 2 4 7 0 6 0 5 3 6 8 5\n 6 2 2 4 9 9 9 3 6 1 9 0 2 4 9 0 7 3 0 8 6 1 1 0 6 7 8 9 4 5 3 0 6 9 4 5 7\n 0 1 5 0 8 4 1 4 6 0 6 9 3 4 9 8 4 9 5 1 0 9 3 0 9 9 9 0 6 0 6 0 6 7 2 9 5\n 7 7 1 6 4 8 8 5 2 1 7 1 5 4 4 1 0 3 5 1 6 3 7 4 7 5 6 9 6 4 1 7 8 8 4 0 4\n 2]\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"### Testing","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport pickle\nimport matplotlib.pyplot as plt\n\n#------------------------------------------\n# Define the rational function\ndef rational_function(x, alpha, beta):\n    \"\"\"\n    r(x) = (Î±_0 + Î±_1*x1**1 + Î±_2*x2**2 + ...) / \n           (Î²_0 + Î²_1*x1**1 + Î²_2*x2**2 + ...).\n    \"\"\"\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n#------------------------------------------\n# Load MNIST test data (10,000 images)\nfrom keras.datasets import mnist\n(_, _), (x_test, y_test) = mnist.load_data()\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#------------------------------------------\nsubset_size = 10000\n# Subset the test dataset\nx_test_subset = x_test[:subset_size]\ny_test_subset = y_test[:subset_size]\nprint(f\"Shape of test subset: {x_test_subset.shape}\")\n\n#------------------------------------------\n# Flatten the test dataset (convert from 28x28 to 784)\nx_test_subset = x_test_subset.reshape(x_test_subset.shape[0], -1)\nprint(f\"Shape of flattened test subset: {x_test_subset.shape}\")\n\n#------------------------------------------\n# Load PCA instance\nwith open(\"models/pca_model.pkl\", \"rb\") as file:\n    pca = pickle.load(file)  # Load the PCA model trained on training data\n    \nx_test_pca = pca.transform(x_test_subset)  # Transform test data using the saved PCA\n\nprint(f\"Shape of PCA-transformed test subset: {x_test_pca.shape}\")\n\n# # Apply PCA to test data\n# n_components = 77  # Desired number of components\n# pca = PCA(n_components=n_components)\n# x_test_pca = pca.fit_transform(x_test_subset)\n\n#------------------------------------------\n# Thresholding: Convert PCA-transformed data to binary (0s and 1s)\nthreshold_value = 0\nx_test_binary = (x_test_pca > threshold_value).astype(int)\nprint(f\"Binary thresholded test subset: {x_test_binary.shape}\")\n\n#------------------------------------------\n# Load the saved models and test\nmodels_dir = \"/kaggle/working/models/\"  # Update based on your environment\naccuracies = []\n\nfor digit in range(10):\n    # Load model for each digit\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n    theta = model[\"theta\"]\n\n    # Evaluate the rational function for each test data point\n    y_predicted = [\n        rational_function(x, alpha, beta) for x in x_test_binary\n    ]\n\n    # Convert predictions to binary (1 for this digit, 0 for others)\n    y_pred_binary = np.array(y_predicted) > 0.5\n    y_true_binary = y_test_subset == digit\n\n    # Calculate accuracy for this digit\n    accuracy = np.mean(y_pred_binary == y_true_binary)\n    accuracies.append(accuracy)\n\n    print(f\"Accuracy for digit {digit}: {accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Calculate and print overall accuracy\noverall_accuracy = np.mean(accuracies)\nprint(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Plotting accuracies for each digit\nplt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\nplt.xlabel(\"Digits\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy for Each Digit\")\nplt.xticks(range(10))\nplt.ylim(0, 1)\nplt.legend()\nplt.grid(True)\nplt.show()\n\nprint(f\"y_pred_binary =\", y_pred_binary)\nprint(f\"y_true_binary =\", y_true_binary)\n\nprint(f\"y_pred_binary.shape =\", y_pred_binary.shape)\nprint(f\"y_true_binary.shape =\", y_true_binary.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Debugging: Check rational function output for a specific index\nspecific_index = 333  # Change this to the desired index\nif specific_index < len(x_b):\n    rational_output = rational_function(x_b[specific_index], optimal_alpha, optimal_beta)\n    prediction = 1 if rational_output > 0.5 else 0  # Binary prediction\n    b_label = y_binary[specific_index]  # Actual label (0 or 1)\n    actual_label = y_subset[specific_index]\n    \n    print(f\"Input at Index {specific_index}: {x_b[specific_index]}\")\n    print(f\"Rational Output: {rational_output:.4f}, b_Label: {b_label}, Prediction: {prediction}, Actual Label:{actual_label}\")\nelse:\n    print(f\"Index {specific_index} is out of bounds. Max index: {len(x_b)-1}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ss","metadata":{}},{"cell_type":"code","source":"with open(f\"{models_dir}classifier_8.pkl\", \"rb\") as file:\n    model = pickle.load(file)\n\nalpha = model[\"alpha\"]\nbeta = model[\"beta\"]\ntheta = model[\"theta\"]\n\nx = x_test_binary[80]\nhs = rational_function(x, alpha, beta)\n\n\nprint(f\"hs =\", hs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"gg","metadata":{}},{"cell_type":"code","source":"def visual_cross_check_rational_function(x_test_subset, x_test_binary, y_test_subset, models_dir):\n    \"\"\"\n    Visual cross-check for rational function output.\n    Displays the selected test image, the actual label, and the rational function's output.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    # Step 1: Create subsets for each digit\n    digit_subsets = {}\n    digit_indices = {}\n    for digit in range(10):\n        indices = np.where(y_test_subset == digit)[0]\n        digit_subsets[digit] = x_test_binary[indices]\n        digit_indices[digit] = indices\n\n    # Step 2: Select digit and index\n    selected_digit = int(input(\"Enter the digit (0-9) to cross-check: \"))\n    if selected_digit not in digit_subsets:\n        print(f\"Invalid digit {selected_digit}.\")\n        return\n\n    print(f\"Number of images for digit {selected_digit}: {len(digit_subsets[selected_digit])}\")\n    selected_index = int(input(f\"Enter the index (0-{len(digit_subsets[selected_digit]) - 1}) to select an image: \"))\n    if selected_index < 0 or selected_index >= len(digit_subsets[selected_digit]):\n        print(f\"Invalid index {selected_index}.\")\n        return\n\n    selected_image_binary = digit_subsets[selected_digit][selected_index]\n    original_image_index = digit_indices[selected_digit][selected_index]\n    selected_image_original = x_test_subset[original_image_index]\n\n    # Step 3: Load the corresponding model\n    with open(f\"{models_dir}classifier_{selected_digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n\n    # Step 4: Evaluate the rational function\n    rational_output = rational_function(selected_image_binary, alpha, beta)\n    prediction = 1 if rational_output > 0.5 else 0\n\n    # Step 5: Display the image, label, and rational function output\n    plt.figure(figsize=(4, 4))\n    plt.imshow(selected_image_original.reshape(28, 28), cmap=\"gray\")  # Reshape to 28x28\n    plt.title(f\"Digit: {selected_digit} | Prediction: {prediction} | Rational Output: {rational_output:.4f}\")\n    plt.axis(\"off\")\n    plt.show()\n\n# Main execution for visual cross-check\nif __name__ == \"__main__\":\n    # Visual cross-check\n    visual_cross_check_rational_function(x_test_subset, x_test_binary, y_test_subset, models_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
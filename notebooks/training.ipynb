{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"####  üçÅCheck Versions","metadata":{}},{"cell_type":"code","source":"# !python --version\n\nimport cupy as cp\ncp.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:08:58.153805Z","iopub.execute_input":"2024-12-19T16:08:58.154153Z","iopub.status.idle":"2024-12-19T16:09:00.085849Z","shell.execute_reply.started":"2024-12-19T16:08:58.154113Z","shell.execute_reply":"2024-12-19T16:09:00.084203Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'13.3.0'"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"#### üçÅ Create Directory","metadata":{}},{"cell_type":"code","source":"import os\n\nmodels_dir = \"/kaggle/working/models/\"\n\n# Ensure the directory exists\nos.makedirs(models_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:09:00.086935Z","iopub.execute_input":"2024-12-19T16:09:00.087326Z","iopub.status.idle":"2024-12-19T16:09:00.095394Z","shell.execute_reply.started":"2024-12-19T16:09:00.087293Z","shell.execute_reply":"2024-12-19T16:09:00.092043Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### üçÅ Preprocessing","metadata":{}},{"cell_type":"code","source":"# Import\nfrom keras.datasets import mnist\n(x_train, y_train), (_, _) = mnist.load_data()\nprint(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n\n#1 Flatten\nx_train_flat = x_train.reshape(x_train.shape[0], -1)\nprint(f\"x_train_flat shape: {x_train_flat.shape}, y_train shape: {y_train.shape}\")\n\n#2 Subsets\nsubset_size = 100\nx_train_subset = x_train_flat[:subset_size]\ny_train_subset = y_train[:subset_size]\nprint(f\"x_train_subset shape: {x_train_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\nimport pickle\nn_components = 2\npca = PCA(n_components=n_components)\nx_train_pca = pca.fit_transform(x_train_subset)\nprint(f\"x_train_pca shape: \", x_train_pca.shape)\n# Load PCA instance\nwith open(\"models/pca_model.pkl\", \"wb\") as file:\n    pickle.dump(pca, file)  # Save the fitted PCA model\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_train_norm = scaler.fit_transform(x_train_pca)\nprint(f\"x_train_norm shape: {x_train_norm.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:09:00.097824Z","iopub.execute_input":"2024-12-19T16:09:00.101109Z","iopub.status.idle":"2024-12-19T16:09:12.858272Z","shell.execute_reply.started":"2024-12-19T16:09:00.101071Z","shell.execute_reply":"2024-12-19T16:09:12.857296Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nx_train shape: (60000, 28, 28), y_train shape: (60000,)\nx_train_flat shape: (60000, 784), y_train shape: (60000,)\nx_train_subset shape: (100, 784)\nx_train_pca shape:  (100, 2)\nx_train_norm shape: (100, 2)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### [Training]","metadata":{}},{"cell_type":"code","source":"import pickle\nimport cupy as cp\nimport numpy as np\nfrom scipy.optimize import linprog\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Feasibility check function\ndef check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary):\n    num_data_points = x_train_norm.shape[0]\n    num_coefficients = n_components + 1  # (+1 for the first constant terms Œ±0 & Œ≤0)\n    delta = 1e-6  # a small positive value\n\n    # # Construct G(x) and H(x) matrices for numerator and denominator\n    # G = cp.zeros((num_data_points, num_coefficients))  # Numerator matrix\n    # H = cp.zeros((num_data_points, num_coefficients))  # Denominator matrix\n\n    # for i in range(num_data_points):\n    #   G[i, 0] = 1\n    #   H[i, 0] = 1\n    #   for j in range(num_coefficients-1):\n    #     G[i, j+1] = x_train_norm[i, j] ** (j+1)\n    #     H[i, j+1] = x_train_norm[i, j] ** (j+1)\n\n    # # print(f\"G: {G}\")\n    # # print(f\"G.shape =\", G.shape)\n    # # print(f\"H: {H}\")\n\n    #-----------------------------------------\n    def construct_G_H_matrices(x_train_norm, n, d):\n      import itertools\n      num_data_points = x_train_norm.shape[0]\n    \n      # Generate multi-indices\n      multi_indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n      num_coefficients = len(multi_indices)\n    \n      # Initialize G and H matrices\n      G = cp.zeros((num_data_points, num_coefficients))  # Numerator\n      H = cp.zeros((num_data_points, num_coefficients))  # Denominator\n    \n      # Construct G and H using multi-indices\n      for i in range(num_data_points):\n          for j, idx in enumerate(multi_indices):\n              term = cp.prod(cp.array([x_train_norm[i, k] ** idx[k] for k in range(n)]))\n              G[i, j] = term\n              H[i, j] = term  # G and H share the same multi-index logic\n      return G, H, multi_indices\n    \n    def generate_multi_indices(n, d):\n        indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n        return indices\n\n    num_data_points = x_train_norm.shape[0]\n    indices = generate_multi_indices(2, 2)\n    \n    num_coefficients = len(indices)\n    \n    G, H, multi_indices = construct_G_H_matrices(x_train_norm, 2, 2)\n    \n    # Construct constraints for Ax <= b\n    A = []\n    b = []\n\n    for i in range(num_data_points):\n        f_plus_z = y_binary[i] + z  # Upper bound\n        f_minus_z = y_binary[i] - z  # Lower bound\n\n        # Constraint 1: (f(xi) - z) * Œ≤^T H(xi) - Œ±^T G(xi) ‚â§ Œ∏\n        # (-G(xi))Œ±T + (f(xi) - z).H(xi)Œ≤T + (-1)Œ∏ ‚â§ 0\n        constraint_1 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Œ±\n        constraint_1[0:num_coefficients] = -G[i]\n        # (2) Coefficients of Œ≤\n        constraint_1[num_coefficients:2 * num_coefficients] = (f_minus_z) * H[i]\n        # (3) Coefficient of Œ∏ (last element)\n        constraint_1[-1] = -1\n        A.append(constraint_1)\n        b.append(0)\n\n        # Constraint 2: Œ±^T G(xi) + (-1).(f(xi) + z) * Œ≤^T H(xi) ‚â§ Œ∏\n        # G(xi).Œ±T + (-1)(f(xi) - z).H(xi)Œ≤T + (-1)Œ∏ ‚â§ 0\n        constraint_2 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Œ±\n        constraint_2[0:num_coefficients] = G[i]\n        # (2) Coefficients of Œ≤\n        constraint_2[num_coefficients:2 * num_coefficients] = -(f_plus_z) * H[i]\n        # (3) Coefficient of Œ∏ (last element)\n        constraint_2[-1] = -1\n        A.append(constraint_2)\n        b.append(0)\n\n        # Constraint 3: Œ≤^T H(x) ‚â• Œ¥\n        # (0)Œ±^T + (-H(x)) Œ≤^T + (0)Œ∏ ‚â§ -Œ¥\n        constraint_3 = cp.zeros(2 * num_coefficients + 1)\n        # Coefficient of Œ≤\n        constraint_3[num_coefficients:2 * num_coefficients] = -H[i]\n        A.append(constraint_3)\n        b.append(-delta)\n\n    # Convert CuPy arrays to NumPy arrays for SciPy\n    A = cp.asnumpy(cp.array(A))\n    b = cp.asnumpy(cp.array(b))\n\n    # Objective function to minimize Œ∏\n    c = cp.asnumpy(cp.zeros(2 * num_coefficients + 1))\n    c[-1] = 1  # Only Œ∏ has a coefficient in the objective function\n\n    # Solve the linear programming problem (methods: highs, revised simplex)\n    result = linprog(c, A_ub=A, b_ub=b, method=\"highs\")\n\n    # Check feasibility and return results\n    if result.success:\n        alpha_coefficients = result.x[:num_coefficients]\n        beta_coefficients = result.x[num_coefficients:2 * num_coefficients]\n        theta = result.x[-1]\n        return True, alpha_coefficients, beta_coefficients, theta\n    else:\n        return False, None, None, None\n\n\n# Bisection loop\ndef bisection_loop(x_train_norm, y_binary, uL, uH, precision):\n    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n    z_values = []\n\n    while uH - uL > precision:\n        z = (uL + uH) / 2\n        z_values.append(z)\n        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary)\n\n        if feasible:\n            uH = z\n            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n        else:\n            uL = z\n\n    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values\n\n# Train a classifier for each digit\nfor digit in range(10):\n    print(f\"Training classifier for digit {digit}...\")\n\n    # Assign labels: Positive for the current digit, negative for others\n    # y_binary = (y_train_subset == digit).astype(int)\n    y_binary = (y_train_subset == digit).astype(float)\n\n    # Scale binary labels to larger values\n    # Positive class = 2, Negative class = 4\n    y_binary = np.where(y_binary == 1, 2, 4)\n\n    # print(f\"y_binary =\", y_binary)\n    # print(f\"y_train_subset =\", y_train_subset)\n\n    # Bisection parameters\n    uL = 0  # Initial lower bound\n    uH = 500  # Initial upper bound\n    precision = 1e-6 # Precision threshold\n\n    # Run bisection loop\n    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(x_train_norm, y_binary, uL, uH, precision)\n\n    # Print results\n    print(f\"Number of Iterations: {len(z_values)}\")\n    # print(f\"z Values in all Iterations: {z_values}\")\n    print(f\"Optimal z (Maximum Deviation): {optimal_z}\")\n\n    # # Plot convergence of z values\n    # plt.figure(figsize=(8, 6))\n    # plt.plot(range(len(z_values)), z_values, marker='o', linestyle='-')\n    # plt.xlabel(\"Iteration\")\n    # plt.ylabel(\"z Value\")\n    # plt.title(\"Convergence of z Values\")\n    # plt.grid(True)\n    # plt.show()\n\n    print(f\"Optimized Coefficients (Numerator Œ±): {optimal_alpha}\")\n    print(f\"Optimized Coefficients (Denominator Œ≤): {optimal_beta}\")\n    print(f\"Optimal Œ∏: {optimal_theta}\")\n    \n    # print(f\"rational_function =\", rational_function(x_train_norm[0], optimal_alpha, optimal_beta))\n\n    # Save the model\n    model = {\n        \"alpha\": optimal_alpha,\n        \"beta\": optimal_beta,\n        \"theta\": optimal_theta,\n        \"n_components\": n_components\n    }\n\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"wb\") as file:\n        pickle.dump(model, file)\n\n    print(f\"Model for digit {digit} saved at {models_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:09:12.860272Z","iopub.execute_input":"2024-12-19T16:09:12.861279Z","iopub.status.idle":"2024-12-19T16:09:55.823215Z","shell.execute_reply.started":"2024-12-19T16:09:12.861240Z","shell.execute_reply":"2024-12-19T16:09:55.822228Z"}},"outputs":[{"name":"stdout","text":"Training classifier for digit 0...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [3.e-06 0.e+00 0.e+00 0.e+00 0.e+00 0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00]\nOptimal Œ∏: 9.999990686774199e-07\nModel for digit 0 saved at /kaggle/working/models/\nTraining classifier for digit 1...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06  0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00]\nOptimal Œ∏: 9.99999068677425e-07\nModel for digit 1 saved at /kaggle/working/models/\nTraining classifier for digit 2...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06  0.e+00 -0.e+00  0.e+00  0.e+00  0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00]\nOptimal Œ∏: 9.999990686774266e-07\nModel for digit 2 saved at /kaggle/working/models/\nTraining classifier for digit 3...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06  0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06  0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00]\nOptimal Œ∏: 9.999990686774254e-07\nModel for digit 3 saved at /kaggle/working/models/\nTraining classifier for digit 4...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00]\nOptimal Œ∏: 9.999990686774254e-07\nModel for digit 4 saved at /kaggle/working/models/\nTraining classifier for digit 5...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06  0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00]\nOptimal Œ∏: 9.999990686774146e-07\nModel for digit 5 saved at /kaggle/working/models/\nTraining classifier for digit 6...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06  0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00]\nOptimal Œ∏: 9.999990686774258e-07\nModel for digit 6 saved at /kaggle/working/models/\nTraining classifier for digit 7...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00]\nOptimal Œ∏: 9.999990686774273e-07\nModel for digit 7 saved at /kaggle/working/models/\nTraining classifier for digit 8...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06  0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00]\nOptimal Œ∏: 9.999990686774226e-07\nModel for digit 8 saved at /kaggle/working/models/\nTraining classifier for digit 9...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06  0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00]\nOptimal Œ∏: 9.999990686774254e-07\nModel for digit 9 saved at /kaggle/working/models/\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### [Testing]","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport pickle\nimport matplotlib.pyplot as plt\n\n# # Define the rational function\n# def rational_function(x, alpha, beta):\n#     \"\"\"\n#     r(x) = (Œ±_0 + Œ±_1*x1**1 + Œ±_2*x2**2 + ...) / \n#            (Œ≤_0 + Œ≤_1*x1**1 + Œ≤_2*x2**2 + ...).\n#     \"\"\"\n#     numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n#     denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n#     return numerator / denominator\n\n#-----------------------------------------------------\nimport itertools\nimport numpy as np\n\ndef generate_multi_indices(n, d):\n    indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n    return indices\n\ndef construct_polynomial(x, coefficients, indices):\n    polynomial_value = 0\n    for coeff, idx in zip(coefficients, indices):\n        term = coeff * np.prod([x[i] ** idx[i] for i in range(len(x))])\n        polynomial_value += term\n    return polynomial_value\n\ndef rational_function(x, alpha, beta, n, d):\n    indices = generate_multi_indices(n, d)\n\n    # Compute numerator and denominator\n    numerator = construct_polynomial(x, alpha, indices)\n    denominator = construct_polynomial(x, beta, indices)\n\n    # # Avoid division by zero\n    # if np.abs(denominator) < 1e-8:\n    #     denominator = 1e-8\n\n    return numerator / denominator\n\n#-----------------------------------------------------\n# Import\nfrom keras.datasets import mnist\n(_, _), (x_test, y_test) = mnist.load_data()\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#1 Flatten\nx_test = x_test.reshape(x_test.shape[0], -1)\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#2 Subsets\nsubset_size = 10000\nx_test_subset = x_test[:subset_size]\ny_test_subset = y_test[:subset_size]\nprint(f\"x_test_subset shape: {x_test_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\nimport pickle\nn_components = 2\npca = PCA(n_components=n_components)\nx_test_pca = pca.fit_transform(x_test_subset)\nprint(f\"x_test_pca shape: \", x_test_pca.shape)\n\n# # with training settings\n# with open(\"models/pca_model.pkl\", \"rb\") as file:\n#     pca = pickle.load(file)  # Load the PCA model trained on training data\n    \n# # Transform test data using the saved PCA\n# x_test_pca = pca.transform(x_test_subset)\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_test_norm = scaler.fit_transform(x_test_pca)\nprint(f\"x_test_norm shape: {x_test_norm.shape}\")\n\n#------------------------------------------\n# Load the saved models and test\nmodels_dir = \"/kaggle/working/models/\"  # Update based on your environment\naccuracies = []\n\n#------------------------------------------\nfor digit in range(10):\n    # Load model for each digit\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n    theta = model[\"theta\"]\n\n    n = 2\n    d = 2\n\n    # Evaluate the rational function for each test data point\n    y_predicted = [\n        rational_function(x, alpha, beta, n, d) for x in x_test_norm\n    ]\n\n    #y_predicted = [\n    #rational_function(x, alpha, beta, n, d) for x in x_test_norm\n    #]\n\n    # Convert predictions to binary (1 for this digit, 0 for others)\n    y_pred_binary = np.array(y_predicted) < 3\n    y_true_binary = y_test_subset == digit\n\n    # Calculate accuracy for this digit\n    accuracy = np.mean(y_pred_binary == y_true_binary)\n    accuracies.append(accuracy)\n\n    print(f\"Accuracy for digit {digit}: {accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Calculate and print overall accuracy\noverall_accuracy = np.mean(accuracies)\nprint(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Plotting accuracies for each digit\nplt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\nplt.xlabel(\"Digits\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy for Each Digit\")\nplt.xticks(range(10))\nplt.ylim(0, 1)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# print(f\"y_pred_binary =\", y_pred_binary)\n# print(f\"y_true_binary =\", y_true_binary)\n\n# print(f\"y_pred_binary.shape =\", y_pred_binary.shape)\n# print(f\"y_true_binary.shape =\", y_true_binary.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:10:37.795589Z","iopub.execute_input":"2024-12-19T16:10:37.795987Z","iopub.status.idle":"2024-12-19T16:10:47.919965Z","shell.execute_reply.started":"2024-12-19T16:10:37.795957Z","shell.execute_reply":"2024-12-19T16:10:47.919096Z"}},"outputs":[{"name":"stdout","text":"x_test shape: (10000, 28, 28), y_test shape: (10000,)\nx_test shape: (10000, 784), y_test shape: (10000,)\nx_test_subset shape: (10000, 784)\nx_test_pca shape:  (10000, 2)\nx_test_norm shape: (10000, 2)\nAccuracy for digit 0: 90.20%\nAccuracy for digit 1: 88.65%\nAccuracy for digit 2: 10.32%\nAccuracy for digit 3: 10.10%\nAccuracy for digit 4: 9.82%\nAccuracy for digit 5: 91.08%\nAccuracy for digit 6: 9.58%\nAccuracy for digit 7: 10.28%\nAccuracy for digit 8: 9.74%\nAccuracy for digit 9: 10.09%\nOverall Accuracy: 33.99%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Define the rational function\ndef rational_function(x, alpha, beta):\n    \"\"\"\n    r(x) = (Œ±_0 + Œ±_1*x1**1 + Œ±_2*x2**2 + ...) / \n           (Œ≤_0 + Œ≤_1*x1**1 + Œ≤_2*x2**2 + ...).\n    \"\"\"\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n# Function to cross-check a single test image\ndef cross_check_single_image(x_test_subset, y_test_subset, index, models_dir, pca_model_path):\n    \"\"\"\n    Cross-check a single image from the test dataset.\n    \n    Steps:\n    - Displays the actual test image at the given index.\n    - Shows the actual label.\n    - Calculates rational function outputs for all digit models.\n    - Predicts the digit with the highest confidence.\n    \"\"\"\n    # Load the PCA model\n    with open(pca_model_path, \"rb\") as file:\n        pca = pickle.load(file)\n    \n    # Preprocess the test image\n    selected_image = x_test_subset[index]  # Select the test image\n    selected_label = y_test_subset[index]  # Select the actual label\n    \n    # Flatten and apply PCA transformation\n    selected_image_flat = selected_image.reshape(1, -1)  # Flatten (1, 784)\n    selected_image_pca = pca.transform(selected_image_flat)  # Apply PCA\n    \n    # Normalize using MinMaxScaler\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    selected_image_normalized = scaler.fit_transform(selected_image_pca)[0]  # Normalized PCA data\n    \n    # Display the actual image\n    plt.imshow(selected_image, cmap=\"gray\")\n    plt.title(f\"Actual Label: {selected_label}\")\n    plt.axis(\"off\")\n    plt.show()\n    \n    # Load all digit models and calculate rational function outputs\n    rational_outputs = {}\n    for digit in range(10):\n        # Load the respective model\n        with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n            model = pickle.load(file)\n        \n        alpha = model[\"alpha\"]\n        beta = model[\"beta\"]\n        \n        # Calculate the rational function output\n        output = rational_function(selected_image_normalized, alpha, beta)\n        rational_outputs[digit] = output\n    \n    # Print rational function outputs\n    print(\"Rational Function Outputs for Each Digit:\")\n    for digit, output in rational_outputs.items():\n        print(f\"Digit {digit}: {output:.4f}\")\n    \n    # Predict the digit based on the closest output to the positive class (e.g., 2)\n    predictions = {digit: abs(output - 2) for digit, output in rational_outputs.items()}\n    predicted_digit = min(predictions, key=predictions.get)\n    \n    print(f\"\\nPredicted Digit: {predicted_digit}\")\n    print(f\"Actual Label: {selected_label}\")\n    \n    # Final Cross-Check\n    if predicted_digit == selected_label:\n        print(\"Prediction: Correct ‚úÖ\")\n    else:\n        print(\"Prediction: Incorrect ‚ùå\")\n\n# Main execution\nif __name__ == \"__main__\":\n    # Load the MNIST test dataset\n    from keras.datasets import mnist\n    (_, _), (x_test, y_test) = mnist.load_data()\n    print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n    \n    # Set up test dataset\n    subset_size = 10000  # Use all test images\n    x_test_subset = x_test[:subset_size]\n    y_test_subset = y_test[:subset_size]\n    \n    # Path to saved models and PCA\n    models_dir = \"/kaggle/working/models/\"  # Update the directory path\n    pca_model_path = \"models/pca_model.pkl\"\n    \n    # Select an index (change this to test different images)\n    test_index = 90 # Set the index of the image you want to test\n    \n    # Cross-check the selected image\n    cross_check_single_image(x_test_subset, y_test_subset, test_index, models_dir, pca_model_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T16:09:57.358483Z","iopub.status.idle":"2024-12-19T16:09:57.358799Z","shell.execute_reply.started":"2024-12-19T16:09:57.358653Z","shell.execute_reply":"2024-12-19T16:09:57.358668Z"}},"outputs":[],"execution_count":null}]}
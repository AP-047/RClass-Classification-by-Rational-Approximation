{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"####  üçÅCheck Versions","metadata":{}},{"cell_type":"code","source":"# !python --version\nimport cupy as cp\ncp.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T17:39:30.576992Z","iopub.execute_input":"2025-01-10T17:39:30.577970Z","iopub.status.idle":"2025-01-10T17:39:30.585383Z","shell.execute_reply.started":"2025-01-10T17:39:30.577917Z","shell.execute_reply":"2025-01-10T17:39:30.584338Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'13.3.0'"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"#### üçÅ Create Directory","metadata":{}},{"cell_type":"code","source":"import os\n\nmodels_dir = \"/kaggle/working/models/\"\n\n# Ensure the directory exists\nos.makedirs(models_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T17:39:30.587001Z","iopub.execute_input":"2025-01-10T17:39:30.587358Z","iopub.status.idle":"2025-01-10T17:39:30.600291Z","shell.execute_reply.started":"2025-01-10T17:39:30.587319Z","shell.execute_reply":"2025-01-10T17:39:30.599358Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### üçÅ Preprocessing","metadata":{}},{"cell_type":"code","source":"# Import\nfrom keras.datasets import mnist\n(x_train, y_train), (_, _) = mnist.load_data()\nprint(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n\n#1 Flatten\nx_train_flat = x_train.reshape(x_train.shape[0], -1)\nprint(f\"x_train_flat shape: {x_train_flat.shape}, y_train shape: {y_train.shape}\")\n\n#2 Subsets\nsubset_size = 10000\nx_train_subset = x_train_flat[:subset_size]\ny_train_subset = y_train[:subset_size]\nprint(f\"x_train_subset shape: {x_train_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\nimport numpy as np\nn_components = 155\npca = PCA(n_components=n_components)\nx_train_pca = pca.fit_transform(x_train_subset)\nprint(f\"x_train_pca shape: \", x_train_pca.shape)\nvariance = np.sum(pca.explained_variance_ratio_)\nprint(f\"variance =\", variance)\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_train_norm = scaler.fit_transform(x_train_pca)\nprint(f\"x_train_norm shape: {x_train_norm.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T21:40:55.954035Z","iopub.execute_input":"2025-01-10T21:40:55.954477Z","iopub.status.idle":"2025-01-10T21:40:59.493160Z","shell.execute_reply.started":"2025-01-10T21:40:55.954440Z","shell.execute_reply":"2025-01-10T21:40:59.491786Z"}},"outputs":[{"name":"stdout","text":"x_train shape: (60000, 28, 28), y_train shape: (60000,)\nx_train_flat shape: (60000, 784), y_train shape: (60000,)\nx_train_subset shape: (10000, 784)\nx_train_pca shape:  (10000, 155)\nvariance = 0.9519028045131284\nx_train_norm shape: (10000, 155)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### [Training]","metadata":{}},{"cell_type":"code","source":"import pickle\nimport cupy as cp\nimport numpy as np\nfrom scipy.optimize import linprog\nimport matplotlib.pyplot as plt\nimport itertools\n\n# Feasibility check function\ndef check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary):\n    # num_data_points = x_train_norm.shape[0]\n    # num_coefficients = n_components + 1  # (+1 for the first constant terms Œ±0 & Œ≤0)\n    # delta = 1e-6  # a small positive value\n\n    # # Construct G(x) and H(x) matrices for numerator and denominator\n    # G = cp.zeros((num_data_points, num_coefficients))  # Numerator matrix\n    # H = cp.zeros((num_data_points, num_coefficients))  # Denominator matrix\n\n    # for i in range(num_data_points):\n    #   G[i, 0] = 1\n    #   H[i, 0] = 1\n    #   for j in range(num_coefficients-1):\n    #     G[i, j+1] = x_train_norm[i, j] ** (j+1)\n    #     H[i, j+1] = x_train_norm[i, j] ** (j+1)\n\n    print(f\"G: {G}\")\n    print(f\"G.shape =\", G.shape)\n    print(f\"H: {H}\")\n\n    -----------------------------------------\n    def construct_G_H_matrices(x_train_norm, n, d):\n      import itertools\n      num_data_points = x_train_norm.shape[0]\n    \n      # Generate multi-indices\n      multi_indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n      num_coefficients = len(multi_indices)\n    \n      # Initialize G and H matrices\n      G = cp.zeros((num_data_points, num_coefficients))  # Numerator\n      H = cp.zeros((num_data_points, num_coefficients))  # Denominator\n    \n      # Construct G and H using multi-indices\n      for i in range(num_data_points):\n          for j, idx in enumerate(multi_indices):\n              term = cp.prod(cp.array([x_train_norm[i, k] ** idx[k] for k in range(n)]))\n              G[i, j] = term\n              H[i, j] = term  # G and H share the same multi-index logic\n      return G, H, multi_indices\n    \n    def generate_multi_indices(n, d):\n        indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n        return indices\n\n    num_data_points = x_train_norm.shape[0]\n    indices = generate_multi_indices(2, 2)\n    \n    num_coefficients = len(indices)\n    \n    G, H, multi_indices = construct_G_H_matrices(x_train_norm, 2, 2)\n    \n    # Construct constraints for Ax <= b\n    A = []\n    b = []\n\n    for i in range(num_data_points):\n        f_plus_z = y_binary[i] + z  # Upper bound\n        f_minus_z = y_binary[i] - z  # Lower bound\n\n        # Constraint 1: (f(xi) - z) * Œ≤^T H(xi) - Œ±^T G(xi) ‚â§ Œ∏\n        # (-G(xi))Œ±T + (f(xi) - z).H(xi)Œ≤T + (-1)Œ∏ ‚â§ 0\n        constraint_1 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Œ±\n        constraint_1[0:num_coefficients] = -G[i]\n        # (2) Coefficients of Œ≤\n        constraint_1[num_coefficients:2 * num_coefficients] = (f_minus_z) * H[i]\n        # (3) Coefficient of Œ∏ (last element)\n        constraint_1[-1] = -1\n        A.append(constraint_1)\n        b.append(0)\n\n        # Constraint 2: Œ±^T G(xi) + (-1).(f(xi) + z) * Œ≤^T H(xi) ‚â§ Œ∏\n        # G(xi).Œ±T + (-1)(f(xi) - z).H(xi)Œ≤T + (-1)Œ∏ ‚â§ 0\n        constraint_2 = cp.zeros(2 * num_coefficients + 1)\n        # (1) Coefficients of Œ±\n        constraint_2[0:num_coefficients] = G[i]\n        # (2) Coefficients of Œ≤\n        constraint_2[num_coefficients:2 * num_coefficients] = -(f_plus_z) * H[i]\n        # (3) Coefficient of Œ∏ (last element)\n        constraint_2[-1] = -1\n        A.append(constraint_2)\n        b.append(0)\n\n        # Constraint 3: Œ≤^T H(x) ‚â• Œ¥\n        # (0)Œ±^T + (-H(x)) Œ≤^T + (0)Œ∏ ‚â§ -Œ¥\n        constraint_3 = cp.zeros(2 * num_coefficients + 1)\n        # Coefficient of Œ≤\n        constraint_3[num_coefficients:2 * num_coefficients] = -H[i]\n        A.append(constraint_3)\n        b.append(-delta)\n\n    # Convert CuPy arrays to NumPy arrays for SciPy\n    A = cp.asnumpy(cp.array(A))\n    b = cp.asnumpy(cp.array(b))\n\n    # Objective function to minimize Œ∏\n    c = cp.asnumpy(cp.zeros(2 * num_coefficients + 1))\n    c[-1] = 1  # Only Œ∏ has a coefficient in the objective function\n\n    # Solve the linear programming problem (methods: highs, revised simplex)\n    result = linprog(c, A_ub=A, b_ub=b, method=\"highs\")\n\n    # Check feasibility and return results\n    if result.success:\n        alpha_coefficients = result.x[:num_coefficients]\n        beta_coefficients = result.x[num_coefficients:2 * num_coefficients]\n        theta = result.x[-1]\n        return True, alpha_coefficients, beta_coefficients, theta\n    else:\n        return False, None, None, None\n\n\n# Bisection loop\ndef bisection_loop(x_train_norm, y_binary, uL, uH, precision):\n    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n    z_values = []\n\n    while uH - uL > precision:\n        z = (uL + uH) / 2\n        z_values.append(z)\n        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary)\n\n        if feasible:\n            uH = z\n            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n        else:\n            uL = z\n\n    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values\n\n# Train a classifier for each digit\nfor digit in range(10):\n    print(f\"Training classifier for digit {digit}...\")\n\n    # Assign labels: Positive for the current digit, negative for others\n    # y_binary = (y_train_subset == digit).astype(int)\n    y_binary = (y_train_subset == digit).astype(float)\n\n    # Scale binary labels to larger values\n    # Positive class = 2, Negative class = 4\n    y_binary = np.where(y_binary == 1, 2, 4)\n\n    # print(f\"y_binary =\", y_binary)\n    # print(f\"y_train_subset =\", y_train_subset)\n\n    # Bisection parameters\n    uL = 0  # Initial lower bound\n    uH = 500  # Initial upper bound\n    precision = 1e-6 # Precision threshold\n\n    # Run bisection loop\n    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(x_train_norm, y_binary, uL, uH, precision)\n\n    # Print results\n    print(f\"Number of Iterations: {len(z_values)}\")\n    # print(f\"z Values in all Iterations: {z_values}\")\n    print(f\"Optimal z (Maximum Deviation): {optimal_z}\")\n\n    print(f\"Optimized Coefficients (Numerator Œ±): {optimal_alpha}\")\n    print(f\"Optimized Coefficients (Denominator Œ≤): {optimal_beta}\")\n    print(f\"Optimal Œ∏: {optimal_theta}\")\n    \n    # print(f\"rational_function =\", rational_function(x_train_norm[0], optimal_alpha, optimal_beta))\n\n    # Save the model\n    model = {\n        \"alpha\": optimal_alpha,\n        \"beta\": optimal_beta,\n        \"theta\": optimal_theta,\n        \"n_components\": n_components\n    }\n\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"wb\") as file:\n        pickle.dump(model, file)\n\n    print(f\"Model for digit {digit} saved at {models_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T17:39:45.304559Z","iopub.execute_input":"2025-01-10T17:39:45.306345Z","iopub.status.idle":"2025-01-10T19:37:12.495704Z","shell.execute_reply.started":"2025-01-10T17:39:45.306306Z","shell.execute_reply":"2025-01-10T19:37:12.494921Z"}},"outputs":[{"name":"stdout","text":"Training classifier for digit 0...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.00002159e-06  0.00000000e+00 -9.96521586e-11 -3.34030364e-11\n -1.44510579e-09  4.79731742e-10 -1.72602849e-09  1.75565826e-09\n  1.83859318e-09  3.66987485e-10  3.91819214e-09  1.68089594e-08\n  1.42920392e-08  2.06535375e-08 -2.15240891e-08 -5.10973107e-10\n -3.88094811e-08 -2.01152272e-11 -4.73088224e-10  0.00000000e+00\n -6.31924214e-08 -4.61692581e-08  4.15918334e-08  2.70774839e-06\n  2.00106699e-06  3.90703829e-10  2.29796532e-09  4.95958816e-09\n -2.21962194e-08  0.00000000e+00  4.93216235e-08 -4.82370374e-09\n -4.35328448e-08 -1.00881166e-08 -1.82066371e-09  5.83804754e-09\n  2.00008302e-06  4.77620472e-07 -1.70605995e-06 -1.01739966e-08\n  1.57372787e-08 -9.65484388e-10  1.99803424e-06 -1.68558622e-09\n  0.00000000e+00  1.99346979e-06  1.99962907e-06 -1.93751317e-09\n  1.79944502e-07  7.42606655e-08 -2.81989959e-09  2.95529880e-09\n  1.99909837e-06 -6.74497878e-08  0.00000000e+00 -1.38793197e-08\n  2.00038849e-06  1.99987054e-06 -2.39769937e-10  2.00085204e-06\n  0.00000000e+00 -8.66105788e-09 -2.93784090e-08  4.94762546e-09\n  0.00000000e+00  5.87561715e-11 -8.79566467e-09 -1.81482046e-09\n -2.16709521e-08  2.00008920e-06  1.99993882e-06  1.03367140e-08\n -7.89808859e-10 -2.01048412e-08  1.99979910e-06  2.00005714e-06\n  0.00000000e+00 -4.73595292e-10]\nOptimized Coefficients (Denominator Œ≤): [ 9.99996134e-07  2.26118028e-11 -4.21146762e-11 -4.26851434e-11\n -3.01589886e-10  2.25162886e-10 -3.89931554e-10  1.27262892e-10\n  7.87429818e-10  3.91560501e-10  8.46629864e-10  5.18566327e-09\n  7.32781969e-09  6.29743295e-09 -1.00393193e-08 -8.07399039e-11\n -1.02386054e-08 -3.63594040e-11 -5.14103426e-09 -8.65747049e-11\n -8.91313817e-09 -1.07047710e-08  1.05001367e-08  6.76444731e-07\n  2.66196508e-10  1.70438676e-10  4.95761106e-10  1.08323064e-09\n  3.13107038e-11  6.28930041e-09  2.46924640e-08  6.58485548e-11\n -2.26645334e-08 -4.83678010e-09  7.89125277e-11  2.98482473e-09\n  5.65368238e-11  1.19379512e-07 -9.26512892e-07 -1.31008355e-09\n  6.94298966e-09 -2.19337045e-10 -5.09041121e-10 -6.02845563e-10\n  1.29131020e-10  1.97285273e-12 -9.57175616e-11 -9.87678852e-10\n -7.30499061e-11  2.26165942e-08 -8.58937299e-10  1.23905334e-09\n -2.30166502e-10 -3.29223660e-08  2.44879984e-13 -3.52098521e-09\n  1.01737964e-10 -4.09819482e-11 -1.10516418e-10  1.82853176e-10\n  0.00000000e+00  4.49362235e-11 -7.65519078e-09 -1.13571835e-11\n  3.99003287e-09  2.56905120e-10 -8.18629889e-11 -4.52589607e-10\n -1.17734478e-10  4.38189918e-12 -3.05132385e-11  1.29712432e-09\n -1.84818861e-10 -8.80700651e-11  0.00000000e+00  0.00000000e+00\n  1.00008019e-06  0.00000000e+00]\nOptimal Œ∏: 9.999987572818248e-07\nModel for digit 0 saved at /kaggle/working/models/\nTraining classifier for digit 1...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 0.0009546056389808655\nOptimized Coefficients (Numerator Œ±): [ 2.99915961e-06  2.54044380e-09 -1.98354415e-09  1.92166849e-09\n  2.56085529e-10  3.69748593e-09 -6.87932466e-10  5.06298757e-11\n -6.42145463e-09 -5.02184536e-09 -5.63588697e-09 -1.95326031e-10\n  1.04389940e-08  3.59749689e-08  0.00000000e+00  1.12427890e-08\n  0.00000000e+00  1.87807963e-07  0.00000000e+00  3.26437529e-08\n -2.47740199e-10 -2.19992679e-09  0.00000000e+00 -8.87379641e-08\n -1.26849542e-09  0.00000000e+00  1.99445029e-06  1.96879440e-07\n  6.96098801e-10  3.53200640e-09  2.07757035e-06 -1.05029185e-08\n  1.94388703e-06  4.48889384e-05  1.98750161e-06  2.27539089e-06\n  3.29674970e-05  1.99907388e-06  2.00872300e-10  0.00000000e+00\n -1.81072914e-09  1.71676159e-06  2.01562620e-06  6.94802678e-05\n  0.00000000e+00  2.00024172e-06  1.99609801e-06  1.98342313e-06\n -1.83155213e-09  5.64642678e-08  2.00713134e-06  1.99956049e-06\n  1.96314122e-06  1.26064715e-09 -2.27604991e-09  1.98800773e-06\n  1.88293474e-06  2.00022565e-06 -1.02817640e-08 -1.23852472e-08\n  1.99071803e-06  1.99655649e-10  1.95434536e-06  1.99889104e-06\n  1.63791640e-06  1.95974974e-06  1.99973406e-06 -1.44562242e-10\n  0.00000000e+00  1.99985959e-06  0.00000000e+00  1.97515999e-06\n  1.23007248e-09  1.99916890e-06  1.99968175e-06  2.00010642e-06\n -5.00864897e-07  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 9.99653589e-07  8.35343384e-10 -3.62662541e-10  8.63733211e-10\n  8.32857279e-11  1.35316661e-09 -1.95596839e-10  3.60832952e-11\n -2.60103138e-10 -5.45460751e-10 -2.14285277e-09  2.14482858e-11\n  3.60090095e-10  9.24720224e-09 -8.68900710e-11  5.00686997e-09\n -3.25016543e-10 -3.53185724e-10  1.05129124e-09 -2.22470534e-10\n  4.27154902e-10 -5.28286110e-10 -2.13962474e-08  2.62520784e-11\n -3.45553052e-10 -3.01774563e-11  8.92593273e-11  4.91782573e-08\n  1.45200603e-10  9.04664392e-10  1.94225359e-08 -3.51489289e-09\n -1.33591552e-08  1.07212101e-05 -5.12403404e-10  1.49767211e-07\n  7.74011245e-06 -1.36348827e-10  8.56365320e-11 -3.91509496e-09\n -5.78157263e-10 -7.08936180e-08  3.46132133e-09  1.68439324e-05\n -2.92295768e-10  1.36513394e-10 -1.01444736e-09 -4.17154794e-09\n  8.24154575e-11  1.34522293e-08  1.84291579e-09 -1.47446328e-10\n -1.55561050e-09  4.49063758e-10  3.95540395e-10  0.00000000e+00\n -2.93747485e-08  1.14016254e-10 -8.68081618e-10  6.47433915e-10\n -2.14225116e-09 -8.55414147e-11 -4.46279313e-10 -3.70871441e-10\n  2.38635986e-09 -9.61735217e-09 -1.57887209e-10  1.60973406e-10\n -0.00000000e+00 -1.47272562e-10  2.22907524e-10 -0.00000000e+00\n  2.83484417e-10 -7.06295621e-10 -0.00000000e+00  3.90584707e-10\n -6.86228186e-08  0.00000000e+00]\nOptimal Œ∏: 9.990176872505892e-07\nModel for digit 1 saved at /kaggle/working/models/\nTraining classifier for digit 2...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.e-06  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00\n  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00  0.e+00\n -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00\n  0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00  0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.e-06 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00  0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00  0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00  0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00\n -0.e+00 -0.e+00 -0.e+00 -0.e+00 -0.e+00  0.e+00]\nOptimal Œ∏: 9.99999068677443e-07\nModel for digit 2 saved at /kaggle/working/models/\nTraining classifier for digit 3...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 3.073364496231079e-05\nOptimized Coefficients (Numerator Œ±): [ 3.00000020e-06 -9.41963208e-13 -2.65456999e-13  2.68572010e-12\n  3.38993271e-12 -1.52135648e-11  0.00000000e+00 -1.55807126e-12\n  6.02208378e-12 -3.40084917e-12  1.34258345e-11 -6.94394884e-11\n -7.65691974e-11  2.47248573e-10 -2.49057284e-13 -1.13850995e-09\n -2.58835734e-10 -1.79753563e-10 -4.44421569e-09  2.50303039e-09\n  3.28372436e-11  0.00000000e+00 -9.27032486e-11 -4.90942686e-10\n  1.52422945e-09  1.29246939e-10 -2.53808335e-11  0.00000000e+00\n  3.38693462e-09  0.00000000e+00 -5.87208670e-11  1.56760905e-08\n  2.85923946e-10  3.79911535e-10  0.00000000e+00  1.23814054e-09\n  0.00000000e+00 -0.00000000e+00 -0.00000000e+00  1.99788950e-06\n -0.00000000e+00 -1.46952727e-09  7.86811348e-11  0.00000000e+00\n  6.68896227e-11  1.99999439e-06  0.00000000e+00 -0.00000000e+00\n  0.00000000e+00 -2.31470502e-10  3.37164305e-09  1.17132252e-09\n  0.00000000e+00  1.41997309e-08 -4.09664549e-09 -0.00000000e+00\n  0.00000000e+00  0.00000000e+00  1.99663158e-06  1.99997003e-06\n  0.00000000e+00  0.00000000e+00 -1.59568621e-10  6.11682509e-10\n  1.99997971e-06 -7.10181944e-09  0.00000000e+00 -3.27761844e-08\n -4.10411212e-10  1.99963731e-06  2.00023456e-06  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  2.00000480e-06  0.00000000e+00\n  1.99998598e-06  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 9.99999904e-07  7.38267247e-14 -9.09168241e-14  6.31073596e-13\n  1.66207428e-12 -4.09533267e-12 -1.23779646e-12  3.05253683e-12\n  1.29489871e-12 -5.79611236e-14  4.28013399e-12 -1.47610673e-11\n -2.32240757e-11  7.08554564e-11  4.17082040e-13  9.07807055e-11\n -5.25030380e-11 -2.02620416e-11  4.82644378e-10  1.89856126e-09\n  7.19096869e-12 -2.44882449e-10 -1.63757097e-11  0.00000000e+00\n  4.15581089e-10  1.48007489e-12 -4.47766751e-11 -0.00000000e+00\n  8.76488466e-10  2.05742658e-12 -0.00000000e+00  2.73805431e-09\n  3.77651101e-11  8.23340995e-11 -4.91003028e-12  6.95054322e-12\n -5.10126306e-10 -0.00000000e+00  0.00000000e+00 -0.00000000e+00\n  1.57300407e-10 -8.29216075e-10  3.88435408e-11 -7.22767908e-10\n -0.00000000e+00 -0.00000000e+00  2.88248770e-09  0.00000000e+00\n  7.66468108e-10 -1.31465326e-11  0.00000000e+00  2.90162911e-10\n -0.00000000e+00 -4.50471613e-10  1.56120730e-10  1.35771386e-09\n -2.33505212e-08  0.00000000e+00 -2.93406131e-09 -0.00000000e+00\n -7.18868067e-09  4.55317477e-11 -6.32115708e-11 -0.00000000e+00\n  0.00000000e+00 -1.82032214e-09 -1.86188651e-08  1.07815819e-10\n -8.73202509e-09 -9.08128883e-11  0.00000000e+00 -5.89184695e-10\n -7.61716298e-11 -0.00000000e+00  0.00000000e+00  8.49069596e-07\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.999692589160935e-07\nModel for digit 3 saved at /kaggle/working/models/\nTraining classifier for digit 4...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 0.00012014061212539673\nOptimized Coefficients (Numerator Œ±): [ 2.99999991e-06 -1.21709163e-11  0.00000000e+00  3.87369367e-11\n -5.46379580e-11  2.98936520e-10  6.82308967e-10 -5.77318282e-10\n  2.48436264e-10 -1.12726262e-09 -1.74215666e-10 -5.48653229e-10\n  7.87198698e-10 -4.05163766e-10 -5.02641162e-09  0.00000000e+00\n -6.87410440e-10  0.00000000e+00 -4.20532002e-10 -6.58987448e-08\n  1.12556057e-08 -9.88932834e-09 -6.51924626e-09  0.00000000e+00\n -4.33613570e-08  1.99181125e-08  0.00000000e+00  0.00000000e+00\n -1.43488433e-08  0.00000000e+00  0.00000000e+00  3.15229427e-08\n -1.34936634e-08  9.28173202e-08 -2.15362140e-09  0.00000000e+00\n  0.00000000e+00 -1.37881074e-09  0.00000000e+00  0.00000000e+00\n  8.49494576e-09  1.72574552e-08  2.00045850e-06 -3.17262986e-08\n  1.99613715e-06  2.00014749e-06  0.00000000e+00  0.00000000e+00\n  2.49900264e-08 -1.04981938e-08 -5.94204765e-08 -2.05462239e-08\n  1.99991254e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  3.12970239e-08  2.00740748e-06  5.51798385e-11  1.84661137e-10\n  0.00000000e+00  2.00067923e-06  1.99925504e-06  1.99790378e-06\n -2.79451932e-09  1.92336134e-06  0.00000000e+00 -1.23800134e-08\n  2.00007497e-06  2.00001634e-06  1.99999467e-06  0.00000000e+00\n  1.99999697e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000090e-06 -4.30228916e-12 -1.40072640e-12  7.61371723e-12\n -2.40825836e-11  7.85135489e-11  2.87052229e-10 -2.48834301e-10\n  1.58281289e-10 -2.93572175e-10 -4.67698994e-11  3.03690811e-10\n  2.14148389e-10 -2.80126859e-10  5.40273910e-10 -1.68732652e-12\n -1.73242344e-10 -1.12881666e-09  0.00000000e+00 -1.38689292e-08\n  2.79900243e-09 -1.43157376e-09 -1.10701071e-09  1.46352492e-09\n -2.79140753e-10  5.25913101e-09  0.00000000e+00 -3.06227927e-09\n -4.70557396e-09  1.76457361e-09 -2.24341735e-10  8.03164924e-09\n  3.79280683e-09  1.78267623e-08 -5.46151615e-10  4.57997416e-10\n -1.09402281e-11  1.19650070e-10 -3.12571897e-13 -1.85130334e-08\n  1.49670306e-09  8.99935183e-09  0.00000000e+00 -9.40521265e-09\n -9.66744767e-10  5.23929385e-12  4.92804141e-11 -7.02182038e-12\n  0.00000000e+00 -3.74426805e-09 -2.68931999e-08 -1.78683720e-09\n  0.00000000e+00 -3.30821809e-09  0.00000000e+00 -7.02354998e-12\n  7.81222479e-09  1.85034164e-09  2.40603822e-11 -2.68370989e-11\n -1.28716236e-12  1.11570988e-11 -1.82722144e-10 -5.23981991e-10\n -7.00777331e-10 -8.66932605e-11 -1.61991206e-11 -3.09404489e-09\n  1.53215565e-11  0.00000000e+00  5.74790323e-12  1.85096083e-08\n  0.00000000e+00 -1.72844409e-11  1.94044475e-11 -7.59405096e-10\n  2.83872935e-10  0.00000000e+00]\nOptimal Œ∏: 9.998794055212138e-07\nModel for digit 4 saved at /kaggle/working/models/\nTraining classifier for digit 5...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.00000001e-06  0.00000000e+00 -2.05405511e-13  9.74598882e-13\n  1.25759493e-12 -2.58422553e-12  0.00000000e+00  1.24853819e-11\n -9.33037099e-12 -1.13027716e-11  0.00000000e+00  4.86418699e-12\n  0.00000000e+00  4.85653282e-12 -3.33709770e-12  0.00000000e+00\n -1.35993596e-10 -3.27477539e-11  7.11580910e-09 -2.29247561e-11\n  0.00000000e+00  5.64880494e-10  1.58232770e-10  1.28028067e-11\n  3.20762173e-10  7.74416977e-10  0.00000000e+00 -2.09133849e-09\n  6.55807173e-10  0.00000000e+00 -4.27520998e-11 -6.49912531e-08\n  2.47386728e-10  3.69876718e-10 -8.93235888e-09 -9.18447284e-10\n  1.99184057e-06 -4.12260467e-09 -4.24176099e-09  0.00000000e+00\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.10609770e-08\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -1.76233150e-09  0.00000000e+00 -6.35497388e-12 -5.24623431e-08\n  0.00000000e+00 -0.00000000e+00  2.77548766e-12  1.79128463e-06\n  6.38921400e-08 -0.00000000e+00  0.00000000e+00  2.59641062e-11\n  1.99999595e-06  1.88451513e-11 -2.17869793e-08 -0.00000000e+00\n  0.00000000e+00  0.00000000e+00 -5.00575349e-09  0.00000000e+00\n  3.30457102e-10  0.00000000e+00  1.99970579e-06  0.00000000e+00\n -3.29804709e-10 -0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00 -5.12591174e-12]\nOptimized Coefficients (Denominator Œ≤): [ 9.99999941e-07  1.47126736e-13 -2.79618596e-14  2.22477369e-13\n  3.85836608e-13 -1.29822651e-13 -2.43726897e-13  4.49773800e-12\n -1.94645263e-12 -3.54310036e-12  1.02140465e-12  1.80797323e-12\n -3.73064962e-12  2.53271329e-12  0.00000000e+00 -1.31347862e-13\n -4.96737258e-12 -1.50953862e-11  1.86853649e-09 -7.51453602e-13\n -1.21061874e-11 -2.83926147e-11 -1.67856101e-11  0.00000000e+00\n  8.06471815e-11 -1.39038842e-09 -4.19271992e-12 -1.08068761e-09\n  8.82762550e-11 -2.68633130e-11  1.51498388e-11 -8.74077344e-09\n  1.18475641e-10  1.73438193e-10 -3.33265070e-09  0.00000000e+00\n -2.04257885e-09 -2.44411448e-09 -0.00000000e+00  4.73335066e-08\n -0.00000000e+00 -0.00000000e+00  1.02571732e-12  2.02685269e-08\n -0.00000000e+00  5.01171458e-10  1.06094832e-09 -7.93595235e-10\n -4.43110212e-10  4.45881450e-13  0.00000000e+00 -0.00000000e+00\n  1.85737720e-09  0.00000000e+00  0.00000000e+00 -5.22425535e-08\n -0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00  1.05765405e-11 -5.62032881e-09  9.19052624e-12\n  0.00000000e+00  6.33233013e-11 -1.25127238e-09 -0.00000000e+00\n  7.90498557e-11 -0.00000000e+00 -7.35723816e-11 -4.66158433e-08\n -7.66763074e-11 -6.90081995e-12  0.00000000e+00 -0.00000000e+00\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.99999057421578e-07\nModel for digit 5 saved at /kaggle/working/models/\nTraining classifier for digit 6...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 6.0535967350006104e-05\nOptimized Coefficients (Numerator Œ±): [ 2.99999975e-06  1.72468715e-11 -6.29107648e-11 -3.77872735e-12\n -2.67327804e-11  1.61287286e-10  0.00000000e+00 -1.90381971e-10\n -1.81911410e-10  2.07143255e-09 -3.92759490e-10  5.75114673e-09\n  1.03849899e-09 -1.62282299e-09  2.64214105e-09 -4.76148180e-09\n -1.29696645e-09 -1.29596994e-09 -1.08547493e-09  1.92789525e-09\n  4.11097960e-08  6.80116534e-10 -3.10014333e-11 -3.38861747e-10\n  2.43306047e-10  5.82977843e-12 -6.32244064e-10  5.87535093e-08\n -7.62026318e-11  2.49524794e-11  4.97982908e-09  2.74319653e-09\n  1.51610513e-10  2.66623448e-09  2.48409975e-10  2.14623512e-08\n -1.11565949e-10  2.64287830e-07 -1.25827213e-10 -4.61453807e-11\n  2.01809591e-06 -6.12556261e-10  2.97785198e-10  3.53624766e-11\n  1.84578597e-09  2.00002933e-06 -1.20575107e-09  0.00000000e+00\n  1.65880711e-11 -6.14763049e-11  3.65660384e-11  7.35017464e-11\n  1.99989322e-06 -1.26106466e-11  1.99601680e-06 -3.00348856e-10\n  0.00000000e+00 -1.48360925e-09  3.75735009e-09 -2.06330411e-10\n -1.01576983e-09  0.00000000e+00 -1.70054487e-10 -4.67620913e-10\n  1.63987842e-06  1.92362764e-06  0.00000000e+00  2.54896612e-11\n -2.49921137e-08 -5.58233710e-09  1.99997120e-06  0.00000000e+00\n  2.00180661e-06  1.80464724e-10  7.66394433e-10  1.99994818e-06\n  0.00000000e+00  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000402e-06 -2.11841128e-12 -2.03860427e-11  3.75032562e-13\n -7.28483076e-12  4.38086633e-11 -5.74873757e-11  9.77104933e-11\n -3.76400178e-11  6.81138398e-10 -1.06954788e-10  6.52015534e-11\n  3.74743122e-10 -7.36141418e-10 -9.32629247e-10 -1.24239999e-09\n -2.26222850e-10 -8.34580691e-12 -8.61873779e-12  2.85376308e-10\n  9.76048609e-09 -6.61796547e-10 -4.62473088e-13 -1.71946385e-10\n  6.13578988e-11  1.44852034e-11 -1.65608717e-10  2.10959551e-09\n -0.00000000e+00  1.20302207e-11  1.23731816e-09 -8.34015359e-11\n -2.21330364e-11  2.31623098e-09  6.60106555e-11  5.47854194e-09\n -0.00000000e+00  1.69298759e-11 -0.00000000e+00  0.00000000e+00\n  4.37167968e-09 -1.54430901e-10  1.92231770e-10  3.79615597e-11\n  7.97858531e-10  2.77028044e-09 -4.57282863e-11 -1.51997848e-08\n  2.41902644e-12 -2.27172032e-10  0.00000000e+00 -0.00000000e+00\n  1.17586876e-11 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n  1.00307053e-06 -0.00000000e+00  1.90129238e-09 -0.00000000e+00\n  0.00000000e+00 -0.00000000e+00 -3.15954458e-11 -1.00957219e-10\n -9.00121973e-08  0.00000000e+00 -1.24918232e-10  1.04234216e-11\n -6.46804644e-09 -0.00000000e+00  0.00000000e+00 -9.26493143e-10\n  3.30933213e-10 -2.10999528e-11 -0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.999383801585881e-07\nModel for digit 6 saved at /kaggle/working/models/\nTraining classifier for digit 7...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.00001093e-06 -1.66364262e-11  0.00000000e+00 -2.27800615e-11\n -2.17499607e-11 -2.68726067e-12 -1.08540738e-10 -4.95546535e-11\n -1.16239492e-10 -3.04505807e-10 -1.63474714e-10  8.15895790e-10\n  0.00000000e+00  1.90938313e-09 -4.47346808e-10 -7.85889113e-12\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n  0.00000000e+00 -1.31369341e-09 -3.68123878e-10 -3.01934281e-08\n  7.34902253e-11  0.00000000e+00  0.00000000e+00 -5.64547793e-10\n  6.02694519e-11  0.00000000e+00 -1.29888485e-09  8.03121267e-10\n  5.05493848e-10  0.00000000e+00  0.00000000e+00  5.48432004e-13\n  1.30932630e-11  0.00000000e+00  2.00000009e-06  0.00000000e+00\n -8.39794944e-08  0.00000000e+00  0.00000000e+00  1.70091594e-11\n -3.47878518e-08  0.00000000e+00 -8.58729515e-12  2.00000602e-06\n  1.99996860e-06  0.00000000e+00  1.75919024e-10  1.56047071e-11\n  0.00000000e+00  1.99999013e-06  1.99982743e-06  2.00006549e-06\n -0.00000000e+00  1.99999200e-06  0.00000000e+00  2.00001417e-06\n  2.00002831e-06  0.00000000e+00  1.99999447e-06 -7.86818324e-09\n  1.99267766e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n -2.67533037e-11  0.00000000e+00 -5.67992717e-10  1.99741583e-06\n -1.91670911e-10  2.00048992e-06  0.00000000e+00 -0.00000000e+00\n  1.99939264e-06  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000199e-06 -4.14062202e-12 -1.60981505e-12 -5.29086354e-12\n  1.40969684e-11  8.36669120e-12 -3.87735679e-11  4.71008320e-11\n -4.20686280e-11 -6.76946287e-11 -5.77036631e-11  2.21710775e-10\n  1.61880916e-10  5.70796406e-10 -5.49001711e-10  0.00000000e+00\n  6.20077305e-11 -5.22027746e-10 -1.67104160e-12 -5.64181021e-12\n  3.76832094e-12 -2.09343273e-10 -1.00812684e-10 -0.00000000e+00\n  1.92705088e-11 -9.08249348e-11 -2.89212061e-12 -8.26342001e-11\n  1.10654262e-10 -5.29291462e-12 -3.21677041e-10  2.02268441e-10\n -6.75443038e-11  3.08884750e-10 -4.11198317e-12 -5.34111653e-12\n  0.00000000e+00 -2.11294713e-12 -0.00000000e+00 -0.00000000e+00\n -2.09906778e-08 -7.58280237e-10 -6.19305601e-10 -0.00000000e+00\n -8.69785855e-09 -0.00000000e+00  0.00000000e+00  2.79623325e-12\n -1.12343197e-11  1.93137529e-10  7.94088855e-11 -0.00000000e+00\n  8.49689431e-13  0.00000000e+00  0.00000000e+00 -2.11800637e-11\n  4.78335962e-12 -2.45158178e-12 -0.00000000e+00  3.30102325e-12\n  0.00000000e+00 -4.15490496e-13 -1.73573914e-12 -1.99057099e-09\n -0.00000000e+00  5.06391051e-12  0.00000000e+00 -0.00000000e+00\n -1.46073253e-11 -2.90925775e-12 -1.41941300e-10  6.69342723e-11\n -4.90250584e-11  0.00000000e+00 -0.00000000e+00  0.00000000e+00\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.999992496612876e-07\nModel for digit 7 saved at /kaggle/working/models/\nTraining classifier for digit 8...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.00000072e-06 -1.60655504e-12 -4.95937618e-13 -9.21771516e-15\n -1.10390425e-11  2.86447362e-11 -3.68333045e-11  1.18678604e-11\n -1.02995587e-10  1.85507469e-10  0.00000000e+00  0.00000000e+00\n  4.43374269e-10 -2.02259272e-11 -1.93546435e-10 -1.67382458e-09\n  2.09458512e-10  6.12801463e-11 -1.93251425e-09  2.26426088e-09\n  0.00000000e+00 -1.34850255e-09  2.38471779e-09 -2.39311172e-10\n -4.03871149e-10  0.00000000e+00  1.16601392e-07 -1.14323737e-08\n -4.16952124e-10  0.00000000e+00  0.00000000e+00  1.00449620e-09\n  0.00000000e+00  0.00000000e+00  0.00000000e+00  7.18789967e-09\n  2.00000187e-06  0.00000000e+00  0.00000000e+00  3.00918749e-08\n -1.53430501e-10  4.10652526e-08 -5.62687878e-09  0.00000000e+00\n  0.00000000e+00  2.08607259e-12  0.00000000e+00 -8.02310319e-10\n  4.17168710e-10  0.00000000e+00  4.45909055e-09  0.00000000e+00\n  0.00000000e+00  4.60087302e-09  7.18794548e-10 -2.96497231e-12\n  0.00000000e+00  0.00000000e+00  9.39478758e-09 -2.76875634e-10\n -1.78479412e-11 -5.79920697e-08  3.87148210e-09  0.00000000e+00\n -1.02541894e-10 -3.40655128e-11 -1.90543463e-11 -1.16346615e-08\n  1.55226606e-09  0.00000000e+00  0.00000000e+00  3.13722058e-08\n  0.00000000e+00  1.71686815e-06  1.99999337e-06  4.74906182e-10\n  1.98697702e-06  2.00004327e-06]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000031e-06 -7.94459364e-13 -7.87133592e-14 -1.39184458e-13\n -4.20388177e-13 -4.93824560e-12  6.48264445e-12  6.21858659e-12\n -5.21423499e-11  2.36330407e-11 -2.96995400e-12  3.18317004e-12\n  1.07029413e-10  4.35076444e-13  8.79810557e-11 -8.54892629e-10\n  4.79159663e-11  0.00000000e+00 -5.52077707e-10  0.00000000e+00\n  8.79438747e-13 -9.58141000e-11  1.17914262e-09  3.96097116e-10\n  8.08658054e-12  3.84854890e-11  3.14623346e-08 -1.08500527e-09\n -9.59636954e-11 -0.00000000e+00  2.12707859e-11  3.49874807e-10\n -1.37243522e-10  5.69331846e-12  3.17874323e-12  1.52604062e-09\n  0.00000000e+00 -3.80207110e-09 -3.05596369e-13  0.00000000e+00\n -6.83550679e-11  3.42312721e-12 -1.43871549e-09 -1.08392967e-10\n  1.32381893e-08 -1.02774946e-13 -4.54687476e-09 -2.00776754e-10\n  1.03578977e-10 -8.20905059e-09  1.95982286e-12 -0.00000000e+00\n  9.92190259e-07  3.59531875e-11  4.50792318e-10  0.00000000e+00\n -5.38343267e-13  1.79628874e-09  2.32257892e-09 -1.75772658e-12\n -3.74128532e-12 -1.44993471e-08  1.42506024e-08 -1.07267383e-09\n  0.00000000e+00  0.00000000e+00 -2.73633622e-12  0.00000000e+00\n  0.00000000e+00 -1.09792940e-08 -4.72629370e-10  0.00000000e+00\n  2.16762787e-14 -4.23073830e-12  0.00000000e+00  0.00000000e+00\n -3.50686753e-09  0.00000000e+00]\nOptimal Œ∏: 9.999991568847262e-07\nModel for digit 8 saved at /kaggle/working/models/\nTraining classifier for digit 9...\nNumber of Iterations: 29\nOptimal z (Maximum Deviation): 9.313225746154785e-07\nOptimized Coefficients (Numerator Œ±): [ 3.00000374e-06 -1.97591682e-11  5.96508685e-12 -7.36553570e-12\n -1.20213245e-11  3.16167308e-12  9.53103064e-12 -1.39926351e-10\n -1.04669183e-11  0.00000000e+00  0.00000000e+00 -1.61678958e-10\n -3.48281257e-10  3.48765881e-09  0.00000000e+00  6.19306182e-11\n -1.98769549e-09  3.40124382e-09  7.83015341e-08  1.65338912e-09\n -2.01681504e-10  6.50119037e-10  1.22117205e-09  0.00000000e+00\n  3.97864338e-09  3.43132543e-09 -4.18981059e-09 -4.69168102e-08\n -3.61350681e-11 -5.53857073e-10  6.97837965e-09  4.17253238e-09\n  8.81311102e-08  1.81434129e-11 -8.07770874e-11  0.00000000e+00\n -2.99272664e-11  4.96933367e-09  0.00000000e+00  1.60260257e-11\n -3.84887810e-08 -3.63129534e-09  2.94193455e-08 -2.81286520e-10\n  1.99998912e-06 -1.85737018e-11  4.09125547e-08  2.00000269e-06\n -2.59529049e-10  1.91187407e-06 -6.21078759e-08  1.45741244e-08\n  2.00004896e-06 -3.13858814e-09 -1.32008272e-08 -4.84692782e-11\n  2.45826884e-10  1.99998277e-06  1.56358484e-09  1.55205163e-11\n  6.07104691e-09  5.16799453e-09 -1.78333902e-08 -3.20779062e-10\n -2.04081356e-11 -1.31862708e-10  0.00000000e+00 -7.57856246e-11\n  1.99996987e-06  2.00001106e-06 -1.70578333e-10  1.99996860e-06\n -2.27161282e-11 -1.96942172e-09  2.01205832e-10  2.37752449e-09\n  0.00000000e+00  0.00000000e+00]\nOptimized Coefficients (Denominator Œ≤): [ 1.00000051e-06 -1.56702786e-12  4.27824794e-13 -2.96197849e-12\n -6.43449543e-12 -2.10151888e-12  1.32016301e-11 -4.03012003e-11\n  1.45837945e-11 -3.90099060e-11  1.52082054e-11  1.44700565e-11\n  1.61415206e-11  5.92525280e-10  1.18919528e-10  3.22866300e-12\n -4.00482853e-14  7.51282205e-10  1.41859461e-10  5.44674544e-10\n  3.27167804e-12 -5.42499256e-11  4.40717955e-10  1.62854879e-10\n -6.07097385e-13 -4.28289240e-12 -9.61025036e-11 -8.20465345e-11\n -1.03299884e-12 -2.50410823e-10  1.36800167e-09  1.18951723e-11\n  3.27720882e-10  4.63655544e-12 -1.19188809e-11 -3.74997869e-10\n  0.00000000e+00  7.06037373e-10 -1.03066048e-09  1.11773340e-11\n -9.63539644e-09 -1.08184929e-09  7.34145937e-09 -4.93402850e-11\n  6.30958045e-13 -5.69955488e-13  9.59125084e-09 -0.00000000e+00\n  2.12753412e-11 -3.25222487e-10  0.00000000e+00  1.27792524e-11\n -3.65905974e-13 -7.87552596e-10 -1.47646130e-12  2.73354585e-12\n  6.03697219e-11 -3.19710121e-12  0.00000000e+00  1.01731454e-11\n  6.76387269e-10  7.38460835e-13 -3.46036168e-11  1.29717095e-10\n  0.00000000e+00  1.27490612e-12  0.00000000e+00  1.73421775e-11\n  0.00000000e+00  2.57646467e-12 -4.28352949e-11 -1.36452654e-11\n -1.10059438e-11 -5.61545505e-10  0.00000000e+00 -3.15748594e-12\n  0.00000000e+00  0.00000000e+00]\nOptimal Œ∏: 9.999989290284357e-07\nModel for digit 9 saved at /kaggle/working/models/\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"### [Testing]","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nfrom sklearn.decomposition import PCA\nimport pickle\nimport matplotlib.pyplot as plt\n\n# Define the rational function\n# (Œ±_0 + Œ±_1*x1**1 + Œ±_2*x2**2 + ...)\ndef rational_function(x, alpha, beta):\n    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n    return numerator / denominator\n\n#-----------------------------------------------------\n# import itertools\n\n# def generate_multi_indices(n, d):\n#     indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n#     return indices\n\n# def construct_polynomial(x, coefficients, indices):\n#     polynomial_value = 0\n#     for coeff, idx in zip(coefficients, indices):\n#         term = coeff * np.prod([x[i] ** idx[i] for i in range(len(x))])\n#         polynomial_value += term\n#     return polynomial_value\n\n# def rational_function(x, alpha, beta, n, d):\n#     indices = generate_multi_indices(n, d)\n\n#     # Compute numerator and denominator\n#     numerator = construct_polynomial(x, alpha, indices)\n#     denominator = construct_polynomial(x, beta, indices)\n\n#     # # Avoid division by zero\n#     # if np.abs(denominator) < 1e-8:\n#     #     denominator = 1e-8\n\n#     return numerator / denominator\n\n#-----------------------------------------------------\n# Import\nfrom keras.datasets import mnist\n(_, _), (x_test, y_test) = mnist.load_data()\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#1 Flatten\nx_test = x_test.reshape(x_test.shape[0], -1)\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n\n#2 Subsets\nsubset_size = 10000\nx_test_subset = x_test[:subset_size]\ny_test_subset = y_test[:subset_size]\nprint(f\"x_test_subset shape: {x_test_subset.shape}\")\n\n#3 PCA\nfrom sklearn.decomposition import PCA\nimport pickle\nn_components = 77\npca = PCA(n_components=n_components)\nx_test_pca = pca.fit_transform(x_test_subset)\nprint(f\"x_test_pca shape: \", x_test_pca.shape)\n\n#4 Normalize\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nx_test_norm = scaler.fit_transform(x_test_pca)\nprint(f\"x_test_norm shape: {x_test_norm.shape}\")\n\n#------------------------------------------\n# Load the saved models and test\nmodels_dir = \"/kaggle/working/models/\"\naccuracies = []\n\n#------------------------------------------\nfor digit in range(10):\n    # Load model for each digit\n    with open(f\"{models_dir}classifier_{digit}.pkl\", \"rb\") as file:\n        model = pickle.load(file)\n\n    alpha = model[\"alpha\"]\n    beta = model[\"beta\"]\n    theta = model[\"theta\"]\n\n    # n = 2\n    # d = 2\n    # # Evaluate the rational function for each test data point\n    # y_predicted = [\n    #     rational_function(x, alpha, beta, n, d) for x in x_test_norm\n    # ]\n\n    y_predicted = [\n    rational_function(x, alpha, beta) for x in x_test_norm\n    ]\n\n    # Convert predictions to binary (higher digit - for this digit, 0/lower digit for others)\n    y_pred_binary = np.array(y_predicted) < 3\n    y_true_binary = y_test_subset == digit\n\n    # Calculate accuracy for this digit\n    accuracy = np.mean(y_pred_binary == y_true_binary)\n    accuracies.append(accuracy)\n\n    print(f\"Accuracy for digit {digit}: {accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Calculate and print overall accuracy\noverall_accuracy = np.mean(accuracies)\nprint(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n\n#------------------------------------------\n# Plotting accuracies for each digit\nplt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\nplt.xlabel(\"Digits\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Accuracy for Each Digit\")\nplt.xticks(range(10))\nplt.ylim(0, 1)\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# print(f\"y_pred_binary =\", y_pred_binary)\n# print(f\"y_true_binary =\", y_true_binary)\n\n# print(f\"y_pred_binary.shape =\", y_pred_binary.shape)\n# print(f\"y_true_binary.shape =\", y_true_binary.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:37:12.497297Z","iopub.execute_input":"2025-01-10T19:37:12.497677Z","iopub.status.idle":"2025-01-10T19:37:21.771476Z","shell.execute_reply.started":"2025-01-10T19:37:12.497638Z","shell.execute_reply":"2025-01-10T19:37:21.770626Z"}},"outputs":[{"name":"stdout","text":"x_test shape: (10000, 28, 28), y_test shape: (10000,)\nx_test shape: (10000, 784), y_test shape: (10000,)\nx_test_subset shape: (10000, 784)\nx_test_pca shape:  (10000, 77)\nx_test_norm shape: (10000, 77)\nAccuracy for digit 0: 54.15%\nAccuracy for digit 1: 52.27%\nAccuracy for digit 2: 89.68%\nAccuracy for digit 3: 40.55%\nAccuracy for digit 4: 40.93%\nAccuracy for digit 5: 53.67%\nAccuracy for digit 6: 51.71%\nAccuracy for digit 7: 45.45%\nAccuracy for digit 8: 47.92%\nAccuracy for digit 9: 54.18%\nOverall Accuracy: 53.05%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import time\nstart_time = time.time()\n\nend_time = time.time()\nprint(\"runing time:{} s\".format(end_time - start_time))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0f260a-39de-40b3-88e4-b86ec9388c0b",
   "metadata": {},
   "source": [
    "üçÅ Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9d1051-7755-406d-add7-6d75c6b80251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28), y_train shape: (60000,)\n",
      "x_train_flat shape: (60000, 784), y_train shape: (60000,)\n",
      "x_train_subset shape: (1000, 784)\n",
      "x_train_pca shape: (1000, 77)\n",
      "variance = 0.9022549810637561\n",
      "x_train_norm shape: (1000, 77)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Import\n",
    "(x_train, y_train), (_, _) = mnist.load_data()\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# 1. Flatten\n",
    "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
    "print(f\"x_train_flat shape: {x_train_flat.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "# 2. Subsets\n",
    "subset_size = 1000\n",
    "x_train_subset = x_train_flat[:subset_size]\n",
    "y_train_subset = y_train[:subset_size]\n",
    "print(f\"x_train_subset shape: {x_train_subset.shape}\")\n",
    "\n",
    "# 3. PCA\n",
    "n_components = 77  # Reduce to 77 components\n",
    "pca = PCA(n_components=n_components)\n",
    "x_train_pca = pca.fit_transform(x_train_subset)\n",
    "print(f\"x_train_pca shape: {x_train_pca.shape}\")\n",
    "variance = np.sum(pca.explained_variance_ratio_)\n",
    "print(f\"variance = {variance}\")  # Verify how much variance is retained\n",
    "\n",
    "# 4. Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_train_norm = scaler.fit_transform(x_train_pca)\n",
    "print(f\"x_train_norm shape: {x_train_norm.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5bce02-b9ac-4a1a-8503-8b77fc5478c4",
   "metadata": {},
   "source": [
    "üçÅ Check Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a048f795-7498-48bf-8d2e-fbdd77af7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing directory: /home/ajayp/RClass/models/\n",
      "Directory already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to your existing directory\n",
    "models_dir = \"/home/ajayp/RClass/models/\"\n",
    "print(f\"Using existing directory: {models_dir}\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(models_dir):\n",
    "    print(\"Directory already exists.\")\n",
    "else:\n",
    "    print(\"Directory does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b612615-577d-4672-9d4b-e59ac09d2d7f",
   "metadata": {},
   "source": [
    "üçÅ Problem Setup & Variable Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e0d36a-c516-4bd8-8be2-4e7459a2c921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.numerical.mip import MixedIntegerLinearProgram\n",
    "\n",
    "# 1. Initialize the problem (Minimization problem)\n",
    "p = MixedIntegerLinearProgram(maximization=False, solver=\"GLPK\")\n",
    "\n",
    "# 3. Define coefficients\n",
    "num_coefficients = 77  # PCA components\n",
    "# num_coefficients = len(multi_indices)\n",
    "\n",
    "# 2. Create variables\n",
    "vars = p.new_variable(real=True)  # Real-valued variables\n",
    "theta = vars[\"theta\"]  # Œ∏ - error bound to minimize\n",
    "alpha = [vars[f\"a{j}\"] for j in range(num_coefficients)]  # Œ± coefficients\n",
    "beta = [vars[f\"b{j}\"] for j in range(num_coefficients)]   # Œ≤ coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4290ae6-5efe-4685-ae6c-d3373b6bcaae",
   "metadata": {},
   "source": [
    "üçÅ Simple Approach: Construct G(x) & H(x) Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbd156c6-7344-4845-88af-71944ba124ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def construct_G_H_matrices(x_train_norm, n_components):\n",
    "\n",
    "#     # Parameters\n",
    "#     num_data_points = x_train_norm.shape[0]\n",
    "#     num_coefficients = n_components + 1  # Include constant terms Œ±0 & Œ≤0\n",
    "\n",
    "#     # Initialize G and H matrices\n",
    "#     G = np.zeros((num_data_points, num_coefficients))  # Numerator\n",
    "#     H = np.zeros((num_data_points, num_coefficients))  # Denominator\n",
    "\n",
    "#     # Construct G and H matrices\n",
    "#     for i in range(num_data_points):\n",
    "#         G[i, 0] = 1  # Constant term for numerator\n",
    "#         H[i, 0] = 1  # Constant term for denominator\n",
    "#         for j in range(num_coefficients - 1):\n",
    "#             G[i, j+1] = x_train_norm[i, j] ** (j+1)  # Polynomial terms\n",
    "#             H[i, j+1] = x_train_norm[i, j] ** (j+1)\n",
    "\n",
    "#     return G, H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de99bef8-0fe1-4081-bced-104b53ea8bd0",
   "metadata": {},
   "source": [
    "üçÅ Multi-Indices Generation (Polynomials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b0d412d-4778-442c-b1b3-2eeeb0d5a398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_multi_indices(n, d):\n",
    "    return [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n",
    "\n",
    "multi_indices = generate_multi_indices(2, 2)\n",
    "print(f\"Multi-indices: {multi_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa50a29-fe0f-4967-9ca8-17ef970b7841",
   "metadata": {},
   "source": [
    "üçÅ Construct G(x) and H(x) Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b1d0755-426d-4e69-85a8-c5340a017154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_G_H_matrices(x_train_norm, n, d):\n",
    "    num_data_points = x_train_norm.shape[0]\n",
    "    multi_indices = generate_multi_indices(n, d)\n",
    "    num_coefficients = len(multi_indices)\n",
    "\n",
    "    # Initialize G and H matrices\n",
    "    G = []\n",
    "    H = []\n",
    "\n",
    "    # Construct G and H using multi-indices\n",
    "    for i in range(num_data_points):\n",
    "        G_row = []\n",
    "        H_row = []\n",
    "        for idx in multi_indices:\n",
    "            term = np.prod([x_train_norm[i, k] ** idx[k] for k in range(n)])\n",
    "            G_row.append(term)\n",
    "            H_row.append(term)\n",
    "        G.append(G_row)\n",
    "        H.append(H_row)\n",
    "    \n",
    "    return G, H, multi_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b969c-c87f-44a6-b6ef-42ee34a5b0c1",
   "metadata": {},
   "source": [
    "üçÅ Feasibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad9fc628-31a0-44d2-8019-52861b8559c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.numerical.mip import MixedIntegerLinearProgram\n",
    "import numpy as np\n",
    "\n",
    "def check_feasibility_and_compute_coefficients(z, x_train_norm, y_binary, n_components):\n",
    "    # Parameters\n",
    "    num_data_points = x_train_norm.shape[0]\n",
    "    num_coefficients = n_components + 1\n",
    "    delta = 1e-6  # Avoid zero denominator\n",
    "\n",
    "    # Construct G and H matrices\n",
    "    # Approach 1\n",
    "    G, H = construct_G_H_matrices(x_train_norm, n_components)\n",
    "\n",
    "    # Approach 2\n",
    "    # G, H, _ = construct_G_H_matrices(x_train_norm, 2, 2)\n",
    "\n",
    "    # Define constraints and optimization\n",
    "    p = MixedIntegerLinearProgram(maximization=False)\n",
    "    vars = p.new_variable(real=True)\n",
    "\n",
    "    # Variables\n",
    "    theta = vars[\"theta\"]\n",
    "    alpha = [vars[f\"a{j}\"] for j in range(num_coefficients)]\n",
    "    beta = [vars[f\"b{j}\"] for j in range(num_coefficients)]\n",
    "\n",
    "    # Add Constraints\n",
    "    for i in range(num_data_points):\n",
    "        # Upper Bound Constraint\n",
    "        f_minus_z = y_binary[i] - z\n",
    "        p.add_constraint(\n",
    "            -sum(alpha[j] * G[i][j] for j in range(num_coefficients)) +\n",
    "            f_minus_z * sum(beta[j] * H[i][j] for j in range(num_coefficients)) -\n",
    "            theta <= 0\n",
    "        )\n",
    "        # Lower Bound Constraint\n",
    "        f_plus_z = y_binary[i] + z\n",
    "        p.add_constraint(\n",
    "            sum(alpha[j] * G[i][j] for j in range(num_coefficients)) -\n",
    "            f_plus_z * sum(beta[j] * H[i][j] for j in range(num_coefficients)) -\n",
    "            theta <= 0\n",
    "        )\n",
    "        # Positivity Constraint for Œ≤\n",
    "        p.add_constraint(\n",
    "            sum(beta[j] * H[i][j] for j in range(num_coefficients)) >= delta\n",
    "        )\n",
    "\n",
    "    # Objective: Minimize Œ∏\n",
    "    p.set_objective(theta)\n",
    "\n",
    "    # Solve the problem\n",
    "    try:\n",
    "        p.solve()\n",
    "        optimal_alpha = [p.get_values(alpha[j]) for j in range(num_coefficients)]\n",
    "        optimal_beta = [p.get_values(beta[j]) for j in range(num_coefficients)]\n",
    "        optimal_theta = p.get_values(theta)\n",
    "        return True, optimal_alpha, optimal_beta, optimal_theta\n",
    "    except Exception as e:\n",
    "        return False, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25671fa7-1ab3-418d-96d3-844071f25f8c",
   "metadata": {},
   "source": [
    "üçÅ Bisection Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dacda36-8f70-480b-b40e-a0a48ba26a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection_loop(x_train_norm, y_binary, uL, uH, precision, n_components):\n",
    "    optimal_alpha, optimal_beta, optimal_theta = None, None, None\n",
    "    z_values = []\n",
    "\n",
    "    while uH - uL > precision:\n",
    "        z = (uL + uH) / 2\n",
    "        z_values.append(z)\n",
    "\n",
    "        # Feasibility Check\n",
    "        feasible, alpha_coefficients, beta_coefficients, theta = check_feasibility_and_compute_coefficients(\n",
    "            z, x_train_norm, y_binary, n_components\n",
    "        )\n",
    "\n",
    "        # Update bounds based on feasibility\n",
    "        if feasible:\n",
    "            uH = z\n",
    "            optimal_alpha, optimal_beta, optimal_theta = alpha_coefficients, beta_coefficients, theta\n",
    "        else:\n",
    "            uL = z\n",
    "\n",
    "    return uH, optimal_alpha, optimal_beta, optimal_theta, z_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a7367-02fc-4e8a-8e00-a92566f4255b",
   "metadata": {},
   "source": [
    "üçÅ Training for Each Digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b67f186d-2164-40c7-bf52-65290b6351c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for digit 0...\n",
      "Digit 0: Optimal z = 22282498125/67108864\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0009325441277321631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14557688690032647, 0.0, -2.8256322357636923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -6.00179772023484, 0.0, 0.0, 0.0, 126.00190564179435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10021.26520430418, 0.0, 0.0, 0.0, 0.0, 0.0, 122881.59385468383, 0.0, 0.0, 0.0, 0.0, 383737.36713365436, 490957291391.57916, 0.0, 0.0, 0.0, 0.0, -3076976.95976099, 0.0, 0.0, 0.0, 1.2851673707041699e+31, 0.0, 0.0005712671208861209, 0.0, -90.26442856736276, 0.0, 3.0750919105322194e+18, 0.0, 1.9485199522651656e+16, 0.0, 0.0, 0.0, -30993.406199757686, 0.0, 368273703243186.8, 0.0, -27.59981636411019, 3337503.1952387183]\n",
      "Theta: -0.0003280350963622332\n",
      "Model saved for digit 0 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 1...\n",
      "Digit 1: Optimal z = 44094164625/134217728\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00985588890539972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -31463472045.544044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4514633981714056, 0.1123188014049563, 0.0, -2.059631292312808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.760135964735996, 0.0, 0.0, 0.0, 86.42032535864814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7130.424824251857, 0.0, 0.0, 0.0, 0.0, 0.0, 85766.05661171417, 0.0, 0.0, 0.0, 0.0, 285307.14339110855, 305106523620.8162, 0.0, 0.0, 0.0, 0.0, -2287807.930209037, 0.0, 0.0, 0.0, 1.0077094042007982e+31, 0.0, 0.0, 0.0, -63.02353165943137, 0.0, 2.1466179813561134e+18, 0.0, 18972697869505.918, 0.0, 0.0, 0.0, -14237.92680745047, 0.0, 267585873579627.66, 0.0, -8.409351461469306, 8708092713672269.0]\n",
      "Theta: 0.0\n",
      "Model saved for digit 1 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 2...\n",
      "Digit 2: Optimal z = 22282498125/67108864\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006994080955183033, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1455768869003008, 0.0, -2.8256322357632015, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -6.00179772023378, 0.0, 0.0, 0.0, 126.0019056417721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10021.265204302445, 0.0, 0.0, 0.0, 0.0, 0.0, 122881.59385466237, 0.0, 0.0, 0.0, 0.0, 383737.36713358783, 490957291391.4956, 0.0, 0.0, 0.0, 0.0, -3076976.9597604554, 0.0, 0.0, 0.0, 1.285167370703943e+31, 0.0, 0.0005712671208860791, 0.0, -90.26442856733351, 0.0, 3.07509191053169e+18, 0.0, 1.948519952264911e+16, 0.0, 0.0, 0.0, -30993.4061997527, 0.0, 368273703243122.6, 0.0, -27.59981636410609, 3336976.2162559945]\n",
      "Theta: -0.00032803509636414714\n",
      "Model saved for digit 2 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 3...\n",
      "Digit 3: Optimal z = 916477875/16777216\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -456266060909772.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -11.614682859946008, 0.030814947271819923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0130515049324083, 0.0, 0.0, 0.0, 0.0, -12.009282801179202, 0.0, 0.0, -64.93457507955411, 4539352697947.65, 162072348.17920554, 0.0, -7192.463943332706, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.002278106667422237, 0.0, 5414036.477139378, 165871796805.1422, -468247.78100287635, 0.0, 0.0, 4836.805354865526, 3600.769283967695, 0.0, 0.0, 3035762.8708472773, 7.806052442377235e+17, 0.0, 0.0, 1007941.7076643503, -120961.57041393858, 71.53558505069815, 0.0, 0.0, 1.3172640353309532e+19, 0.0, 2024525.7578659232, -1.9228464805599719, 23.965621880502496, 0.0, 422068376.9204893, 271133579385.8102, 114680349109.53374, -9.927651125156945]\n",
      "Theta: 0.0\n",
      "Model saved for digit 3 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 4...\n",
      "Digit 4: Optimal z = 44094164625/134217728\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00985588890539972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -31463472045.544044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4514633981714056, 0.1123188014049563, 0.0, -2.059631292312808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.760135964735996, 0.0, 0.0, 0.0, 86.42032535864814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7130.424824251857, 0.0, 0.0, 0.0, 0.0, 0.0, 85766.05661171417, 0.0, 0.0, 0.0, 0.0, 285307.14339110855, 305106523620.8162, 0.0, 0.0, 0.0, 0.0, -2287807.930209037, 0.0, 0.0, 0.0, 1.0077094042007982e+31, 0.0, 0.0, 0.0, -63.02353165943137, 0.0, 2.1466179813561134e+18, 0.0, 18972697869505.918, 0.0, 0.0, 0.0, -14237.92680745047, 0.0, 267585873579627.66, 0.0, -8.409351461469306, 8708092713672269.0]\n",
      "Theta: 0.0\n",
      "Model saved for digit 4 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 5...\n",
      "Digit 5: Optimal z = 17090959625/67108864\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0014651184109337426, 0.0, 0.01633976106588719, 0.0, 0.02951216384365335, 0.0, 0.0, 0.0, -0.2485836844321248, 0.0, 0.0006507947646926368, 0.0, 15.596283041687952, -0.0014825046535950923, 0.0, 0.0, 0.0, 0.0, 0.009790556731570003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -82649.27386637981, 0.00027672653659002895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 393.43059969295433, 0.0, 0.0, -77406049040182.05, 0.0, 485954146704209.2, 0.0, -100.38973840801901, 0.0, 0.0, 0.0, 33834990476.652912, 7.781494003405686, 0.0, -110262757955.84471]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0023000435286219755, 0.0, 0.0, 0.0018180604506488859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022812836901591665, 0.0, 0.0, 0.00010212061093371713, -0.0064649382875822965, 0.0, 0.0, 0.4124053764271447, 0.0, -0.04683727105609919, 0.0, -0.8829606570587222, 2.4304777101243194e-05, 0.0, 0.0, 0.0, 0.0, -0.013668621654882342, 14505.092566202999, 0.0, -0.230290099655053, 3.109327627521011, 53988895891.258385, 0.0, 0.0, 0.0, -610.5655137861609, -0.14952112075894564, 0.0, 0.0, 0.0, 6.240538713383678e+23, 0.0, 0.0, 3.4705970722814388, 36.90015432408627, 0.0, 4360093036879.985, 0.0, 1893265310146.2578, 0.0, 0.0, -0.00017512349919439674, 0.0, 0.0, 131818684.71614282, -0.07235136344227691, 0.037858613695191966, 672828861.8610005]\n",
      "Theta: 0.0\n",
      "Model saved for digit 5 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 6...\n",
      "Digit 6: Optimal z = 44094164625/134217728\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00985588890539972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -31463472045.544044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4514633981714056, 0.1123188014049563, 0.0, -2.059631292312808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.760135964735996, 0.0, 0.0, 0.0, 86.42032535864814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7130.424824251857, 0.0, 0.0, 0.0, 0.0, 0.0, 85766.05661171417, 0.0, 0.0, 0.0, 0.0, 285307.14339110855, 305106523620.8162, 0.0, 0.0, 0.0, 0.0, -2287807.930209037, 0.0, 0.0, 0.0, 1.0077094042007982e+31, 0.0, 0.0, 0.0, -63.02353165943137, 0.0, 2.1466179813561134e+18, 0.0, 18972697869505.918, 0.0, 0.0, 0.0, -14237.92680745047, 0.0, 267585873579627.66, 0.0, -8.409351461469306, 8708092713672269.0]\n",
      "Theta: 0.0\n",
      "Model saved for digit 6 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 7...\n",
      "Digit 7: Optimal z = 22282498125/67108864\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0009325441277321631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14557688690032647, 0.0, -2.8256322357636923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -6.00179772023484, 0.0, 0.0, 0.0, 126.00190564179435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 10021.26520430418, 0.0, 0.0, 0.0, 0.0, 0.0, 122881.59385468383, 0.0, 0.0, 0.0, 0.0, 383737.36713365436, 490957291391.57916, 0.0, 0.0, 0.0, 0.0, -3076976.95976099, 0.0, 0.0, 0.0, 1.2851673707041699e+31, 0.0, 0.0005712671208861209, 0.0, -90.26442856736276, 0.0, 3.0750919105322194e+18, 0.0, 1.9485199522651656e+16, 0.0, 0.0, 0.0, -30993.406199757686, 0.0, 368273703243186.8, 0.0, -27.59981636411019, 3337503.1952387183]\n",
      "Theta: -0.0003280350963622332\n",
      "Model saved for digit 7 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 8...\n",
      "Digit 8: Optimal z = 28455005875/67108864\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4011907125564736, 214.01869849179664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01426401426699688, 0.0, 0.0, 0.0012335616399535383, 0.0, 0.0, -93.49737540616366, 0.0, 0.0, 0.0, 1.0836812739910479e+26, 0.0, 0.0, -1244.6766504318416, 0.0, 0.0, -194135473493183.8, 0.0, 915666307010723.4, 0.0, 0.0, 0.0, 0.0, 0.0, -3342706993681.1846, 0.0, 0.0, -1636708046494.6553]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012653759892058076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.226608525405402, 0.0, 0.0, 32.753906642737505, 0.0, 0.0, 0.0, 0.0, 15.991982309411988, -0.0008741923348121103, -463.7670745550644, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.4794518459395171, 0.0, 0.0, 0.0, 2.7617957705916006e-05, 488309948426.33386, 0.0, 0.0, -3970.7454498772017, -16.769109736331696, 0.0, 0.0, -10232.641231124886, 0.0, 1.0545305538627174e+26, 0.0, 0.0, 0.0, 0.0, 0.0, 704574512949984.8, 0.0, 2157285266926.0732, 0.0, 0.0, 0.0, 0.0, 0.0, 623437728250.3959, 5489807.168603402, -1.0262106530180242, 1261017833403.0757]\n",
      "Theta: 0.0\n",
      "Model saved for digit 8 at /home/ajayp/RClass/models/\n",
      "Training classifier for digit 9...\n",
      "Digit 9: Optimal z = 44094164625/134217728\n",
      "Alpha: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00985588890539972, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -31463472045.544044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Beta: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4514633981714056, 0.1123188014049563, 0.0, -2.059631292312808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.760135964735996, 0.0, 0.0, 0.0, 86.42032535864814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7130.424824251857, 0.0, 0.0, 0.0, 0.0, 0.0, 85766.05661171417, 0.0, 0.0, 0.0, 0.0, 285307.14339110855, 305106523620.8162, 0.0, 0.0, 0.0, 0.0, -2287807.930209037, 0.0, 0.0, 0.0, 1.0077094042007982e+31, 0.0, 0.0, 0.0, -63.02353165943137, 0.0, 2.1466179813561134e+18, 0.0, 18972697869505.918, 0.0, 0.0, 0.0, -14237.92680745047, 0.0, 267585873579627.66, 0.0, -8.409351461469306, 8708092713672269.0]\n",
      "Theta: 0.0\n",
      "Model saved for digit 9 at /home/ajayp/RClass/models/\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for digit in range(10):\n",
    "    print(f\"Training classifier for digit {digit}...\")\n",
    "\n",
    "    # Binary labels for one-vs-all classification\n",
    "    y_binary = (y_train_subset == digit).astype(float)\n",
    "\n",
    "    # Scale binary labels (2-Y, 4-N)\n",
    "    y_binary = np.where(y_binary == 1, 2, 4)\n",
    "\n",
    "    # Bisection parameters\n",
    "    uL = 0  # Lower bound\n",
    "    uH = 500  # Upper bound\n",
    "    precision = 1e-6  # Precision threshold\n",
    "\n",
    "    # Bisection loop\n",
    "    optimal_z, optimal_alpha, optimal_beta, optimal_theta, z_values = bisection_loop(\n",
    "        x_train_norm, y_binary, uL, uH, precision, n_components\n",
    "    )\n",
    "\n",
    "    # Results\n",
    "    print(f\"Digit {digit}: Optimal z = {optimal_z}\")\n",
    "    print(f\"Alpha: {optimal_alpha}\")\n",
    "    print(f\"Beta: {optimal_beta}\")\n",
    "    print(f\"Theta: {optimal_theta}\")\n",
    "\n",
    "    # Save the model\n",
    "    model = {\n",
    "        \"alpha\": optimal_alpha,\n",
    "        \"beta\": optimal_beta,\n",
    "        \"theta\": optimal_theta,\n",
    "        \"n_components\": n_components\n",
    "    }\n",
    "    with open(f\"{models_dir}/classifier_{digit}.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "    print(f\"Model saved for digit {digit} at {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028ecf5-08c6-4750-b751-9aaad34aab1d",
   "metadata": {},
   "source": [
    "üçÅ Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64882b02-6450-4da1-bd99-d73accf3059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape: (10000, 28, 28), y_test shape: (10000,)\n",
      "x_test shape: (10000, 784), y_test shape: (10000,)\n",
      "x_test_subset shape: (10000, 784)\n",
      "x_test_pca shape: (10000, 77)\n",
      "x_test_norm shape: (10000, 77)\n",
      "Accuracy for digit 0: 9.80%\n",
      "Accuracy for digit 1: 11.35%\n",
      "Accuracy for digit 2: 10.32%\n",
      "Accuracy for digit 3: 10.10%\n",
      "Accuracy for digit 4: 9.82%\n",
      "Accuracy for digit 5: 12.02%\n",
      "Accuracy for digit 6: 9.58%\n",
      "Accuracy for digit 7: 10.28%\n",
      "Accuracy for digit 8: 11.14%\n",
      "Accuracy for digit 9: 10.09%\n",
      "Overall Accuracy: 10.45%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import os\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Simple Approach\n",
    "# Define rational function for polynomial approach\n",
    "def rational_function(x, alpha, beta):\n",
    "    numerator = alpha[0] + sum(alpha[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n",
    "    denominator = beta[0] + sum(beta[i+1] * x[i] ** (i + 1) for i in range(len(x)))\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if abs(denominator) < 1e-8:\n",
    "        denominator = 1e-8\n",
    "\n",
    "    return numerator / denominator\n",
    "\n",
    "#-----------------------------------------------------\n",
    "#2 Multi-Indices Approach\n",
    "# import itertools\n",
    "\n",
    "# def generate_multi_indices(n, d):\n",
    "#     indices = [idx for idx in itertools.product(range(d + 1), repeat=n) if sum(idx) <= d]\n",
    "#     return indices\n",
    "\n",
    "# def construct_polynomial(x, coefficients, indices):\n",
    "#     polynomial_value = 0\n",
    "#     for coeff, idx in zip(coefficients, indices):\n",
    "#         term = coeff * np.prod([x[i] ** idx[i] for i in range(len(x))])\n",
    "#         polynomial_value += term\n",
    "#     return polynomial_value\n",
    "\n",
    "# def rational_function(x, alpha, beta, n, d):\n",
    "#     indices = generate_multi_indices(n, d)\n",
    "\n",
    "#     # Compute numerator and denominator\n",
    "#     numerator = construct_polynomial(x, alpha, indices)\n",
    "#     denominator = construct_polynomial(x, beta, indices)\n",
    "\n",
    "#     # Avoid division by zero\n",
    "#     if abs(denominator) < 1e-8:\n",
    "#         denominator = 1e-8\n",
    "\n",
    "#     return numerator / denominator\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Import and Preprocess Test Data\n",
    "(_, _), (x_test, y_test) = mnist.load_data()\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Flatten\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Subsets\n",
    "subset_size = 10000\n",
    "x_test_subset = x_test[:subset_size]\n",
    "y_test_subset = y_test[:subset_size]\n",
    "print(f\"x_test_subset shape: {x_test_subset.shape}\")\n",
    "\n",
    "# PCA\n",
    "n_components = 77\n",
    "pca = PCA(n_components=n_components)\n",
    "x_test_pca = pca.fit_transform(x_test_subset)\n",
    "print(f\"x_test_pca shape: {x_test_pca.shape}\")\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_test_norm = scaler.fit_transform(x_test_pca)\n",
    "print(f\"x_test_norm shape: {x_test_norm.shape}\")\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Directory Setup for Models (SageMath Path)\n",
    "models_dir = \"/home/ajayp/RClass/models/\"\n",
    "if not os.path.exists(models_dir):\n",
    "    raise FileNotFoundError(f\"Models directory not found at: {models_dir}\")\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Load Saved Models and Test\n",
    "for digit in range(10):\n",
    "    \n",
    "    # Load the model for each digit\n",
    "    with open(f\"{models_dir}/classifier_{digit}.pkl\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    alpha = model[\"alpha\"]\n",
    "    beta = model[\"beta\"]\n",
    "    theta = model[\"theta\"]\n",
    "\n",
    "    # Evaluate predictions using Polynomial Approach\n",
    "    y_predicted = [\n",
    "        rational_function(x, alpha, beta) for x in x_test_norm\n",
    "    ]\n",
    "\n",
    "    # Evaluate predictions using Multi-Indices Approach\n",
    "    # n = 2\n",
    "    # d = 2\n",
    "    # y_predicted = [\n",
    "    #     rational_function(x, alpha, beta, n, d) for x in x_test_norm\n",
    "    # ]\n",
    "\n",
    "    # Binary classification based on predictions\n",
    "    y_pred_binary = np.array(y_predicted) < 3\n",
    "    y_true_binary = y_test_subset == digit\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = np.mean(y_pred_binary == y_true_binary)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Accuracy for digit {digit}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Overall Accuracy\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Plot Accuracies for Each Digit\n",
    "plt.bar(range(10), accuracies, color='blue', alpha=0.7, label=\"Accuracy\")\n",
    "plt.xlabel(\"Digits\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy for Each Digit\")\n",
    "plt.xticks(range(10))\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5704b3-0611-437d-b821-787b4657a2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.4",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
